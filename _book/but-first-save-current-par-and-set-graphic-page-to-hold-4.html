<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>6 but first, save current par and set graphic page to hold 4 | BIO4558 Biostatistiques appliquées avec R</title>
  <meta name="description" content="6 but first, save current par and set graphic page to hold 4 | BIO4558 Biostatistiques appliquées avec R" />
  <meta name="generator" content="bookdown 0.13 and GitBook 2.6.7" />

  <meta property="og:title" content="6 but first, save current par and set graphic page to hold 4 | BIO4558 Biostatistiques appliquées avec R" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="6 but first, save current par and set graphic page to hold 4 | BIO4558 Biostatistiques appliquées avec R" />
  
  
  

<meta name="author" content="Julien Martin" />


<meta name="date" content="2019-09-25" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="anova-a-un-critere-de-classification.html"/>
<link rel="next" href="anova-a-criteres-multiples-plans-factoriels-et-hierarchiques.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Préface</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#quelques-points-importants-a-retenir"><i class="fa fa-check"></i>Quelques points importants à retenir</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#quest-ce-que-r-et-pourquoi-lutiliser-dans-ce-cours"><i class="fa fa-check"></i>Qu’est-ce que R et pourquoi l’utiliser dans ce cours?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#installation"><i class="fa fa-check"></i>Installation</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#instructions-generales-pour-les-laboratoires"><i class="fa fa-check"></i>Instructions générales pour les laboratoires</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#et-pour-les-dilettantes-ou-ceux-qui-sont-allergiques-a-la-programmation"><i class="fa fa-check"></i>Et pour les dilettantes ou ceux qui sont allergiques à la programmation…</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introductionR.html"><a href="introductionR.html"><i class="fa fa-check"></i><b>1</b> Introduction à R</a><ul>
<li class="chapter" data-level="1.1" data-path="introductionR.html"><a href="introductionR.html#importer-et-exporter-des-donnees"><i class="fa fa-check"></i><b>1.1</b> Importer et exporter des données</a><ul>
<li class="chapter" data-level="1.1.1" data-path="introductionR.html"><a href="introductionR.html#ouvrir-et-sauvegarder-un-fichier-de-donnees-en-format-r"><i class="fa fa-check"></i><b>1.1.1</b> Ouvrir et sauvegarder un fichier de données en format R</a></li>
<li class="chapter" data-level="1.1.2" data-path="introductionR.html"><a href="introductionR.html#entrer-des-donnees"><i class="fa fa-check"></i><b>1.1.2</b> Entrer des données</a></li>
<li class="chapter" data-level="1.1.3" data-path="introductionR.html"><a href="introductionR.html#nettoyercorriger-des-donnees"><i class="fa fa-check"></i><b>1.1.3</b> Nettoyer/corriger des données</a></li>
<li class="chapter" data-level="1.1.4" data-path="introductionR.html"><a href="introductionR.html#importer-des-donnees-a-partir-dexcel."><i class="fa fa-check"></i><b>1.1.4</b> Importer des données à partir d’Excel.</a></li>
<li class="chapter" data-level="1.1.5" data-path="introductionR.html"><a href="introductionR.html#exporter-des-donnees-a-partir-de-r."><i class="fa fa-check"></i><b>1.1.5</b> Exporter des données à partir de R.</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="introductionR.html"><a href="introductionR.html#examen-preliminaire-des-donnees"><i class="fa fa-check"></i><b>1.2</b> Examen préliminaire des données</a><ul>
<li class="chapter" data-level="1.2.1" data-path="introductionR.html"><a href="introductionR.html#sommaire-statistique"><i class="fa fa-check"></i><b>1.2.1</b> Sommaire statistique</a></li>
<li class="chapter" data-level="1.2.2" data-path="introductionR.html"><a href="introductionR.html#histogramme-densite-de-probabilite-empirique-boxplot-et-examen-visuel-de-la-normalite"><i class="fa fa-check"></i><b>1.2.2</b> Histogramme, densité de probabilité empirique, boxplot et examen visuel de la normalité</a></li>
<li class="chapter" data-level="1.2.3" data-path="introductionR.html"><a href="introductionR.html#diagrammes-de-dispersion-bivaries"><i class="fa fa-check"></i><b>1.2.3</b> Diagrammes de dispersion bivariés</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="introductionR.html"><a href="introductionR.html#creer-des-sous-ensembles-de-cas"><i class="fa fa-check"></i><b>1.3</b> Créer des sous-ensembles de cas</a></li>
<li class="chapter" data-level="1.4" data-path="introductionR.html"><a href="introductionR.html#transformations-de-donnees"><i class="fa fa-check"></i><b>1.4</b> Transformations de données</a></li>
<li class="chapter" data-level="1.5" data-path="introductionR.html"><a href="introductionR.html#exercice"><i class="fa fa-check"></i><b>1.5</b> Exercice</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html"><a href="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html"><i class="fa fa-check"></i><b>2</b> Analyse de puissance avec R et G*Power ahahahaha</a><ul>
<li class="chapter" data-level="2.1" data-path="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html"><a href="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html#la-theorie"><i class="fa fa-check"></i><b>2.1</b> La théorie</a><ul>
<li class="chapter" data-level="2.1.1" data-path="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html"><a href="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html#quest-ce-que-la-puissance"><i class="fa fa-check"></i><b>2.1.1</b> Qu’est-ce que la puissance?</a></li>
<li class="chapter" data-level="2.1.2" data-path="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html"><a href="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html#pourquoi-faire-une-analyse-de-puissance"><i class="fa fa-check"></i><b>2.1.2</b> Pourquoi faire une analyse de puissance?</a></li>
<li class="chapter" data-level="2.1.3" data-path="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html"><a href="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html#facteurs-qui-affectent-la-puissance"><i class="fa fa-check"></i><b>2.1.3</b> Facteurs qui affectent la puissance</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html"><a href="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html#quest-ce-que-gpower"><i class="fa fa-check"></i><b>2.2</b> Qu’est ce que G*Power?</a></li>
<li class="chapter" data-level="2.3" data-path="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html"><a href="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html#comment-utiliser-gpower"><i class="fa fa-check"></i><b>2.3</b> Comment utiliser G*Power</a><ul>
<li class="chapter" data-level="2.3.1" data-path="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html"><a href="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html#principe-general"><i class="fa fa-check"></i><b>2.3.1</b> Principe général</a></li>
<li class="chapter" data-level="2.3.2" data-path="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html"><a href="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html#types-danalyses-de-puissance-disponibles"><i class="fa fa-check"></i><b>2.3.2</b> Types d’analyses de puissance disponibles</a></li>
<li class="chapter" data-level="2.3.3" data-path="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html"><a href="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html#comment-calculer-la-taille-de-leffet-gpower-permet-de-faire-une-analyse-de-puissance-pour-de-nombreux-tests-statistiques"><i class="fa fa-check"></i><b>2.3.3</b> Comment calculer la taille de l’effet G*Power permet de faire une analyse de puissance pour de nombreux tests statistiques</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html"><a href="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html#calculs-de-puissance-pour-un-test-de-t-comparant-deux-moyennes-independantes"><i class="fa fa-check"></i><b>2.4</b> Calculs de puissance pour un test de t comparant deux moyennes indépendantes</a><ul>
<li class="chapter" data-level="2.4.1" data-path="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html"><a href="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html#analyse-post-hoc"><i class="fa fa-check"></i><b>2.4.1</b> Analyse post-hoc</a></li>
<li class="chapter" data-level="2.4.2" data-path="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html"><a href="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html#analyse-a-priori"><i class="fa fa-check"></i><b>2.4.2</b> Analyse a priori</a></li>
<li class="chapter" data-level="2.4.3" data-path="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html"><a href="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html#analyse-de-sensitivite"><i class="fa fa-check"></i><b>2.4.3</b> Analyse de sensitivité</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html"><a href="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html#points-a-retenir"><i class="fa fa-check"></i><b>2.5</b> Points à retenir</a></li>
<li class="chapter" data-level="2.6" data-path="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html"><a href="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html#exercice-1"><i class="fa fa-check"></i><b>2.6</b> Exercice</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="correlation-et-regression-lineaire-simple.html"><a href="correlation-et-regression-lineaire-simple.html"><i class="fa fa-check"></i><b>3</b> Corrélation et régression linéaire simple</a></li>
<li class="chapter" data-level="4" data-path="comparaison-de-deux-echantillons.html"><a href="comparaison-de-deux-echantillons.html"><i class="fa fa-check"></i><b>4</b> Comparaison de deux échantillons</a></li>
<li class="chapter" data-level="5" data-path="anova-a-un-critere-de-classification.html"><a href="anova-a-un-critere-de-classification.html"><i class="fa fa-check"></i><b>5</b> ANOVA à un critère de classification</a></li>
<li class="chapter" data-level="6" data-path="but-first-save-current-par-and-set-graphic-page-to-hold-4.html"><a href="but-first-save-current-par-and-set-graphic-page-to-hold-4.html"><i class="fa fa-check"></i><b>6</b> but first, save current par and set graphic page to hold 4</a></li>
<li class="chapter" data-level="7" data-path="anova-a-criteres-multiples-plans-factoriels-et-hierarchiques.html"><a href="anova-a-criteres-multiples-plans-factoriels-et-hierarchiques.html"><i class="fa fa-check"></i><b>7</b> ANOVA à critères multiples : plans factoriels et hiérarchiques</a></li>
<li class="chapter" data-level="8" data-path="but-first-save-current-par-and-set-graphic-page-to-hold-4-1.html"><a href="but-first-save-current-par-and-set-graphic-page-to-hold-4-1.html"><i class="fa fa-check"></i><b>8</b> but first, save current par and set graphic page to hold 4</a></li>
<li class="chapter" data-level="9" data-path="fit-simplified-model.html"><a href="fit-simplified-model.html"><i class="fa fa-check"></i><b>9</b> fit simplified model</a></li>
<li class="chapter" data-level="10" data-path="modified-from-code-written-by-david-c-howell.html"><a href="modified-from-code-written-by-david-c-howell.html"><i class="fa fa-check"></i><b>10</b> modified from code written by David C. Howell</a></li>
<li class="chapter" data-level="11" data-path="httpwww-uvm-edudhowellstatpagesmore-stuffpermuta-.html"><a href="httpwww-uvm-edudhowellstatpagesmore-stuffpermuta-.html"><i class="fa fa-check"></i><b>11</b> <span>http://www.uvm.edu/~dhowell/StatPages/More_Stuff/Permuta-</span></a></li>
<li class="chapter" data-level="12" data-path="bootstrap-1000-time-using-the-residuals-bootstraping.html"><a href="bootstrap-1000-time-using-the-residuals-bootstraping.html"><i class="fa fa-check"></i><b>12</b> Bootstrap 1000 time using the residuals bootstraping</a></li>
<li class="chapter" data-level="13" data-path="regression-multiple.html"><a href="regression-multiple.html"><i class="fa fa-check"></i><b>13</b> Régression multiple</a></li>
<li class="chapter" data-level="14" data-path="bootstrap-analysis-the-simple-way-with-library-simpleboot.html"><a href="bootstrap-analysis-the-simple-way-with-library-simpleboot.html"><i class="fa fa-check"></i><b>14</b> Bootstrap analysis the simple way with library simpleboot</a></li>
<li class="chapter" data-level="15" data-path="define-model-to-be-bootstrapped-and-the-data-source-used.html"><a href="define-model-to-be-bootstrapped-and-the-data-source-used.html"><i class="fa fa-check"></i><b>15</b> Define model to be bootstrapped and the data source used</a></li>
<li class="chapter" data-level="16" data-path="ancova-et-glm.html"><a href="ancova-et-glm.html"><i class="fa fa-check"></i><b>16</b> ANCOVA et GLM</a></li>
<li class="chapter" data-level="17" data-path="analyse-de-donnees-de-frequence-tableaux-de-contingence-modeles-log-lineaires-et-regression-de-poisson.html"><a href="analyse-de-donnees-de-frequence-tableaux-de-contingence-modeles-log-lineaires-et-regression-de-poisson.html"><i class="fa fa-check"></i><b>17</b> Analyse de données de fréquence: Tableaux de contingence, modèles log-linéaires et régression de Poisson</a></li>
<li class="chapter" data-level="18" data-path="convert-case-form-to-table-form.html"><a href="convert-case-form-to-table-form.html"><i class="fa fa-check"></i><b>18</b> convert case form to table form</a></li>
<li class="chapter" data-level="19" data-path="fit-full-model.html"><a href="fit-full-model.html"><i class="fa fa-check"></i><b>19</b> Fit full model</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">BIO4558 Biostatistiques appliquées avec R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="but-first-save-current-par-and-set-graphic-page-to-hold-4" class="section level1">
<h1><span class="header-section-number">6</span> but first, save current par and set graphic page to hold 4</h1>
<p>graphs
opar &lt;- par(mfrow = c(2, 2))
anova.model1 &lt;- lm(fklngth ~ year, data=Dam10dat)
plot(anova.model1)
par(opar)
D’après les graphiques, on peut douter de la normalité et de
l’homogénéité des variances. Notez qu’il y a un point qui ressort
vraiment avec une forte valeur résiduelle (cas numéro 59) et qu’il ne
s’aligne pas bien avec les autres valeurs: c’est la valeur extrême qui
avait été détectée plus tôt. Ce point fera sans doute gonfler la variance
résiduelle du groupe auquel il appartient.
Des tests formels nous confirmeront ou infirmeront nos conclusions
faites à partir de ces graphiques.
 Faites un test de normalité sur les résidus de l’ANOVA.
shapiro.test(residuals(anova.model1))
Shapiro-Wilk normality test
data: residuals(anova.model1)
W = 0.9157, p-value = 1.63e-06</p>
<p>Ce test confirme nos soupçons: les résidus ne sont pas distribués
normalement. Il faut cependant garder à l’esprit que la puissance est
grande et que même de petites déviations de la normalité sont
suffisantes pour rejeter l’hypothèse nulle.
 Ensuite, éprouvez l’hypothèse d’égalité des variances (homoscedastic-
ité):
require(car)
leveneTest(fklngth ~ year, data=Dam10dat)
Levene’s Test for Homogeneity of Variance
Df F value Pr(&gt;F)
group
3 2.8159 0.04234 <em>
114
—
Signif. codes: 0 ‘<em><strong>’ 0.001 ‘</strong>’ 0.01 ‘</em>’ 0.05 ‘.’ 0.1 ‘ ’ 1
&gt;
La valeur de p vous dit que vous pouvez rejeter l’hypothèse nulle qu’il
n’y a aucune différence dans les variances entre les années. Alors, nous
concluons que les variances ne sont pas homogènes.
Faire l’ANOVA
 Faites une ANOVA de fklnght en choisissant en p résumant pour
l’instant que les conditions d’application sont suffisamment remplies.
Que concluez-vous?
&gt; summary(anova.model1)
Call:
lm(formula = fklngth ~ year)
Residuals:
Min
1Q
-11.2116 -2.6866
Median
-0.7116
3Q
2.2103
Max
26.7885
Coefficients:
Estimate Std. Error t value Pr(&gt;|t|)
(Intercept)

48.0243
0.8566
56.061
&lt; 2e-16 </em><strong>
year1958
0.1872
1.3335
0.140 0.88859
year1965
-5.5077
1.7310 -3.182 0.00189 </strong>
year1966
-3.3127
1.1684 -2.835 0.00542 **
—
Signif. codes: 0 ‘<em><strong>’ 0.001 ‘</strong>’ 0.01 ‘</em>’ 0.05 ‘.’ 0.1 ‘ ’ 1


Residual standard error: 5.211
Multiple R-squared: 0.1355,
on 114 degrees of freedom
F-statistic: 5.957 on 3 and 114 DF,
Adjusted R-squared: 0.1128

p-value: 0.0008246</p>
<p> Les 4 coefficients peuvent être utilisés pour obtenir les valeurs
prédites par le modèle (i.e. les moyennes de chaque groupe). La
fklngth moyenne de la première année (1954) est 48.0243. Les
coefficients pour les 3 autres années sont la différence entre la
moyenne de l’année en question et la moyenne de 1954. La moyenne
pour 1965 est 48.0243-5.5077=42.5166. Pour chaque coefficient, on a
également accès à l’erreur-type, une valeur de t et la probabilité qui lui
est associée (H0 que le coefficient est 0). Les poissons étaient plus
petits après la construction du barrage qu’en 1954. Vous devez
prendre ces p-valeurs avec un grain de sel, car elles ne sont pas
corrigées pour les comparaisons multiples et. En général, je porte peu
d’attention à cette partie des résultats imprimés et me concentre sur ce
qui suit.
 La racine carrée de la variance des résidus (valeurs observées
moins valeurs prédites) qui correspond à la variabilité inexpliquée par
le modèle (variation de la taille des poissons capturés la même année).
 Le R-carré est la proportion de la variabilité de la variable
dépendante qui peut être expliquée par le modèle. Ici, le modèle
explique 13.5% de la variabilité. Les différences de taille d’une année à
l’autre sont relativement petites lorsqu’on les compare à la variation de
taille entre les poissons capturés la même année.
 La p-valeur associée au test “omnibus” que toutes les moyennes
sont égales. Ici, p est beaucoup plus petit que 0.05 et on rejetterait H0
pour conclure que fklngth varie selon les années.
La commande anova() produit le tableau d’ANOVA standard qui
contient la plupart de cette information:
&gt; anova(anova.model1)
Analysis of Variance Table
Response: fklngth
Df Sum Sq Mean Sq F value
Pr(&gt;F)
year
3 485.26 161.75 5.9574 0.0008246 ***
Residuals 114 3095.30
27.15
—
Signif. codes: 0 ‘<em><strong>’ 0.001 ‘</strong>’ 0.01 ‘</em>’ 0.05 ‘.’ 0.1 ‘ ’ 1
&gt;
La variabilité totale de fklngth, mesurée par la somme des carrés des
écarts (Sum sq) est partitionnée en ce qui peut être expliqué par
l’année (485.26) et la variabilité résiduelle inexpliquée (3095.30).
L’année explique bien (485.26/(3095.30+485.26)=.1355 or 13.55%
de la variabilité). Le carré moyen des résidus (Residual Mean Sq) est
leur variance.</p>
<p>Les comparaisons multiples
 La fonction pairwise.t.test() peut être utilisée pour comparer des moy-
ennes et ajuster (ou non, si désiré) les probabilités pour le nombre de
comparaisons en utilisant l’une des options pour p.adj:
pairwise.t.test(Dam10dat<span class="math inline">\(fklngth, &quot;none&quot;) pairwise.t.test(Dam10dat\)</span>fklngth,
“bonf”)
pairwise.t.test(Dam10dat<span class="math inline">\(fklngth, &quot;holm&quot;) pairwise.t.test(Dam10dat\)</span>fklngth,
“fdr”)
Dam10dat<span class="math inline">\(year, p.adj = Dam10dat\)</span>year, p.adj =
Dam10dat<span class="math inline">\(year, p.adj = Dam10dat\)</span>year, p.adj =
&gt; pairwise.t.test(Dam10dat<span class="math inline">\(fklngth, Dam10dat\)</span>year, p.adj =
“none”)
Compare toutes les moyennes, sans ajuster les probabilités.
Pairwise comparisons using t tests with pooled SD
data:
Dam10dat<span class="math inline">\(fklngth and Dam10dat\)</span>year
1954
1958
1965
1958 0.8886 -
-
1965 0.0019 0.0022 -
1966 0.0054 0.0079 0.1996
Option “bonf” ajuste les p-valeurs avec la correction de Bonferroni.
Ici, il y a 6 p-valeurs calculées, et la correction de Bonferroni revient à
simplement multiplier la p-valeur par 6 (sauf si le résultat est supérieur
à 1. Si tel est le cas, la p-valeur ajustée est 1)
&gt;
data:
Pairwise comparisons using t tests with pooled SD
Dam10dat<span class="math inline">\(fklngth and Dam10dat\)</span>year
1954 1958 1965
1958 1.000 -
-
1965 0.011 0.013 -
1966 0.033 0.047 1.000
P value adjustment method: bonferroni
Option “holm” is est la correction séquentielle de Bonferroni dans
laquelle les p-valeurs sont ordonnées de (i=1) la plus faible à (N) la
plus grande. La correction pour les p-valeurs est (N-i+1). Ici, il y a
N=6 paires de moyennes qui sont comparées. La plus petite valeur de
p non corrigée est 0.0019 pour 1954 vs 1965. La p-valeur corrigée est
donc 0.0019<em>(6-1+1)=0.011. La seconde plus petite p-valeur est
0.0022. Sa p-valeur corrigée est 0.0022</em>(6-2+1)=0.011. Pour la p-
valeur la plus élevée, la correction est (N-N+1)=1, donc la p-valeur
corrigée est égale à la p-valeur brute.</p>
<blockquote>
<p>pairwise.t.test(Dam10dat<span class="math inline">\(fklngth, Dam10dat\)</span>year, p.adj = “holm”)
Pairwise comparisons using t tests with pooled SD
data:
Dam10dat<span class="math inline">\(fklngth and Dam10dat\)</span>year
1954 1958 1965
1958 0.889 -
-
1965 0.011 0.011 -
1966 0.022 0.024 0.399
P value adjustment method: holm
L’option “fdr” sert à contrôler le “false discovery rate”.
pairwise.t.test(Dam10dat<span class="math inline">\(fklngth, Dam10dat\)</span>year, p.adj = “fdr”)
Pairwise comparisons using t tests with pooled SD
data:
Dam10dat<span class="math inline">\(fklngth and Dam10dat\)</span>year
1954
1958
1965
1958 0.8886 -
-
1965 0.0066 0.0066 -
1966 0.0108 0.0119 0.2395
Les quatre méthodes mènent ici à la même conclusion: les poissons
sont plus gros après la construction du barrage et toutes les
comparaisons entre les années 50 et 60 sont significatives alors que les
différences entre 54 et 58 ou 65 et 66 ne le sont pas. La conclusion ne
dépend pas du choix de méthode.
Dans d’autres situations, vous pourriez obtenir des résultats
contradictoires. Alors, quelle méthode choisir? Les p-valeurs qui ne
sont pas corrigées sont certainement suspectes lorsqu’il y a plusieurs
comparaisons. D’un autre coté, la correction de Bonferroni est
conservatrice et le devient encore plus lorsqu’il y a de très nombreuses
comparaisons. Des travaux récents suggèrent que la correction fdr est
un bon compromis lorsqu’il y a beaucoup de comparaisons.
La méthode de Tukey est l’une des plus populaires et est facile à
utiliser en R (notez cependant qu’il y a une sale petit bogue qui se
manifeste quand la variable indépendante peut ressemble à un nombre
plutôt qu’un facteur, ce qui explique la petite pirouette avec paste dans
mon code):
myyear &lt;- as.factor(paste(&quot;&quot;, year))
TukeyHSD(aov(fklngth ~ myyear))
Tukey multiple comparisons of means
95% family-wise confidence level
Fit: aov(formula = fklngth ~ myyear)
$myyear
diff
lwr
upr
p adj
1958- 1954 0.1872141 -3.289570 3.6639986 0.9990071
1965- 1954 -5.5076577 -10.021034 -0.9942809 0.0100528
1966- 1954 -3.3126964 -6.359223 -0.2661701 0.0274077</p>
</blockquote>
<p>1965- 1958 -5.6948718 -10.436304 -0.9534397 0.0116943
1966- 1958 -3.4999106 -6.875104 -0.1247171 0.0390011
1966- 1965 2.1949612 -2.240630 6.6305526 0.5710111
plot(TukeyHSD(aov(fklngth ~ myyear)))
Les intervalles de confiance, corrigés pour les comparaisons multiples
par la méthode de Tukey, sont illustrés pour les différences entre
années. Malheureusement les légendes ne sont pas complètes, mais
l’ordre est le même que dans le tableau précédent.
Le package multcomp peut produire de meilleurs graphiques, mais
requiert un peu plus de code:
# Alternative way to compute Tukey multiple comparisons
# set up a one-way ANOVA
anova.fkl.vs.year &lt;- aov(aov(fklngth ~ year))
# set up all-pairs comparisons for factor `year’
library(multcomp)
meandiff &lt;- glht(anova.fkl.vs.year, linfct = mcp(year =
“Tukey”))
confint(meandiff)
Simultaneous Confidence Intervals
Multiple Comparisons of Means: Tukey Contrasts</p>
<p>Fit: aov(formula = aov(fklngth ~ year))
Estimated Quantile = 2.5936
95% family-wise confidence level
Linear Hypotheses:
Estimate lwr
upr
1958 - 1954 == 0
0.1872 -3.2713
3.6457
1965 - 1954 == 0 -5.5077 -9.9973 -1.0180
1966 - 1954 == 0 -3.3127 -6.3432 -0.2822
1965 - 1958 == 0 -5.6949 -10.4114 -0.9783
1966 - 1958 == 0 -3.4999 -6.8574 -0.1424
1966 - 1965 == 0
2.1950 -2.2173
6.6073
old.par &lt;- par(mai = c(1, 1.25, 1, 1))
plot(meandiff)
par(old.par)
C’est un peu mieux, mais ce qui le serait encore plus c’est un
graphique des moyennes, avec leurs intervalles de confiance ajustés
pour les comparaisons multiples:
# Compute and plot means and Tukey CI
means &lt;- glht(anova.fkl.vs.year, linfct = mcp(year =
“Tukey”))
cimeans &lt;- cld(means)
# use sufficiently large upper margin
old.par &lt;- par(mai = c(1, 1, 1.25, 1))
# plot
plot(cimeans)
par(old.par)</p>
<p>Notez les lettres au dessus du graphique: les années étiquetées avec la
même lettre ne diffèrent pas significativement l’une de l’autre.
Transformations de données et ANOVA non-
paramétrique
Dans l’exemple précédent sur les différences annuelles de la variable
fklgnth, on a noté que les conditions d’application de l’ANOVA
n’étaient pas remplies. Si les données ne remplissent pas les conditions
de l’ANOVA paramétrique, il y a 3 options : 1) Ne rien faire. Si les
effectifs dans chaque groupe sont grands, on peut relaxer les
conditions d’application car l’ANOVA est alors assez robuste aux
violations de normalité (mais moins aux violations
d’homoscedasticité), 2) on peut transformer les données, ou 3) on
peut faire une analyse non-paramétrique.
 Refaites l’ANOVA de la section précédente après avoir transformé
en faisant le logarithme à la base de 10. Avec les données
transformées, est-ce que les problèmes qui avaient été identifiés dis-
paraissent ?
fklngth
# Fit anova model on log10 of fklngth and plot residual diagnostics
opar &lt;- par(mfrow = c(2, 2))</p>
<p>anova.model2 &lt;- lm(log10(fklngth) ~ year, data=Dam10dat)
plot(anova.model2)
par(opar)
Les graphiques diagnostiques des résidus donnent:
Les graphiques sont à peine mieux ici. Si on fait le test Wilk-Shapiro
sur les résidus, on obtient:
data: residuals(anova.model2)
W = 0.962, p-value = 0.002048
Si on refait le test de Levene sur les valeurs absolues des résidus, on
obtient:
Levene’s Test for Homogeneity of Variance
Df F value Pr(&gt;F)
group
3 2.6611 0.05148 .
114
—
Signif. codes: 0 ‘<em><strong>’ 0.001 ‘</strong>’ 0.01 ‘</em>’ 0.05 ‘.’ 0.1 ‘ ’ 1
1
Alors, on a toujours des problèmes avec la normalité et on est juste
sur le seuil de décision pour l’égalité des variances. Vous avez le choix
à ce point: 1) essayer de trouver une autre transformation pour mieux
rencontrer les conditions d’application, 2) assumer que les données
sont rencontrent suffisamment les conditions d’application, ou 3)
faire une ANOVA non-paramétrique.
 L’analogue non-paramétrique de l’ANOVA à un critère de classifica-
tion le plus employé est le test de Kruskall-Wallis. Faites ce test ( sur</p>
<p>et comparez les résultats à ceux de l’analyse paramétrique.
Que concluez-vous?
fklngth
kruskal.test(fklngth, year, data=Dam10dat)
Kruskal-Wallis rank sum test
data: fklngth and year
Kruskal-Wallis chi-squared = 15.7309, df = 3, p-value = 0.001288
La conclusion est donc la même qu’avec l’ANOVA paramétrique: on
rejette l’hypothèse nulle que le rang moyen est le même pour chaque
année. Donc, même si les conditions d’application de l’analyse
paramétrique n’étaient pas parfaitement rencontrées, les conclusions
sont les mêmes, ce qui illustre la robustesse de l’ANOVA
paramétrique.
Examen des valeurs extrêmes
Vous devriez avoir remarqué au cours des analyses précédentes qu’il y
avait peut-être des valeurs extrêmes dans les données. Ces points
étaient évidents dans le Box Plot de fklngth by year et ont été notés
comme les points 59, 23, et 87 dans les diagrammes de probabilité des
résidus et dans le diagramme de dispersion des résidus et des valeurs
estimées. En général, vous devez avoir de très bonnes raisons pour
enlever des valeurs extrêmes de la base de données (i.e. vous savez
qu’il y a eu une erreur avec un cas). Cependant, il est quand même
toujours valable de voir comment l’analyse change en enlevant des
valeurs extrêmes de la base de données.
 Répétez l’ANOVA originale sur fklngth et year mais faites le avec un
sous-ensemble de données sans les valeurs extrêmes. Est-ce que les
conclusions ont changé?
Damsubset&lt;-Dam10dat[-c(23,59,87),] #removes obs 23, 59 and
87
aov.Damsubset &lt;- aov(fklngth ~ as.factor(year), Damsubset)
summary(aov.Damsubset)
Df Sum Sq Mean Sq F value
Pr(&gt;F)
as.factor(year)
3 367.51 122.50 6.8942 0.000267 ***
Residuals
111 1972.36
17.77
—
Signif. codes: 0 ‘<em><strong>’ 0.001 ‘</strong>’ 0.01 ‘</em>’ 0.05 ‘.’ 0.1 ‘ ’ 1
shapiro.test(residuals(aov.Damsubset))
Shapiro-Wilk normality test
data: residuals(aov.Damsubset)
W = 0.9853, p-value = 0.2448</p>
<p>leveneTest(log10(fklngth) ~ year, Damsubset)
Levene’s Test for Homogeneity of Variance
Df F value Pr(&gt;F)
group
3 3.8144 0.01206 *
111
—
Signif. codes: 0 ‘<em><strong>’ 0.001 ‘</strong>’ 0.01 ‘</em>’ 0.05 ‘.’ 0.1 ‘ ’ 1
L’élimination de trois valeurs extrêmes améliore un peu les choses,
mais ce n’est pas parfait. On a toujours une problème avec les
variances, mais les résidus sont maintenant normaux. Cependant, le
fait que la conclusion qu’on tire de l’ANOVA originale ne change pas
en enlevant les points renforce le fait qu’on n’a pas une bonne raison
pour enlever les points.
Commandes R pour refaire l’ANOVA sur le sous-ensemble
de données
Damsubset&lt;-Dam10dat[-c(23,59,87),]
# removes obs 23, 59 and 87
aov.Damsubset &lt;- aov(fklngth ~ as.factor(year), Damsubset)
summary(aov.Damsubset)
shapiro.test(residuals(aov.Damsubset))
leveneTest(log10(fklngth) ~ year, Damsubset)</p>
<p>Test de permutation
Commander R pour un test de permutation d’une ANOVA
à un critère de classification.
#############################################################
# Permutation Test for one-way ANOVA
# modified from code written by David C. Howell
# <a href="http://www.uvm.edu/~dhowell/StatPages/More_Stuff/Permuta-" class="uri">http://www.uvm.edu/~dhowell/StatPages/More_Stuff/Permuta-</a>
tion%20Anova/PermTestsAnova.html
# set desired number of permutations
nreps &lt;-500
# to simplify reuse of this code, copy desired dataframe to mydata
mydata&lt;-Dam10dat
# copy model formula to myformula
myformula&lt;-as.formula(“fklngth ~ year”)
# copy dependent variable vector to mydep
mydep&lt;-mydata<span class="math inline">\(fklngth # copy independent variable vector to myindep myindep&lt;-as.factor(mydata\)</span>year)
################################################
# You should not need to modify code chunk below
################################################
# Compute observed F value for original sample
mod1 &lt;- lm(myformula, data=mydata) # Standard Anova
ANOVA &lt;- summary(aov(mod1)) # Save summary to variable
observedF&lt;- ANOVA[[1]]<span class="math inline">\(&quot;F value&quot;[1] # Save observed F value # Print standard ANOVA results cat(&quot; The standard ANOVA for these data follows &quot;, &quot;\n&quot;) print(ANOVA, &quot;\n&quot;) cat(&quot;\n&quot;) cat(&quot;\n&quot;) print(&quot;Resampling as in Manly with unrestricted sampling of obser- vations. &quot;) # Now start resampling Fboot &lt;- numeric(nreps) # initalize vector to receive permuted values Fboot[1] &lt;- observedF for (i in 2:nreps) { newdependent &lt;- sample(mydep, length(mydep)) # randomize dep var mod2 &lt;- lm(newdependent ~ myindep) # refit model b &lt;- summary(aov(mod2)) Fboot[i] &lt;- b[[1]]\)</span>“F value”[1] # store F stats
}
permprob &lt;- length(Fboot[Fboot &gt;= observedF])/nreps
cat(&quot; The permutation probability value is: “, permprob,”&quot;)
# end of code chunk for permutation</p>
<p>Version lmPerm du test de permutation.
## lmPerm version of permutation test
require(lmPerm2)
# for generality, copy desired dataframe to mydata
# and model formula to myformula
mydata&lt;-Dam10dat
myformula&lt;-as.formula(“fklngth ~ year”)
# Fit desired model on the desired dataframe
mymodel &lt;- lm(myformula, data=mydata)
# Calculate permutation p-value
anova(lmp(myformula, data=mydata, perm = “Prob”, center=FALSE,
Ca=0.001))</p>

</div>
            </section>

          </div>
        </div>
      </div>
<a href="anova-a-un-critere-de-classification.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="anova-a-criteres-multiples-plans-factoriels-et-hierarchiques.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["_main.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
