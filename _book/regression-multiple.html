<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>13 Régression multiple | BIO4558 Biostatistiques appliquées avec R</title>
  <meta name="description" content="13 Régression multiple | BIO4558 Biostatistiques appliquées avec R" />
  <meta name="generator" content="bookdown 0.13 and GitBook 2.6.7" />

  <meta property="og:title" content="13 Régression multiple | BIO4558 Biostatistiques appliquées avec R" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="13 Régression multiple | BIO4558 Biostatistiques appliquées avec R" />
  
  
  

<meta name="author" content="Julien Martin" />


<meta name="date" content="2019-09-25" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="bootstrap-1000-time-using-the-residuals-bootstraping.html"/>
<link rel="next" href="bootstrap-analysis-the-simple-way-with-library-simpleboot.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Préface</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#quelques-points-importants-a-retenir"><i class="fa fa-check"></i>Quelques points importants à retenir</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#quest-ce-que-r-et-pourquoi-lutiliser-dans-ce-cours"><i class="fa fa-check"></i>Qu’est-ce que R et pourquoi l’utiliser dans ce cours?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#installation"><i class="fa fa-check"></i>Installation</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#instructions-generales-pour-les-laboratoires"><i class="fa fa-check"></i>Instructions générales pour les laboratoires</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#et-pour-les-dilettantes-ou-ceux-qui-sont-allergiques-a-la-programmation"><i class="fa fa-check"></i>Et pour les dilettantes ou ceux qui sont allergiques à la programmation…</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introductionR.html"><a href="introductionR.html"><i class="fa fa-check"></i><b>1</b> Introduction à R</a><ul>
<li class="chapter" data-level="1.1" data-path="introductionR.html"><a href="introductionR.html#importer-et-exporter-des-donnees"><i class="fa fa-check"></i><b>1.1</b> Importer et exporter des données</a><ul>
<li class="chapter" data-level="1.1.1" data-path="introductionR.html"><a href="introductionR.html#ouvrir-et-sauvegarder-un-fichier-de-donnees-en-format-r"><i class="fa fa-check"></i><b>1.1.1</b> Ouvrir et sauvegarder un fichier de données en format R</a></li>
<li class="chapter" data-level="1.1.2" data-path="introductionR.html"><a href="introductionR.html#entrer-des-donnees"><i class="fa fa-check"></i><b>1.1.2</b> Entrer des données</a></li>
<li class="chapter" data-level="1.1.3" data-path="introductionR.html"><a href="introductionR.html#nettoyercorriger-des-donnees"><i class="fa fa-check"></i><b>1.1.3</b> Nettoyer/corriger des données</a></li>
<li class="chapter" data-level="1.1.4" data-path="introductionR.html"><a href="introductionR.html#importer-des-donnees-a-partir-dexcel."><i class="fa fa-check"></i><b>1.1.4</b> Importer des données à partir d’Excel.</a></li>
<li class="chapter" data-level="1.1.5" data-path="introductionR.html"><a href="introductionR.html#exporter-des-donnees-a-partir-de-r."><i class="fa fa-check"></i><b>1.1.5</b> Exporter des données à partir de R.</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="introductionR.html"><a href="introductionR.html#examen-preliminaire-des-donnees"><i class="fa fa-check"></i><b>1.2</b> Examen préliminaire des données</a><ul>
<li class="chapter" data-level="1.2.1" data-path="introductionR.html"><a href="introductionR.html#sommaire-statistique"><i class="fa fa-check"></i><b>1.2.1</b> Sommaire statistique</a></li>
<li class="chapter" data-level="1.2.2" data-path="introductionR.html"><a href="introductionR.html#histogramme-densite-de-probabilite-empirique-boxplot-et-examen-visuel-de-la-normalite"><i class="fa fa-check"></i><b>1.2.2</b> Histogramme, densité de probabilité empirique, boxplot et examen visuel de la normalité</a></li>
<li class="chapter" data-level="1.2.3" data-path="introductionR.html"><a href="introductionR.html#diagrammes-de-dispersion-bivaries"><i class="fa fa-check"></i><b>1.2.3</b> Diagrammes de dispersion bivariés</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="introductionR.html"><a href="introductionR.html#creer-des-sous-ensembles-de-cas"><i class="fa fa-check"></i><b>1.3</b> Créer des sous-ensembles de cas</a></li>
<li class="chapter" data-level="1.4" data-path="introductionR.html"><a href="introductionR.html#transformations-de-donnees"><i class="fa fa-check"></i><b>1.4</b> Transformations de données</a></li>
<li class="chapter" data-level="1.5" data-path="introductionR.html"><a href="introductionR.html#exercice"><i class="fa fa-check"></i><b>1.5</b> Exercice</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html"><a href="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html"><i class="fa fa-check"></i><b>2</b> Analyse de puissance avec R et G*Power ahahahaha</a><ul>
<li class="chapter" data-level="2.1" data-path="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html"><a href="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html#la-theorie"><i class="fa fa-check"></i><b>2.1</b> La théorie</a><ul>
<li class="chapter" data-level="2.1.1" data-path="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html"><a href="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html#quest-ce-que-la-puissance"><i class="fa fa-check"></i><b>2.1.1</b> Qu’est-ce que la puissance?</a></li>
<li class="chapter" data-level="2.1.2" data-path="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html"><a href="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html#pourquoi-faire-une-analyse-de-puissance"><i class="fa fa-check"></i><b>2.1.2</b> Pourquoi faire une analyse de puissance?</a></li>
<li class="chapter" data-level="2.1.3" data-path="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html"><a href="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html#facteurs-qui-affectent-la-puissance"><i class="fa fa-check"></i><b>2.1.3</b> Facteurs qui affectent la puissance</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html"><a href="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html#quest-ce-que-gpower"><i class="fa fa-check"></i><b>2.2</b> Qu’est ce que G*Power?</a></li>
<li class="chapter" data-level="2.3" data-path="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html"><a href="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html#comment-utiliser-gpower"><i class="fa fa-check"></i><b>2.3</b> Comment utiliser G*Power</a><ul>
<li class="chapter" data-level="2.3.1" data-path="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html"><a href="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html#principe-general"><i class="fa fa-check"></i><b>2.3.1</b> Principe général</a></li>
<li class="chapter" data-level="2.3.2" data-path="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html"><a href="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html#types-danalyses-de-puissance-disponibles"><i class="fa fa-check"></i><b>2.3.2</b> Types d’analyses de puissance disponibles</a></li>
<li class="chapter" data-level="2.3.3" data-path="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html"><a href="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html#comment-calculer-la-taille-de-leffet-gpower-permet-de-faire-une-analyse-de-puissance-pour-de-nombreux-tests-statistiques"><i class="fa fa-check"></i><b>2.3.3</b> Comment calculer la taille de l’effet G*Power permet de faire une analyse de puissance pour de nombreux tests statistiques</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html"><a href="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html#calculs-de-puissance-pour-un-test-de-t-comparant-deux-moyennes-independantes"><i class="fa fa-check"></i><b>2.4</b> Calculs de puissance pour un test de t comparant deux moyennes indépendantes</a><ul>
<li class="chapter" data-level="2.4.1" data-path="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html"><a href="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html#analyse-post-hoc"><i class="fa fa-check"></i><b>2.4.1</b> Analyse post-hoc</a></li>
<li class="chapter" data-level="2.4.2" data-path="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html"><a href="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html#analyse-a-priori"><i class="fa fa-check"></i><b>2.4.2</b> Analyse a priori</a></li>
<li class="chapter" data-level="2.4.3" data-path="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html"><a href="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html#analyse-de-sensitivite"><i class="fa fa-check"></i><b>2.4.3</b> Analyse de sensitivité</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html"><a href="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html#points-a-retenir"><i class="fa fa-check"></i><b>2.5</b> Points à retenir</a></li>
<li class="chapter" data-level="2.6" data-path="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html"><a href="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html#exercice-1"><i class="fa fa-check"></i><b>2.6</b> Exercice</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="correlation-et-regression-lineaire-simple.html"><a href="correlation-et-regression-lineaire-simple.html"><i class="fa fa-check"></i><b>3</b> Corrélation et régression linéaire simple</a></li>
<li class="chapter" data-level="4" data-path="comparaison-de-deux-echantillons.html"><a href="comparaison-de-deux-echantillons.html"><i class="fa fa-check"></i><b>4</b> Comparaison de deux échantillons</a></li>
<li class="chapter" data-level="5" data-path="anova-a-un-critere-de-classification.html"><a href="anova-a-un-critere-de-classification.html"><i class="fa fa-check"></i><b>5</b> ANOVA à un critère de classification</a></li>
<li class="chapter" data-level="6" data-path="but-first-save-current-par-and-set-graphic-page-to-hold-4.html"><a href="but-first-save-current-par-and-set-graphic-page-to-hold-4.html"><i class="fa fa-check"></i><b>6</b> but first, save current par and set graphic page to hold 4</a></li>
<li class="chapter" data-level="7" data-path="anova-a-criteres-multiples-plans-factoriels-et-hierarchiques.html"><a href="anova-a-criteres-multiples-plans-factoriels-et-hierarchiques.html"><i class="fa fa-check"></i><b>7</b> ANOVA à critères multiples : plans factoriels et hiérarchiques</a></li>
<li class="chapter" data-level="8" data-path="but-first-save-current-par-and-set-graphic-page-to-hold-4-1.html"><a href="but-first-save-current-par-and-set-graphic-page-to-hold-4-1.html"><i class="fa fa-check"></i><b>8</b> but first, save current par and set graphic page to hold 4</a></li>
<li class="chapter" data-level="9" data-path="fit-simplified-model.html"><a href="fit-simplified-model.html"><i class="fa fa-check"></i><b>9</b> fit simplified model</a></li>
<li class="chapter" data-level="10" data-path="modified-from-code-written-by-david-c-howell.html"><a href="modified-from-code-written-by-david-c-howell.html"><i class="fa fa-check"></i><b>10</b> modified from code written by David C. Howell</a></li>
<li class="chapter" data-level="11" data-path="httpwww-uvm-edudhowellstatpagesmore-stuffpermuta-.html"><a href="httpwww-uvm-edudhowellstatpagesmore-stuffpermuta-.html"><i class="fa fa-check"></i><b>11</b> <span>http://www.uvm.edu/~dhowell/StatPages/More_Stuff/Permuta-</span></a></li>
<li class="chapter" data-level="12" data-path="bootstrap-1000-time-using-the-residuals-bootstraping.html"><a href="bootstrap-1000-time-using-the-residuals-bootstraping.html"><i class="fa fa-check"></i><b>12</b> Bootstrap 1000 time using the residuals bootstraping</a></li>
<li class="chapter" data-level="13" data-path="regression-multiple.html"><a href="regression-multiple.html"><i class="fa fa-check"></i><b>13</b> Régression multiple</a></li>
<li class="chapter" data-level="14" data-path="bootstrap-analysis-the-simple-way-with-library-simpleboot.html"><a href="bootstrap-analysis-the-simple-way-with-library-simpleboot.html"><i class="fa fa-check"></i><b>14</b> Bootstrap analysis the simple way with library simpleboot</a></li>
<li class="chapter" data-level="15" data-path="define-model-to-be-bootstrapped-and-the-data-source-used.html"><a href="define-model-to-be-bootstrapped-and-the-data-source-used.html"><i class="fa fa-check"></i><b>15</b> Define model to be bootstrapped and the data source used</a></li>
<li class="chapter" data-level="16" data-path="ancova-et-glm.html"><a href="ancova-et-glm.html"><i class="fa fa-check"></i><b>16</b> ANCOVA et GLM</a></li>
<li class="chapter" data-level="17" data-path="analyse-de-donnees-de-frequence-tableaux-de-contingence-modeles-log-lineaires-et-regression-de-poisson.html"><a href="analyse-de-donnees-de-frequence-tableaux-de-contingence-modeles-log-lineaires-et-regression-de-poisson.html"><i class="fa fa-check"></i><b>17</b> Analyse de données de fréquence: Tableaux de contingence, modèles log-linéaires et régression de Poisson</a></li>
<li class="chapter" data-level="18" data-path="convert-case-form-to-table-form.html"><a href="convert-case-form-to-table-form.html"><i class="fa fa-check"></i><b>18</b> convert case form to table form</a></li>
<li class="chapter" data-level="19" data-path="fit-full-model.html"><a href="fit-full-model.html"><i class="fa fa-check"></i><b>19</b> Fit full model</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">BIO4558 Biostatistiques appliquées avec R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="regression-multiple" class="section level1">
<h1><span class="header-section-number">13</span> Régression multiple</h1>
<p>Après avoir complété cet exercice de laboratoire, vous devriez pouvoir
:
• Utiliser R pour ajuster une régression multiple et comparer des
modèles selon l’approche inférentielle et celle de la théorie de
l’information
• Utiliser R pour éprouver des hypothèses sur l’effet des variables
indépendantes sur la variable dépendante.
• Utiliser R pour évaluer la multicolinéarité entre les variables indé-
pendantes et en évaluer ses effets.
• Utiliser R pour effectuer une régression curvilinéaire (polyno-
miale).
Conseils généraux
Les variables qui intéressent les biologistes sont généralement
influencées par plusieurs facteurs, et une description exacte ou une
prédiction de la variable dépendante requiert que plus d’une variable
soit incluse dans le modèle. La régression multiple permet de
quantifier l’effet de plusieurs variables continues sur la variable
dépendante.
Il est important de réaliser que la maîtrise de la régression multiple ne
s’acquiert pas instantanément. Les débutants doivent garder à l’esprit
plusieurs points importants :
1. Un modèle de régression multiple peut être hautement significatif
même si aucun des termes pris isolément ne l’est (ceci est causé
par la multicolinéarité),
2. Un modèle peut ne pas être significatif alors que l’un ou plusieurs
des termes le sont (ceci est un signe d’un modèle trop complexe
(“overfitting”)) et,
3. À moins que les variables indépendantes soient parfaitement
orthogonales (c’est-à-dire qu’il n’y ait aucune corrélation entre
elles et donc pas de multicolinéarité) les diverses approches de
sélection des variables indépendantes peuvent mener à des
modèles différents.</p>
<p>Examen préliminaire des données
Le fichier Mregdat.Rdata contient des données de richesse spécifique
de quatre groupes d’organismes dans 30 marais de la région Ottawa-
Cornwall-Kingston. Les variables sont la richesse spécifique des
oiseaux ( bird , et son logarithme base 10 logbird ), des mammifères
( mammal , logmam ), des amphibiens et reptiles ( herptile , logherp ) et
celle des vertébrés ( totsp , logtot ) ; les coordonnées des sites ( lat ,
long ) ; la superficie du marais ( logarea ), le pourcentage du marais
inondé toute l’année ( swamp ) le pourcentage des terres couvertes par
des forêts dans un rayon de 1km du marais ( cpfor2 ) et la densité des
routes pavées (en m/ha) dans un rayon de 1km du marais ( thtden ).
Nous allons nous concentrer sur les amphibiens et les reptiles
(herptile) pour cet exemple, il est donc avisé d’examiner la distribution
de cette variable et les corrélations avec les variables indépendantes
potentielles:
require(car)
scatterplotMatrix(~logherp + logarea + cpfor2 + thtden +
swamp,
reg.line = lm, smooth = TRUE, span = 0.5, diagonal = “den-
sity”,
data = mydata)</p>
<p>Figure 1.
 En utilisant les données de ce fichier, faites la régression simple de
logherp
sur logarea . Que concluez-vous à partir de cette analyse?
model.loga&lt;-lm(logherp ~ logarea, data = mydata)
summary(model.loga)
Call:
lm(formula = logherp ~ logarea, data = mydata)
Residuals:
Min
1Q
-0.38082 -0.09265
Median
0.00763
3Q
0.10409
Max
0.46977
Coefficients:
Estimate Std. Error t value
(Intercept) 0.18503
0.15725
1.177
logarea
0.24736
0.06536
3.784
—
Signif. codes: 0 ‘***’ 0.001 ‘<strong>’ 0.01
Pr(&gt;|t|)
0.249996
0.000818 </strong><em>
‘</em>’ 0.05 ‘.’ 0.1 ‘ ’ 1
Residual standard error: 0.1856 on 26 degrees of freedom
(2 observations deleted due to missingness)
Multiple R-squared: 0.3552,
Adjusted R-squared: 0.3304
F-statistic: 14.32 on 1 and 26 DF, p-value: 0.0008185
opar &lt;- par(mfrow(2,2))
plot(model.loga)
opar</p>
<p>Figure 2.
Il semble donc y avoir une relation positive entre la richesse spécifique
des reptiles et des amphibiens et la surface des marais. La régression
n’explique cependant qu’environ le tiers de la variabilité (R 2 =0.355).
L’analyse des résidus indique qu’il n’y a pas de problème avec la
normalité , l’homoscédasticité, ni l’indépendance.
 Faites ensuite la régression de logherp sur cpfor2 . Que concluez-
vous?
Call:
lm(formula = logherp ~ cpfor2, data = mydata)
Residuals:
Min
1Q
-0.4909 -0.1027
Median
0.0588
3Q
0.1603
Max
0.2516
Coefficients:
Estimate Std. Error t value Pr(&gt;|t|)
(Intercept) 0.609197
0.104233
5.845 3.68e-06 ***
cpfor2
0.002706
0.001658
1.632
0.115
—
Signif. codes: 0 ‘<em><strong>’ 0.001 ‘</strong>’ 0.01 ‘</em>’ 0.05 ‘.’ 0.1 ‘ ’ 1
Residual standard error: 0.2202 on 26 degrees of freedom
(2 observations deleted due to missingness)
Multiple R-squared: 0.09289,
Adjusted R-squared: 0.058
F-statistic: 2.662 on 1 and 26 DF, p-value: 0.1148</p>
<p>Ici, on doit accepter l’hypothèse nulle et conclure qu’il n’y a pas de
relation entre la richesse spécifique dans les marais et la proportion de
forêts sur les terres adjacentes. Qu’est-ce qui arrive quand on fait une
régression avec les 2 variables indépendantes?
 Refaites la régression de logherp sur logarea et cpfor2 à la fois, soit
que logherp~logarea+cpfor2 . Que concluez-vous?
Call:
lm(formula = logherp ~ logarea + cpfor2, data = mydata)
Residuals:
Min
1Q
-0.40438 -0.11512
Median
0.01774
3Q
0.08187
Max
0.36179
Coefficients:
Estimate Std. Error t value
(Intercept) 0.027058
0.166749
0.162
logarea
0.247789
0.061603
4.022
cpfor2
0.002724
0.001318
2.067
—
Signif. codes: 0 ‘<em><strong>’ 0.001 ‘</strong>’ 0.01
Pr(&gt;|t|)
0.872398
0.000468 </em><strong>
0.049232 <em>
‘</em>’ 0.05 ‘.’ 0.1 ‘ ’ 1
Residual standard error: 0.175 on 25 degrees of freedom
(2 observations deleted due to missingness)
Multiple R-squared: 0.4493,
Adjusted R-squared: 0.4052
F-statistic: 10.2 on 2 and 25 DF, p-value: 0.0005774
Residual standard error: 0.175 on 25 degrees of freedom
Multiple R-Squared: 0.4493
F-statistic: 10.2 on 2 and 25 degrees of freedom, the p-value is 0.0005774
2 observations deleted due to missing values
On voit donc qu’on peut rejeter les 2 hypothèses nulles que la pente
de la régression de logherp sur logarea est zéro et que la pente de la
régression de logherp sur cpfor2 est zéro.
Pourquoi cpfor2 devient-il un facteur significatif dans la régression
multiple alors qu’il n’est pas significatif dans la régression simple?
Parce qu’il est parfois nécessaire de contrôler pour l’effet d’une
variable pour pouvoir détecter les effets plus subtils d’autres variables.
Ici, il y a une relation significative entre logherp et logarea qui
masque l’effet de cpfor2 sur logherp . Lorsque le modèle tient compte
des deux variables explicatives, il devient possible de détecter l’effet de
cpfor2 .
 Ajustez un autre modèle, cette fois en remplaçant cpfor2 par thtden
( Logherp~Logarea+thtden ). Que concluez-vous?
Call:
lm(formula = logherp ~ logarea + thtden, data = mydata)
Residuals:
Min
1Q
-0.31583 -0.12326
Median
0.02095
3Q
0.13201
Max
0.31674
Coefficients:
Estimate Std. Error t value Pr(&gt;|t|)
(Intercept) 0.37634
0.14926
2.521 0.018437 <em>
logarea
0.22504
0.05701
3.947 0.000567 </em></strong></p>
<p>thtden
-0.04196
0.01345 -3.118 0.004535 <strong>
—
Signif. codes: 0 ‘<em><strong>’ 0.001 ‘</strong>’ 0.01 ‘</em>’ 0.05 ‘.’ 0.1 ‘ ’ 1
Residual standard error: 0.1606 on 25 degrees of freedom
(2 observations deleted due to missingness)
Multiple R-squared: 0.5358,
Adjusted R-squared: 0.4986
F-statistic: 14.43 on 2 and 25 DF, p-value: 6.829e-05
On rejette donc l’hypothèse nulle que la richesse spécifique n’est pas
influencée par la taille des marais (logarea) ni par la densité des routes
(thtden). Notez qu’ici il y a une relation négative significative entre la
richesse spécifique des amphibiens et reptiles et la densité des routes
sur les terres adjacentes, tandis que la relation est positive pour la taille
des marais et pour la densité des forêts ( cpfor2 ; résultat de la dernière
régression).
Le R 2 de ce modèle est plus élevé que pour le précédent, reflétant une
corrélation plus forte entre logherp et thtden qu’entre logherp et
cpfor2 .
La richesse spécifique des reptiles et amphibiens semble donc reliée à
la surface de marais ( logarea ), la densité des routes ( thtden ), et
possiblement au couvert forestier sur les terres adjacentes aux marais
( cpfor2 ). Cependant, les trois variables ne sont peut-être pas
nécessaires dans un modèle prédictif. Si deux des trois variables
(disons cpfor2 et thtden ) sont parfaitement corrélées, alors l’effet de
thtden ne serait rien de plus que celui de cpfor2 (et vice-versa) et un
modèle incluant l’une des deux variables ferait des prédictions
identiques à un modèle incluant ces deux variables (en plus de
logarea ).
 Estimez un modèle de régression avec logherp comme variable dépen-
dante et logarea , cpfor2 et thtden comme variables indépendantes.
Que concluez-vous?
Call:
lm(formula = logherp ~ logarea + cpfor2 + thtden, data = mydata)
Residuals:
Min
1Q
-0.30729 -0.13779
Median
0.02627
3Q
0.11441
Max
0.29582
Coefficients:
(Intercept)
logarea Estimate Std. Error t value Pr(&gt;|t|)
0.284765
0.191420
1.488 0.149867
0.228490
0.057647
3.964 0.000578 </strong><em>
cpfor2 0.001095
0.001414
0.774 0.446516
thtden
-0.035794
0.015726 -2.276 0.032055 </em>
—
Signif. codes: 0 ‘<em><strong>’ 0.001 ‘</strong>’ 0.01 ‘</em>’ 0.05 ‘.’ 0.1 ‘ ’ 1
Residual standard error: 0.1619 on 24 degrees of freedom
(2 observations deleted due to missingness)
Multiple R-squared: 0.5471</p>
<p>,
Adjusted R-squared: 0.4904L ABO - R ÉGRESSION MULTIPLE - 129
F-statistic: 9.662 on 3 and 24 DF,
p-value: 0.0002291
Plusieurs choses sont à noter ici:
Tel que prédit, le coefficient de régression pour cpfor2 n’est plus
significativement différent de 0. Une fois que la variabilité attribuable
à logarea et thtden est enlevée, il ne reste qu’une fraction non-
significative de la variabilité attribuable à cpfor2 .
Le R 2 pour ce modèle(0.547) n’est que légèrement supérieur au R 2
du modèle avec seulement logarea et thtden (.536), ce qui confirme
que cpfor2 n’explique pas grand-chose de plus.
Notez aussi que même si le coefficient de régression pour thtden n’a
pas beaucoup changé par rapport à ce qui avait été estimé lorsque seul
thtden et logarea étaient dans le modèle (0-.036 vs -0.042), l’erreur
type pour l’estimé du coefficient est plus grand, et ce modèle plus
complexe mène à un estimé moins précis. Si la corrélation entre
thtden et cpfor2 était plus forte, la décroissance de la précision serait
encore plus grande.
On peut comparer les deux derniers modèles (i.e., le modèle incluant
les 3 variables et celui avec seulement logarea and thtden ) pour
décider lequel privilégier.
anova(model.loga.cpfor2.thtden, model.loga.thtden)
Analysis of Variance Table
Model 1: logherp ~ logarea + cpfor2 + thtden
Model 2: logherp ~ logarea + thtden
Res.Df
RSS Df Sum of Sq
F Pr(&gt;F)
1
24 0.62937
2
25 0.64508 -1 -0.01571 0.599 0.4465
Cette comparaison révèle que le modèle à 3 variables ne fait pas de
prédictions significativement meilleures que le modèle avec seulement
Logarea et thtden . Ce résultat n’est pas surprenant puisque le test de
signification pour cpfor2 dans le modèle complet indique qu’il faut
accepter l’hypothèse nulle.
À la suite de cette analyse, on doit conclure que :
1. Le meilleur modèle est celui incluant thtden et logarea .
2. Il y a une relation négative entre la richesse spécifique des amphi-
biens et reptiles et la densité des routes sur les terres adjacentes.
3. Il y a une relation positive entre la richesse spécifique et la taille
des marais.</p>
<p>Notez que le “meilleur” modèle n’est pas nécessairement le modèle
parfait, seulement le meilleur n’utilisant que ces trois variables
indépendantes. Il est évident qu’il y a d’autres facteurs qui contrôlent
la richesse spécifique dans les marais puisque, même le “meilleur”
modèle n’explique que la moitié de la variabilité.
Régression multiple pas-à-pas (stepwise)
Quand le nombre de variables prédictives est restreint, comme dans
l’exemple précédent, il est aisé de comparer manuellement les modèles
pour sélectionner le plus adéquat. Cependant, lorsque le nombre de
variables indépendantes augmente, cette approche n’est rapidement
plus utilisable et il est alors utile d’utiliser une méthode automatisée.
La sélection pas à pas avec R utilise le Critère Informatif de Akaike
(Akaike Information Criterion, AIC=n ln(RSS) + 2K où K le nombre
de variables indépendantes, n est le nombre d’observations, et RSS est
la somme des carrés des résidus) comme mesure de la qualité
d’ajustement des modèles. Cette mesure favorise la précision des
prédictions et pénalise la complexité. Lorsque l’on compare des
modèles par AIC, le modèle avec le plus petit AIC est le modèle
à préférer.
 Refaite la régression précédente ( logherp vs logarea cpfor2 et tht-
den ),
mais cette fois en utilisant la fonction stepAIC pour activer la
sélection pas à pas des variables indépendantes:
model.loga.cpfor2.thtden&lt;-lm(logherp ~ logarea + cpfor2 +
thtden, data = mydata)
# Stepwise Regression
library(MASS)
step &lt;- stepAIC(model.loga.cpfor2.thtden, direction=“both”)
step$anova # display results
Start:
AIC=-98.27
logherp ~ logarea + cpfor2 + thtden
Df Sum of Sq
- cpfor2
<none>
- thtden
- logarea
1 0.016
1
1 0.136
0.412
RSS AIC
0.645
0.629
0.765
1.041 -99.576
-98.267
-94.794
-86.167
Step: AIC=-99.58
logherp ~ logarea + thtden
Df Sum of Sq
<none>
+ cpfor2
- thtden
- logarea</p>
<p>1
1
1
0.016
0.251
0.402
RSS AIC
0.645
0.629
0.896
1.047 -99.576
-98.267
-92.376
-88.013L ABO - R ÉGRESSION MULTIPLE - 131
&gt; step<span class="math inline">\(anova # display results Stepwise Model Path Analysis of Deviance Table Initial Model: logherp ~ logarea + cpfor2 + thtden Final Model: logherp ~ logarea + thtden Step Df Deviance Resid. Df Resid. Dev AIC 1 24 0.6293717 -98.26666 2 - cpfor2 1 0.01570813 25 0.6450798 -99.57640 &gt; R nous donne:: L’ajustement (mesuré par AIC) du modèle complet en premier lieu. L’AIC des modèles dans lesquels une variable a été enlevée du modèle complet. Notez que c’est seulement en enlevant cpfor2 du modèle qu’on peut réduire l’AIC La valeur de AIC pour les modèles auxquels on enlève ou on ajoute une variable au modèle sélectionné à la première étape.(i.e. logherp ~ logarea + thtden). Notez qu’aucun des modèles n’a un AIC inférieur à ce modèle. Au lieu de débuter par le modèle complet (saturé) et enlever des termes, on peut commencer par le modèle nul et ajouter des termes: # Forward selection approach model.null&lt;-lm(logherp ~ 1, data = mydata) step &lt;- stepAIC(model.null, scope=~. + logarea + cpfor2 + thtden, direction=&quot;forward&quot;) step\)</span>anova # display results
Start: AIC=-82.09
logherp ~ 1
Df Sum of Sq
1
0.494
1
0.342
1
0.129
+ logarea
+ thtden
+ cpfor2
<none>
RSS
0.896
1.047
1.260
1.390
AIC
-92.376
-88.013
-82.820
-82.091
Step: AIC=-92.38
logherp ~ logarea
+ thtden
+ cpfor2
<none>
Df Sum of Sq
1
0.251
1
0.131
RSS
AIC
0.645 -99.576
0.765 -94.794
0.896 -92.376
Step: AIC=-99.58
logherp ~ logarea + thtden
Df Sum of Sq
<none>
+ cpfor2
1
0.016
RSS
AIC
0.645 -99.576
0.629 -98.267</p>
<blockquote>
<p>step$anova # display results
Stepwise Model Path
Analysis of Deviance Table
Initial Model:
logherp ~ 1
Final Model:
logherp ~ logarea + thtden
Step Df Deviance Resid. Df Resid. Dev
AIC
1
27 1.3895281 -82.09073
2 + logarea 1 0.4935233
26 0.8960048 -92.37639
3 + thtden 1 0.2509250
25 0.6450798 -99.57640</p>
<p>Le résultat final est le même, mais la trajectoire est différente. Dans ce
cas, R débute avec le modèle le plus simple et ajoute une variable
indépendante à chaque étape, sélectionnant la variable minimisant
AIC à cette étape. Le modèle de départ a donc seulement une
ordonnée à l’origine. Puis, logarea est ajouté, suivi de thtden. cpfor2
n’est pas ajouté au modèle, car son addition fait augmenter l’AIC.
Il est recommandé de comparer le résultat final de plusieurs
approches. Si le modèle retenu diffère selon l’approche utilisée, c’est
un signe que le “meilleur” modèle est possiblement difficile à
identifier et que vous devriez être circonspects dans vos inférences.
Dans notre exemple, pas de problème: toutes les méthodes
convergent sur le même modèle final.
Pour conclure cette section, quelques conseils concernant les
méthodes automatisées de sélection des variables indépendantes:
1. Les différentes méthodes de sélection des variables indépendantes
peuvent mener à des modèles différents. Il est souvent utile
d’essayer plus d’une méthode et de comparer les résultats. Si les
résultats diffèrent, c’est presque toujours à cause de multicolinéa-
rité entre les variables indépendantes.
2. Attention à la régression pas-à-pas. Les auteurs de SYSTAT en
disent: “Stepwise regression is probably the most abused compu-
terized statistical technique ever devised. If you think you need
automated stepwise regression to solve a particular problem, you
probably don’t. Professional statisticians rarely use automated
stepwise regression because it does not necessarily find the”best&quot;
fitting model, the “real” model, or alternative “plausible” models.
Furthermore, the order in which variables enter or leave a
stepwise program is usually of no theoretical signficance. You are
always better off thinking about why a model could generate your
data and then testing that model.” En bref, on abuse trop souvent
de cette technique.</p>
</blockquote>
<ol start="3" style="list-style-type: decimal">
<li>Il faut toujours garder à l’esprit que l’existence d’une régression
significative n’est pas suffisante pour prouver une relation causale.
Detecter la multicolinéarité
La multicolinéarité est la présence de corrélations entre les variables
indépendantes. Lorsqu’elle est extrême (multicolinéarité parfaite) elle
empêche l’estimation des modèles statistiques. Lorsqu’elle est grande
ou modérée, elle réduit la puissance de détection de l’effet des
variables indépendantes individuellement, mais elle n’empêche pas
le modèle de faire des prédictions.
Un des indices les plus utilisés pour quantifier la multicolinéarité et le
facteur d’inflation de la variance (VIF, variance inflation factor). Le
fichier d’aide du package HH explique ainsi son calcul:
“A simple diagnostic of collinearity is the variance inflation factor, VIF one for
each regression coefficient (other than the intercept). Since the condition of
collinearity involves the predictors but not the response, this measure is a function of
the X’s but not of Y. The VIF for predictor i is 1/(1-R_i^2), where R_i^2 is
the R^2 from a regression of predictor i against the remaining predictors. If R_i^2
is close to 1, this means that predictor i is well explained by a linear function of the
remaining predictors, and, therefore, the presence of predictor i in the model is
redundant. Values of VIF exceeding 5 are considered evidence of collinearity: The
information carried by a predictor having such a VIF is contained in a subset of
the remaining predictors. If, however, all of a model’s regression coefficients differ
significantly from 0 (p-value &lt; .05), a somewhat larger VIF may be tolerable.”
Bref, les VIF indiquent de combien l’incertitude de chaque coefficient
de régression est augmentée par la multicolinéarité.
Attrappe. Il y a plusieurs fonctions vif() (j’en connais au moins trois
dans les packages car, HH et DAAG), et je ne sais pas en quoi elles
diffèrent.
On peut calculer les VIF avec la fonction vif() du package car: :
require(car)
vif(model.loga.cpfor2.thtden)
logarea
cpfor2
thtden
1.022127 1.344455 1.365970
Ici, il n’y a pas d’évidence de multicolinéarité car toutes les valeurs de
VIF sont près de 1.</li>
</ol>
<p>Régression polynomiale
La régression requiert la linéarité de la relation entre les variables
dépendante et indépendante(s). Lorsque la relation n’est pas linéaire, il
est parfois possible de linéariser la relation en effectuant une
transformation sur une ou plusieurs variables. Cependant, dans bien
des cas il est impossible de transformer les axes pour rendre la relation
linéaire. On doit alors utiliser une forme ou l’autre de régression non-
linéaire.
La forme la plus simple de régression non-linéaire est la régression
polynomiale dans laquelle les variables indépendantes sont à une
puissance plus grande que 1 (Ex : X 2 ou X 3 )
 Faites un diagramme de dispersion des résidus ( residual) de la régres-
sion logherp - logarea en fonction de swamp .
Figure 3.
 L’examen de ce graphique suggère qu’il y a une forte relation entre les
deux variables, mais qu’elle n’est pas linéaire. Essayez de faire une
régression de residual sur swamp . Quelle est votre conclusion?
Call:
lm(formula = myresiduals ~ swamp, data = mydata.noNA)
Residuals:
Min
1Q
-0.350880 -0.138189</p>
<p>Median
0.003131
3Q
0.108485
Max
0.458021L ABO - R ÉGRESSION MULTIPLE - 135
Coefficients:
Estimate Std. Error t value Pr(&gt;|t|)
(Intercept) 0.084571
0.109265
0.774
0.446
swamp
-0.001145
0.001403 -0.816
0.422
Residual standard error: 0.1833 on 26 degrees of freedom
Multiple R-squared: 0.02498,
Adjusted R-squared: -0.01252
F-statistic: 0.666 on 1 and 26 DF, p-value: 0.4219
En deux mots, l’ajustement est épouvantable! Malgré le fait que le
graphique suggère une relation très forte entre les deux variables.
Cependant, cette relation n’est pas linéaire… (ce qui est également
apparent si vous examinez les résidus du modèle linéaire).
 Refaites la régression d’en haut, mais cette fois incluez un terme pour
représenter ( swamp ) 2 . L’expression devrait apparaître comme: residu-
als~SWAMP+SWAMP^2 . Que concluez-vous? Qu’est-ce que l’examen des
résidus de cette régression multiple révèle?
Call:
lm(formula = myresiduals ~ swamp + I(swamp^2), data = mydata.noNA)
Residuals:
Min
1Q
-0.181185 -0.085350
Median
0.007377
3Q
0.067327
Max
0.242455
Coefficients:
Estimate Std. Error t value Pr(&gt;|t|)
(Intercept) -7.804e-01 1.569e-01 -4.975 3.97e-05 <strong><em>
swamp
3.398e-02 5.767e-03
5.892 3.79e-06 </em></strong>
I(swamp^2) -2.852e-04 4.624e-05 -6.166 1.90e-06 ***
—
Signif. codes: 0 ‘<em><strong>’ 0.001 ‘</strong>’ 0.01 ‘</em>’ 0.05 ‘.’ 0.1 ‘ ’ 1
Residual standard error: 0.1177 on 25 degrees of freedom
Multiple R-squared: 0.6132,
Adjusted R-squared: 0.5823
F-statistic: 19.82 on 2 and 25 DF, p-value: 6.972e-06
Il devient évident que si on corrige la richesse spécifique pour la taille
des marais, une fraction importante de la variabilité résiduelle peut
être associée à swamp , selon une relation quadratique. Si vous examinez
les résidus, vous observerez que l’ajustement est nettement meilleur
qu’avec le modèle linéaire.
 En vous basant sur les résultats de la dernière analyse, comment sug-
gérez-vous de modifier le modèle de régression multiple? Quel est,
d’après vous, le meilleur modèle? Pourquoi? Ordonnez les différents
facteurs en ordre croissant de leur effet sur la richesse spécifique des
reptiles.
Suite à ces analyses, il semble opportun d’essayer d’ajuster un modèle
incluant logarea, thtden, cpfor2, swamp et swamp^2 :
Call:
lm(formula = logherp ~ logarea + cpfor2 + thtden + swamp + I(swamp^2),
data = mydata)</p>
<p>Residuals:
Min
1Q
Median
-0.201797 -0.056170 -0.002072
3Q
0.051814
Max
0.205626
Coefficients:
Estimate Std. Error t value Pr(&gt;|t|)
(Intercept) -3.203e-01 1.813e-01 -1.766
0.0912 .
logarea
2.202e-01 3.893e-02
5.656 1.09e-05 <strong><em>
cpfor2
-7.864e-04 9.955e-04 -0.790
0.4380
thtden
-2.929e-02 1.048e-02 -2.795
0.0106 </em>
swamp
3.113e-02 5.898e-03
5.277 2.70e-05 </strong><em>
I(swamp^2) -2.618e-04 4.727e-05 -5.538 1.45e-05 </em><strong>
—
Signif. codes: 0 ‘<em><strong>’ 0.001 ‘</strong>’ 0.01 ‘</em>’ 0.05 ‘.’ 0.1 ‘ ’ 1
Residual standard error: 0.1072 on 22 degrees of freedom
(2 observations deleted due to missingness)
Multiple R-squared: 0.8181,
Adjusted R-squared: 0.7767
F-statistic: 19.78 on 5 and 22 DF, p-value: 1.774e-07
he p-value is 1.774e-007
2 observations deleted due to missing values
Les résultats de cette analyse suggèrent qu’on devrait probablement
exclure cpfor2 du modèle:
Call:
lm(formula = logherp ~ logarea + thtden + swamp + I(swamp^2),
data = mydata)
Residuals:
Min
1Q
Median
-0.19621 -0.05444 -0.01202
3Q
0.07116
Max
0.21295
Coefficients:
Estimate Std. Error t value Pr(&gt;|t|)
(Intercept) -3.461e-01 1.769e-01 -1.957
0.0626 .
logarea
2.232e-01 3.842e-02
5.810 6.40e-06 </strong><em>
thtden
-2.570e-02 9.364e-03 -2.744
0.0116 </em>
swamp
2.956e-02 5.510e-03
5.365 1.89e-05 <strong><em>
I(swamp^2) -2.491e-04 4.409e-05 -5.649 9.46e-06 </em></strong>
—
Signif. codes: 0 ‘<em><strong>’ 0.001 ‘</strong>’ 0.01 ‘</em>’ 0.05 ‘.’ 0.1 ‘ ’ 1
Residual standard error: 0.1063 on 23 degrees of freedom
(2 observations deleted due to missingness)
Multiple R-squared: 0.8129,
Adjusted R-squared: 0.7804
F-statistic: 24.98 on 4 and 23 DF, p-value: 4.405e-08
Est-ce qu’il y a possiblement un problème de multicolinéarité?
&gt; vif(model.polynomial.reduced)
logarea
thtden
swamp I(swamp^2)
1.053193
1.123491 45.845845 45.656453
Les valeurs d’inflation de la variance (VIF) pour les deux termes de
swamp sont beaucoup plus élevés que le seuil de 5. Cependant, c’est la
norme pour les termes polynomiaux et on ne doit pas s’en préoccuper
outre mesure, surtout quand les deux termes sont hautement
significatifs dans le modèle. Les fortes valeurs de VIF indiquent que
les coefficients pour ces deux termes ne sont pas estimés précisément,
mais leur utilisation dans le modèle permet tout de même de faire de
bonnes prédictions (i.e. ils décrivent la réponse à swamp).</p>
<p>Vérifier les conditions d’application de
modèles de régression multiple
Toutes les techniques de sélection des modèles présument que les
conditions d’applications (indépendance, normalité, homoscédasticité,
linéarité) sont remplies. Comme il y a un grand nombre de modèles
qui peuvent être ajustés, il peut paraître quasi impossible de vérifier si
les conditions sont remplies à chaque étape de construction.
Cependant, il est souvent suffisant d’examiner les résidus du modèle
complet (saturé) puis du modèle final. Les termes qui ne contribuent
pas significativement à l’ajustement n’affectent pas beaucoup les
résidus et donc les résidus du modèle final sont généralement
similaires à ceux du modèle complet.
Examinons donc les graphiques diagnostiques du modèle final:
Figure 4.
Tout semble acceptable dans ce cas. Pour convaincre les sceptiques,
on peut faire les tests formels des conditions d’application:
shapiro.test(residuals(model.polynomial.reduced))
Shapiro-Wilk normality test
data: residuals(model.polynomial.reduced)
W = 0.9837, p-value = 0.9278
Les résidus ne dévient pas significativement de la normalité. Bien. &gt;
&gt; #Homoscedasticity
&gt; #Homoscedasticity</p>
<blockquote>
<p>bptest(model.polynomial.reduced)
studentized Breusch-Pagan test
data: model.polynomial.reduced
BP = 3.8415, df = 4, p-value = 0.4279
Pas de déviation d’homoscédasticité non plus. Bien.
#Serial autocorrelation
dwtest(model.polynomial.reduced)
Durbin-Watson test
data: model.polynomial.reduced
DW = 1.725, p-value = 0.2095
alternative hypothesis: true autocorrelation is greater than 0
Pas de corrélation sérielle des résidus, donc pas d’évidence de non-
indépendance.
#Linearity
resettest(model.polynomial.reduced, type = “regressor”, data = mydata)
RESET test
data: model.polynomial.reduced
RESET = 0.9823, df1 = 8, df2 = 15, p-value = 0.4859
Et finalement, pas de déviation significative de normalité. Donc tout
semble acceptable.
Visualiser la taille d’effet
Les coefficients de la régression multiple peuvent mesurer la taille
d’effet, quoiqu’il puisse être nécessaire de les standardiser pour qu’ils
ne soient pas influencés par les unités de mesure. Mais un graphique
est souvent plus informatif. Dans ce contexte, les graphiques des
résidus partiels (appelés components+residual plots dans R) sont
particulièrement utiles. Ces graphique illustrent comment la variable
dépendante, corrigée pour l’effet des autres variables dans le modèle,
varie avec chacune des variables indépendantes du modèle. Voyons
voir:
# Evaluate visually linearity and effect size
# component + residual plot
cr.plots(model.polynomial.reduced, one.page=TRUE, ask=FALSE)</p>
</blockquote>
<p>Figure 5.
Notez que l’échelle de l’axe des y varie sur chaque graphique. Pour
thtden, la variable dépendante (log10(richesse des herptiles)) varie
d’environ 0.4 unités entre la valeur minimum et maximum de thtden.
Pour logarea, la variation est d’environ 0.6 unité log. Pour swamp,
l’interprétation est plus compliquée parce qu’il y a deux termes qui
quantifient son effet, et que ces termes ont des signes opposés (positif
pour swamp et négatif pour swamp^2) ce qui donne une relation
curvilinéaire de type parabole. Le graphique ne permet pas de bien
visualiser cela. Ceci dit, ces graphique n’indiquent pas vraiment de
violation de linéarité.
Pour illustrer ce qui serait visible sur ces graphiques si il y avait une
déviation de linéarité, enlevons le terme du second degré pour swamp,
puis on va refaire ces graphiques et effectuer le test RESET.</p>
<p>Figure 6.
La relation non-linéaire avec swamp devient évidente. Et le test
RESET détecte bien cette non-linéarité:
RESET test
data: g
RESET = 6.7588, df1 = 6, df2 = 18, p-value = 0.0007066
Tester la présence d’interactions
Lorsqu’il y a plusieurs variables indépendantes, vous devriez toujours
garder à l’esprit la possibilité d’interactions. Dans la majorité des
situations de régression multiple cela n’est pas évident parce que
l’addition de termes d’interaction augmente la multicolinéarité des
termes du modèle, et parce qu’il n’y a souvent pas assez
d’observations pour éprouver toutes les interactions ou que les
observations ne sont pas suffisamment balancées pour faire des tests
puissants pour les interactions.
Retournons à notre modèle “final” et voyons ce qui se passe si on
essaie d’ajuster un modèle saturé avec toutes les interactions:
fullmodel.withinteractions&lt;-lm(logherp ~ logarea * cpfor2 <em>
thtden </em> swamp * I(swamp^2), data= Mregdat)
summary(fullmodel.withinteractions)</p>
<p>Call:
lm(formula = logherp ~ logarea * cpfor2 * thtden * swamp * I(swamp^2),
data = Mregdat)
Residuals:
ALL 28 residuals are 0: no residual degrees of freedom!
Coefficients: (4 not defined because of singularities)
Estimate Std. Error t value Pr(&gt;|t|)
(Intercept)
-5.948e+03
NA
NA
NA
logarea
3.293e+03
NA
NA
NA
cpfor2
7.080e+01
NA
NA
NA
thtden
9.223e+02
NA
NA
NA
swamp
1.176e+02
NA
NA
NA
I(swamp<sup>2)
-3.517e-01
NA
NA
NA
logarea:cpfor2
-3.771e+01
NA
NA
NA
logarea:thtden
-4.781e+02
NA
NA
NA
cpfor2:thtden
-1.115e+01
NA
NA
NA
logarea:swamp
-7.876e+01
NA
NA
NA
cpfor2:swamp
-1.401e+00
NA
NA
NA
thtden:swamp
-1.920e+01
NA
NA
NA
logarea:I(swamp</sup>2)
5.105e-01
NA
NA
NA
cpfor2:I(swamp<sup>2)
3.825e-03
NA
NA
NA
thtden:I(swamp</sup>2)
7.826e-02
NA
NA
NA
swamp:I(swamp<sup>2)
-2.455e-03
NA
NA
NA
logarea:cpfor2:thtden
5.359e+00
NA
NA
NA
logarea:cpfor2:swamp
8.743e-01
NA
NA
NA
logarea:thtden:swamp
1.080e+01
NA
NA
NA
cpfor2:thtden:swamp
2.620e-01
NA
NA
NA
logarea:cpfor2:I(swamp</sup>2)
-5.065e-03
NA
NA
NA
logarea:thtden:I(swamp<sup>2)
-6.125e-02
NA
NA
NA
cpfor2:thtden:I(swamp</sup>2)
-1.551e-03
NA
NA
NA
logarea:swamp:I(swamp<sup>2)
-4.640e-04
NA
NA
NA
cpfor2:swamp:I(swamp</sup>2)
3.352e-05
NA
NA
NA
thtden:swamp:I(swamp<sup>2)
2.439e-04
NA
NA
NA
logarea:cpfor2:thtden:swamp
-1.235e-01
NA
NA
NA
logarea:cpfor2:thtden:I(swamp</sup>2)
7.166e-04
NA
NA
NA
logarea:cpfor2:swamp:I(swamp<sup>2)
NA
NA
NA
NA
logarea:thtden:swamp:I(swamp</sup>2)
NA
NA
NA
NA
cpfor2:thtden:swamp:I(swamp<sup>2)
NA
NA
NA
NA
logarea:cpfor2:thtden:swamp:I(swamp</sup>2)
NA
NA
NA
NA
Residual standard error: NaN on 0 degrees of freedom
(2 observations deleted due to missingness)
Multiple R-squared:
1,
Adjusted R-squared:
F-statistic:
NaN on 27 and 0 DF, p-value: NA
NaN
Notez les coefficients manquants aux dernières lignes: on ne peut
inclure les 32 termes si on a seulement 28 observations. Il manque des
observations, le R carré est 1, et le modèle “prédit” parfaitement les
données.
Si on essaie une méthode automatique pour identifier le “meilleur”
modèle dans ce gâchis, R refuse:
step(fullmodel.withinteractions)
Error in step(fullmodel.withinteractions) :
AIC is -infinity for this model, so ‘step’ cannot proceed
Bon, est-ce qu’on oublie tout ça et qu’on accepte le modèle final sans
ce soucier des interactions? Non, pas encore. Il y a un compromis
possible: comparer notre modèle “final” à un modèle qui contient au
moins un sous-ensemble des interactions, par exemple toutes les
interactions du second degré, pour éprouver si l’addition de ces
interactions améliore beaucoup l’ajustement du modèle.</p>
<p>full.model.2ndinteractions&lt;- lm(logherp ~ logarea + cpfor2 +
thtden + swamp + I(swamp^2)
+ logarea:cpfor2 + logarea:thtden + logarea:swamp
+ cpfor2:thtden + cpfor2:swamp
+ thtden:swamp
, data= mydata)
summary(full.model.2ndinteractions)
Call:
lm(formula = logherp ~ logarea + cpfor2 + thtden + swamp + I(swamp^2) +
logarea:cpfor2 + logarea:thtden + logarea:swamp + cpfor2:thtden +
cpfor2:swamp + thtden:swamp, data = mydata)
Residuals:
Min
1Q
-0.216880 -0.036534
Median
0.003506
3Q
0.042990
Max
0.175490
Coefficients:
(Intercept)
logarea
cpfor2
thtden
swamp
I(swamp^2)
logarea:cpfor2
logarea:thtden
logarea:swamp
cpfor2:thtden
cpfor2:swamp
thtden:swamp
—
Signif. codes:
Estimate Std. Error t value Pr(&gt;|t|)
4.339e-01 6.325e-01
0.686 0.502581
-1.254e-01 2.684e-01 -0.467 0.646654
-9.344e-03 7.205e-03 -1.297 0.213032
-1.833e-01 9.035e-02 -2.028 0.059504 .
3.569e-02 7.861e-03
4.540 0.000334 <strong><em>
-3.090e-04 7.109e-05 -4.347 0.000500 </em></strong>
2.582e-03 2.577e-03
1.002 0.331132
7.017e-02 3.359e-02
2.089 0.053036 .
-5.290e-04 2.249e-03 -0.235 0.816981
-2.095e-04 6.120e-04 -0.342 0.736544
4.651e-05 5.431e-05
0.856 0.404390
2.248e-04 4.764e-04
0.472 0.643336
0 ‘<em><strong>’ 0.001 ‘</strong>’ 0.01 ‘</em>’ 0.05 ‘.’ 0.1 ‘ ’ 1
Residual standard error: 0.108 on 16 degrees of freedom
(2 observations deleted due to missingness)
Multiple R-squared: 0.8658,
Adjusted R-squared: 0.7735
F-statistic: 9.382 on 11 and 16 DF, p-value: 4.829e-05
Ce modèle s’ajuste un peu mieux aux données que les modèle “final”
(il explique 86.6% de la variance de logherp, comparé à 81.2% pour le
modèle “final” sans interactions), mais il compte deux fois plus de
paramètres. De plus, si vous examinez les coefficients, il se passe
d’étranges choses: le signe pour logare a changé par exemple. C’est un
des symptômes de la multicolinéarité. Allons voir les facteurs
d’inflation de la variance:
vif(full.model.2ndinteractions)
logarea
cpfor2
49.86060
78.49622
logarea:cpfor2 logarea:thtden
66.97792
71.69894
thtden:swamp
20.04410
thtden
101.42437
logarea:swamp
67.27034
swamp
90.47389
cpfor2:thtden
14.66814
I(swamp^2)
115.08457
cpfor2:swamp
29.41422
Aie! tous les VIF sont plus grands que 5, pas seulement les termes
incluant swamp. Cette forte multicolinéarité empêche de quantifier
avec précision l’effet de ces interactions.
De plus, ce modèle avec interactions n’est pas plus informatif que le
modèle “final” puisque son AIC est plus élevé (souvenez-vous qu’on
privilégie le modèle avec la valeur d’AIC la plus basse):</p>
<blockquote>
<p>AIC(full.model)
[1] -38.3433
AIC(full.model.2ndinteractions)
[1] -34.86123
On peut également utiliser la fonction anova() pour comparer
l’ajustement des deux modèles et vérifier si l’addition des termes
d’intération améliore significativement l’ajustement:
anova(full.model, full.model.2ndinteractions)
Analysis of Variance Table
Model 1: logherp ~ logarea + cpfor2 + thtden + swamp + I(swamp^2)
Model 2: logherp ~ logarea + cpfor2 + thtden + swamp + I(swamp^2) + loga-
rea:cpfor2 +
logarea:thtden + logarea:swamp + cpfor2:thtden + cpfor2:swamp +
thtden:swamp
Res.Df
RSS Df Sum of Sq
F Pr(&gt;F)
1
22 0.252820
2
16 0.186507 6 0.066314 0.9481 0.489
Ici, l’addition des termes d’interaction ne réduit pas significativement
la variabilité résiduelle du modèle “complet”. Qu’en est-il de la si on
compare le modèle avec interaction et notre modèle “final”?
anova(model.polynomial.reduced, full.model.2ndinteractions)
Analysis of Variance Table
Model 1: logherp ~ logarea + thtden + swamp + I(swamp^2)
Model 2: logherp ~ logarea + cpfor2 + thtden + swamp + I(swamp^2) + loga-
rea:cpfor2 +
logarea:thtden + logarea:swamp + cpfor2:thtden + cpfor2:swamp +
thtden:swamp
Res.Df
RSS Df Sum of Sq
F Pr(&gt;F)
1
23 0.259992
2
16 0.186507 7 0.073486 0.9006 0.5294
Le test indique que ces deux modèles ont des variances résiduelles
comparables, et donc que l’addition des termes d’interaction et de
cpfor2 au modèle final n’apporte pas grand chose.
Recherche du meilleur modèle fondée sur la
théorie de l’information
Une des principales critiques des méthodes pas-à-pas (stepwise) est
que les p-valeurs ne sont pas strictement interprétables à cause du
grand nombre de tests qui sont implicites dans le processus. C’est le
problème des comparaisons ou tests multiples: en construisant un
modèle linéaire (comme une régression multiple) à partir d’un grand
nombre de variables et de leurs interactions, il y a tellement de
combinaisons possibles qu’un ajustement de Bonferroni rendrait les
tests trop conservateurs.
Une alternative, élégamment défendue par Burnham et Anderson
(2002, Model selection and multimodel inference: a practical
information-theoretic approach. 2nd ed), est d’utiliser l’AIC (ou</p>
</blockquote>
<p>mieux encore AICc qui est plus approprié quand le nombre
d’observations est inférieur à 40 fois le nombre de variables
indépendantes) pour ordonner les modèles et identifier un sous-
ensemble de modèles qui sont les meilleurs. On peut ensuite calculer
les moyennes des coefficients pondérées par la probabilité que
chacun des modèles soit le meilleur pour obtenir des coefficients qui
sont plus robustes et moins sensibles à la multicolinéarité.
Cette approche a été suivie dans le package MuMIn.
library(MuMIn)
dd &lt;- dredge(full.model.2ndinteractions)
L’objet dd contient tous les modèles possibles (i.e. ceux qui ont toutes
les combinaisons possibles) en utilisant les termes du modèle
full.model.2ndinteractions ajusté précédemment.
On peut ensuite extraire de l’objet dd le sous-ensemble de modèles
qui ont un AICc semblable au meilleur modèle (Burnham et
Anderson suggèrent que les modèles qui dévient par plus de 4 unités
d’AICc du meilleur modèle ont peu de support.empirique)
# get models within 4 units of AICc from the best model
top.models.1 &lt;- get.models(dd, subset = delta &lt; 4)
avgmodel1&lt;-model.avg(top.models.1) # compute average parame-
ters
summary(avgmodel1) #display averaged model
confint(avgmodel1) #display CI for averaged coefficients
Call:
model.avg.default(object = top.models.1)

Component models:
df logLik
23457
2345
123457
234578
12345
23458
234567
23456
7
6
8
8
7
7
8
7
27.78
25.78
28.30
28.26
26.17
26.06
27.88
25.79
AICc Delta Weight
-35.95
-35.56
-33.02
-32.95
-32.74
-32.51
-32.17
-31.99
0.00
0.39
2.93
3.00
3.21
3.44
3.78
3.97
Term codes:
cpfor2
I(swamp^2)
1
2
logarea:swamp logarea:thtden
6
7
Averaged model parameters:


0.34
0.28
0.08
0.08
0.07
0.06
0.05
0.05
logarea
3
swamp:thtden
8
swamp
4
thtden
5
Coefficient Variance
SE Unconditional SE Lower CI
Model-averaged coefficients:
Estimate Std. Error Adjusted SE z value Pr(&gt;|z|)
(Intercept)
-2.075e-01 2.484e-01
2.593e-01
0.800
0.4236
logarea
1.314e-01 1.185e-01
1.222e-01
1.076
0.2820
swamp
3.193e-02 6.125e-03
6.438e-03
4.960
7e-07 <strong><em>
I(swamp^2)
-2.676e-04 4.904e-05
5.154e-05
5.193
2e-07 </em></strong>
thtden
-6.843e-02 5.324e-02
5.459e-02
1.254
0.2100
logarea:thtden 3.924e-02 2.125e-02
2.251e-02
1.743
0.0813 .</p>
<p>cpfor2
-8.187e-04 9.692e-04
1.027e-03
0.797
swamp:thtden
-2.402e-04 3.127e-04
3.313e-04
0.725
logarea:swamp
4.462e-04 1.664e-03
1.762e-03
0.253
—
Signif. codes: 0 ‘<em><strong>’ 0.001 ‘</strong>’ 0.01 ‘</em>’ 0.05 ‘.’ 0.1 ‘
0.4253
0.4684
0.8001
’ 1
Full model-averaged coefficients (with shrinkage):
(Intercept)
logarea
swamp I(swamp^2)
thtden logarea:thtden
-2.0751e-01 1.3143e-01 3.1935e-02 -2.6765e-04 -6.8432e-02
2.1388e-02
cpfor2 swamp:thtden logarea:swamp
-1.2017e-04 -3.2771e-05
4.3777e-05
Relative variable importance:
I(swamp<sup>2)
logarea
1.00
1.00
cpfor2
swamp:thtden
0.15
0.14
(Intercept)
logarea
swamp
I(swamp</sup>2)
thtden
logarea:thtden
cpfor2
swamp:thtden
logarea:swamp
swamp
1.00
logarea:swamp
0.10
thtden logarea:thtden
1.00
0.55
2.5 %
97.5 %
-0.7157333646 0.3007147516
-0.1080048582 0.3708612563
0.0193158426 0.0445532538
-0.0003686653 -0.0001666418
-0.1754184849 0.0385545120
-0.0048800385 0.0833595106
-0.0028313465 0.0011940283
-0.0008894138 0.0004090457
-0.0030067733 0.0038991294
 La liste des modèles qui sont à 4 unités ou moins de l’AICc du
meilleur modèle. Les variables dans chaque modèle sont codées et on
retrouve la clé en dessous du tableau.
 Pour chaque modèle, en plus de l’AICc, le poids Akaike est
calculé. C’est un estimé de la probabilité que ce modèle est le meilleur.
Ici on voit que le premier modèle (le meilleur) a seulement 34% des
chance d’être vraiment le meilleur.
 À partir de ce sous-ensemble de modèles, la moyenne pondérée
des coefficients (en utilisant les poids Akaike) est calculée, avec in IC à
95%. Notez que les termes absents d’un modèle sont considérés avoir
un coefficient de 0 pour ce terme.
Bootstrapping multiple regression
Quand les données ne rencontrent pas les conditions d’application de
normalité et d’homoscédasticité et que les transformations n’arrivent
pas à corriger ces violations, le bootstrap peut être utilisé pour calculer
des intervalles de confiance pour les coefficients. Si la distribution des
coefficients bootstrappés est symétrique et approximativement
normale, on peut utiliser les percentiles empiriques pour calculer les
limites de confiance.
Le code qui suit, utilisant le package simpleboot, a été conçu pour être
facilement modifiable et calcule les limites des IC à partir des
percentiles empiriques.</p>
<div id="section" class="section level60">
<p><span class="header-section-number">13.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.1</span> </p>
</div>
<div id="section-1" class="section level7">
<p><span class="header-section-number">13.0.0.0.0.0.1</span> </p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="bootstrap-1000-time-using-the-residuals-bootstraping.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="bootstrap-analysis-the-simple-way-with-library-simpleboot.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["_main.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
