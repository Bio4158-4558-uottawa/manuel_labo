<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3 Corrélation et régression linéaire simple | BIO4558 Biostatistiques appliquées avec R</title>
  <meta name="description" content="3 Corrélation et régression linéaire simple | BIO4558 Biostatistiques appliquées avec R" />
  <meta name="generator" content="bookdown 0.13 and GitBook 2.6.7" />

  <meta property="og:title" content="3 Corrélation et régression linéaire simple | BIO4558 Biostatistiques appliquées avec R" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3 Corrélation et régression linéaire simple | BIO4558 Biostatistiques appliquées avec R" />
  
  
  

<meta name="author" content="Julien Martin" />


<meta name="date" content="2019-09-25" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html"/>
<link rel="next" href="comparaison-de-deux-echantillons.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Préface</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#quelques-points-importants-a-retenir"><i class="fa fa-check"></i>Quelques points importants à retenir</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#quest-ce-que-r-et-pourquoi-lutiliser-dans-ce-cours"><i class="fa fa-check"></i>Qu’est-ce que R et pourquoi l’utiliser dans ce cours?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#installation"><i class="fa fa-check"></i>Installation</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#instructions-generales-pour-les-laboratoires"><i class="fa fa-check"></i>Instructions générales pour les laboratoires</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#et-pour-les-dilettantes-ou-ceux-qui-sont-allergiques-a-la-programmation"><i class="fa fa-check"></i>Et pour les dilettantes ou ceux qui sont allergiques à la programmation…</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introductionR.html"><a href="introductionR.html"><i class="fa fa-check"></i><b>1</b> Introduction à R</a><ul>
<li class="chapter" data-level="1.1" data-path="introductionR.html"><a href="introductionR.html#importer-et-exporter-des-donnees"><i class="fa fa-check"></i><b>1.1</b> Importer et exporter des données</a><ul>
<li class="chapter" data-level="1.1.1" data-path="introductionR.html"><a href="introductionR.html#ouvrir-et-sauvegarder-un-fichier-de-donnees-en-format-r"><i class="fa fa-check"></i><b>1.1.1</b> Ouvrir et sauvegarder un fichier de données en format R</a></li>
<li class="chapter" data-level="1.1.2" data-path="introductionR.html"><a href="introductionR.html#entrer-des-donnees"><i class="fa fa-check"></i><b>1.1.2</b> Entrer des données</a></li>
<li class="chapter" data-level="1.1.3" data-path="introductionR.html"><a href="introductionR.html#nettoyercorriger-des-donnees"><i class="fa fa-check"></i><b>1.1.3</b> Nettoyer/corriger des données</a></li>
<li class="chapter" data-level="1.1.4" data-path="introductionR.html"><a href="introductionR.html#importer-des-donnees-a-partir-dexcel."><i class="fa fa-check"></i><b>1.1.4</b> Importer des données à partir d’Excel.</a></li>
<li class="chapter" data-level="1.1.5" data-path="introductionR.html"><a href="introductionR.html#exporter-des-donnees-a-partir-de-r."><i class="fa fa-check"></i><b>1.1.5</b> Exporter des données à partir de R.</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="introductionR.html"><a href="introductionR.html#examen-preliminaire-des-donnees"><i class="fa fa-check"></i><b>1.2</b> Examen préliminaire des données</a><ul>
<li class="chapter" data-level="1.2.1" data-path="introductionR.html"><a href="introductionR.html#sommaire-statistique"><i class="fa fa-check"></i><b>1.2.1</b> Sommaire statistique</a></li>
<li class="chapter" data-level="1.2.2" data-path="introductionR.html"><a href="introductionR.html#histogramme-densite-de-probabilite-empirique-boxplot-et-examen-visuel-de-la-normalite"><i class="fa fa-check"></i><b>1.2.2</b> Histogramme, densité de probabilité empirique, boxplot et examen visuel de la normalité</a></li>
<li class="chapter" data-level="1.2.3" data-path="introductionR.html"><a href="introductionR.html#diagrammes-de-dispersion-bivaries"><i class="fa fa-check"></i><b>1.2.3</b> Diagrammes de dispersion bivariés</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="introductionR.html"><a href="introductionR.html#creer-des-sous-ensembles-de-cas"><i class="fa fa-check"></i><b>1.3</b> Créer des sous-ensembles de cas</a></li>
<li class="chapter" data-level="1.4" data-path="introductionR.html"><a href="introductionR.html#transformations-de-donnees"><i class="fa fa-check"></i><b>1.4</b> Transformations de données</a></li>
<li class="chapter" data-level="1.5" data-path="introductionR.html"><a href="introductionR.html#exercice"><i class="fa fa-check"></i><b>1.5</b> Exercice</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html"><a href="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html"><i class="fa fa-check"></i><b>2</b> Analyse de puissance avec R et G*Power ahahahaha</a><ul>
<li class="chapter" data-level="2.1" data-path="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html"><a href="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html#la-theorie"><i class="fa fa-check"></i><b>2.1</b> La théorie</a><ul>
<li class="chapter" data-level="2.1.1" data-path="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html"><a href="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html#quest-ce-que-la-puissance"><i class="fa fa-check"></i><b>2.1.1</b> Qu’est-ce que la puissance?</a></li>
<li class="chapter" data-level="2.1.2" data-path="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html"><a href="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html#pourquoi-faire-une-analyse-de-puissance"><i class="fa fa-check"></i><b>2.1.2</b> Pourquoi faire une analyse de puissance?</a></li>
<li class="chapter" data-level="2.1.3" data-path="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html"><a href="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html#facteurs-qui-affectent-la-puissance"><i class="fa fa-check"></i><b>2.1.3</b> Facteurs qui affectent la puissance</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html"><a href="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html#quest-ce-que-gpower"><i class="fa fa-check"></i><b>2.2</b> Qu’est ce que G*Power?</a></li>
<li class="chapter" data-level="2.3" data-path="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html"><a href="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html#comment-utiliser-gpower"><i class="fa fa-check"></i><b>2.3</b> Comment utiliser G*Power</a><ul>
<li class="chapter" data-level="2.3.1" data-path="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html"><a href="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html#principe-general"><i class="fa fa-check"></i><b>2.3.1</b> Principe général</a></li>
<li class="chapter" data-level="2.3.2" data-path="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html"><a href="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html#types-danalyses-de-puissance-disponibles"><i class="fa fa-check"></i><b>2.3.2</b> Types d’analyses de puissance disponibles</a></li>
<li class="chapter" data-level="2.3.3" data-path="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html"><a href="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html#comment-calculer-la-taille-de-leffet-gpower-permet-de-faire-une-analyse-de-puissance-pour-de-nombreux-tests-statistiques"><i class="fa fa-check"></i><b>2.3.3</b> Comment calculer la taille de l’effet G*Power permet de faire une analyse de puissance pour de nombreux tests statistiques</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html"><a href="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html#calculs-de-puissance-pour-un-test-de-t-comparant-deux-moyennes-independantes"><i class="fa fa-check"></i><b>2.4</b> Calculs de puissance pour un test de t comparant deux moyennes indépendantes</a><ul>
<li class="chapter" data-level="2.4.1" data-path="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html"><a href="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html#analyse-post-hoc"><i class="fa fa-check"></i><b>2.4.1</b> Analyse post-hoc</a></li>
<li class="chapter" data-level="2.4.2" data-path="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html"><a href="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html#analyse-a-priori"><i class="fa fa-check"></i><b>2.4.2</b> Analyse a priori</a></li>
<li class="chapter" data-level="2.4.3" data-path="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html"><a href="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html#analyse-de-sensitivite"><i class="fa fa-check"></i><b>2.4.3</b> Analyse de sensitivité</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html"><a href="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html#points-a-retenir"><i class="fa fa-check"></i><b>2.5</b> Points à retenir</a></li>
<li class="chapter" data-level="2.6" data-path="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html"><a href="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html#exercice-1"><i class="fa fa-check"></i><b>2.6</b> Exercice</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="correlation-et-regression-lineaire-simple.html"><a href="correlation-et-regression-lineaire-simple.html"><i class="fa fa-check"></i><b>3</b> Corrélation et régression linéaire simple</a></li>
<li class="chapter" data-level="4" data-path="comparaison-de-deux-echantillons.html"><a href="comparaison-de-deux-echantillons.html"><i class="fa fa-check"></i><b>4</b> Comparaison de deux échantillons</a></li>
<li class="chapter" data-level="5" data-path="anova-a-un-critere-de-classification.html"><a href="anova-a-un-critere-de-classification.html"><i class="fa fa-check"></i><b>5</b> ANOVA à un critère de classification</a></li>
<li class="chapter" data-level="6" data-path="but-first-save-current-par-and-set-graphic-page-to-hold-4.html"><a href="but-first-save-current-par-and-set-graphic-page-to-hold-4.html"><i class="fa fa-check"></i><b>6</b> but first, save current par and set graphic page to hold 4</a></li>
<li class="chapter" data-level="7" data-path="anova-a-criteres-multiples-plans-factoriels-et-hierarchiques.html"><a href="anova-a-criteres-multiples-plans-factoriels-et-hierarchiques.html"><i class="fa fa-check"></i><b>7</b> ANOVA à critères multiples : plans factoriels et hiérarchiques</a></li>
<li class="chapter" data-level="8" data-path="but-first-save-current-par-and-set-graphic-page-to-hold-4-1.html"><a href="but-first-save-current-par-and-set-graphic-page-to-hold-4-1.html"><i class="fa fa-check"></i><b>8</b> but first, save current par and set graphic page to hold 4</a></li>
<li class="chapter" data-level="9" data-path="fit-simplified-model.html"><a href="fit-simplified-model.html"><i class="fa fa-check"></i><b>9</b> fit simplified model</a></li>
<li class="chapter" data-level="10" data-path="modified-from-code-written-by-david-c-howell.html"><a href="modified-from-code-written-by-david-c-howell.html"><i class="fa fa-check"></i><b>10</b> modified from code written by David C. Howell</a></li>
<li class="chapter" data-level="11" data-path="httpwww-uvm-edudhowellstatpagesmore-stuffpermuta-.html"><a href="httpwww-uvm-edudhowellstatpagesmore-stuffpermuta-.html"><i class="fa fa-check"></i><b>11</b> <span>http://www.uvm.edu/~dhowell/StatPages/More_Stuff/Permuta-</span></a></li>
<li class="chapter" data-level="12" data-path="bootstrap-1000-time-using-the-residuals-bootstraping.html"><a href="bootstrap-1000-time-using-the-residuals-bootstraping.html"><i class="fa fa-check"></i><b>12</b> Bootstrap 1000 time using the residuals bootstraping</a></li>
<li class="chapter" data-level="13" data-path="regression-multiple.html"><a href="regression-multiple.html"><i class="fa fa-check"></i><b>13</b> Régression multiple</a></li>
<li class="chapter" data-level="14" data-path="bootstrap-analysis-the-simple-way-with-library-simpleboot.html"><a href="bootstrap-analysis-the-simple-way-with-library-simpleboot.html"><i class="fa fa-check"></i><b>14</b> Bootstrap analysis the simple way with library simpleboot</a></li>
<li class="chapter" data-level="15" data-path="define-model-to-be-bootstrapped-and-the-data-source-used.html"><a href="define-model-to-be-bootstrapped-and-the-data-source-used.html"><i class="fa fa-check"></i><b>15</b> Define model to be bootstrapped and the data source used</a></li>
<li class="chapter" data-level="16" data-path="ancova-et-glm.html"><a href="ancova-et-glm.html"><i class="fa fa-check"></i><b>16</b> ANCOVA et GLM</a></li>
<li class="chapter" data-level="17" data-path="analyse-de-donnees-de-frequence-tableaux-de-contingence-modeles-log-lineaires-et-regression-de-poisson.html"><a href="analyse-de-donnees-de-frequence-tableaux-de-contingence-modeles-log-lineaires-et-regression-de-poisson.html"><i class="fa fa-check"></i><b>17</b> Analyse de données de fréquence: Tableaux de contingence, modèles log-linéaires et régression de Poisson</a></li>
<li class="chapter" data-level="18" data-path="convert-case-form-to-table-form.html"><a href="convert-case-form-to-table-form.html"><i class="fa fa-check"></i><b>18</b> convert case form to table form</a></li>
<li class="chapter" data-level="19" data-path="fit-full-model.html"><a href="fit-full-model.html"><i class="fa fa-check"></i><b>19</b> Fit full model</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">BIO4558 Biostatistiques appliquées avec R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="correlation-et-regression-lineaire-simple" class="section level1">
<h1><span class="header-section-number">3</span> Corrélation et régression linéaire simple</h1>
<p>Après avoir complété cet exercice de laboratoire, vous devriez être en
mesure de :
• Utiliser R pour produire un diagramme de dispersion pour illus-
trer la relation entre deux variables avec trace lowess
• Utiliser R pour faire des transformations simples
• Utiliser R pour calculer le coefficient de corrélation de Pearson
entre deux variables et en évaluer sa signification statistique.
• Utiliser R pour calculer la corrélation de rang entre des paires de
variables avec le r de Spearman et le tau de Kendall.
• Utiliser R pour évaluer la signification de corrélations dans une
matrice de corrélation en utilisant les probabilités ajustées par la
méthode de Bonferroni.
• Utiliser R pour faire une régression linéaire simple.
• Utiliser R pour évaluer si un ensemble de données remplit les
conditions d’application d’une analyse de régression simple.
• Quantifier la taille de l’effet d’une régression simple et effectuer
une analyse de puissance avec G*Power.
Diagrammes de dispersion
Les analyses de corrélation et de régression devraient toujours
commencer par un examen des données. C’est une étape critique qui
sert à évaluer si ce type d’analyse est approprié pour un ensemble de
données.
Supposons que nous sommes intéressés à évaluer si la longueur
d’esturgeons mâles dans la région de The Pas covarie avec leur poids.
Pour répondre à cette question, regardons d’abord la corrélation entre
fklngth et rdwgth .
Souvenez-vous qu’une des conditions d’application de l’analyse de
corrélation est que la relation entre les deux variables est linéaire. Pour
évaluer cela, commençons par un diagramme de dispersion :
 En utilisant le fichier sturgeon.Rdata , et après avoir attach() le
data.frame sturgeon, faites un diagramme de dispersion avec une</p>
<p>droite de régression et une courbe LOWESS de fklngth en fonction
de rdwght en tapant:
mygraph&lt;-ggplot(
data=sturgeon, # source of data
aes(x=fklength, y=rdwght)) #aesthetics: x=fklngth, y=rdw-
ght
# plot data points, regression, loess trace
mygraph&lt;-mygraph+
stat_smooth(method=lm, se=FALSE, color=“green”) + # add
linear regression, but no SE shading
stat_smooth(color=“red”)+ #add loess
geom_point() # add data points
mygraph # display graph
(notez ici la gymnastique requise pour éliminer les données
manquantes qui posent problème pour obtenir la trace loess).
 Est-ce que la dispersion des points suggère une bonne corrélation
entre les deux variables? Est-ce que la relation semble linéaire?
Figure 1.</p>
<p>Ce graphique suggère une tendance plus curvilinéaire que linéaire.
Malgré tout, il semble y avoir une forte corrélation entre les deux
variables.
 Refaites le diagramme de dispersion avec des axes logarithmiques:
# apply log transformation on defined graph
mygraph+scale_x_log10()+scale_y_log10()
Comparez les diagrammes de dispersion avant et après transformation
(Figures 17 et ).Comme l’analyse de corrélation présuppose une
relation linéaire entre les variables, on devrait donc privilégier l’analyse
sur les données log-transformées.
Transformations et le coefficient de
corrélation
Une autre condition préalable à l’analyse de corrélation est que les
deux variables concernées suivent une distribution normale
bidimensionnelle. On peut aisément vérifier la normalité de chacune</p>
<p>des 2 variables séparément tel que décrit dans le laboratoire précédent.
Si les deux variables sont normalement distribuées, on présume
généralement qu’elles suivent une distribution normale
bidimensionnelle lorsqu’analysées simultanément (notez que ce n’est
pas toujours le cas cependant).
 Examinez la distribution des quatre variables (les deux variables origi-
nales et les variables transformées). Que concluez-vous de l’inspection
visuelle de ces graphiques ?
Les figures ci-dessous sont les diagrammes de probabilité (qqplots()).
Le code pour produire des graphiques multiples sur une page, comme
on voit ci-dessous, est):
attach(sturgeon)
par(mfrow = c(2, 2))
qqnorm(fklngth,ylab=“fklngth”)
qqline(fklngth)
qqnorm(log10(fklngth),ylab=“log10(fklngth)”)
qqline(log10(fklngth))
qqnorm(rdwght,ylab=“rdwght”)
qqline(rdwght)
qqnorm(log10(rdwght),ylab=“log10(rdwgth)”)
qqline(log10(rdwght))
par(mfrow = c(1, 1))
Figure 2.
Il n’y a pas grand-chose à redire: aucune des distributions n’est
parfaitement normale, mais les déviations semblent mineures.</p>
<p> Générez une matrice de graphiques de dispersion améliorés en util-
isant la commande scatterplot.matrix de la librairie car .
scatterplot.matrix(~fklngth+log10(fklngth)+rdwght+log10(rdw-
ght), reg.line=lm,
smooth=TRUE, span=0.5, diagonal = ‘den-
sity’)
pour obtenir
Figure 3.
 Ensuite, calculez le coefficient de corrélation de Pearson entre chaque
paire (variables originales et logtransformées ) en utilisant la com-
mande cor(). Avant de commencer, on va cependant ajouter les vari-
ables transformées au tableau de données sturgeon:
sturgeon<span class="math inline">\(lfklngth &lt;- with(sturgeon, log10(fklngth)) sturgeon\)</span>lrdwght &lt;- with(sturgeon, log10(rdwght))
Vous pouvez ensuite obtenir la matrice de corrélation par:
cor(sturgeon[,c(“fklngth”,“lfklngth”,“lrdwght”,“rdwght”)],
use=“complete.obs”)
Fréquemment, il y a des données manquantes dans un échantillon. En
choisissant use=“complete.obs” , toutes les lignes du fichier pour
lesquelles les variables ne sont pas toutes mesurées sont éliminées.
Dans ce cas, toutes les corrélations seront calculées avec le même
nombre de cas. Par contre, en utilisant use=“pairwise.complete.obs” ,
R élimine une observation que lorsqu’un des deux membres de la</p>
<p>paire a une valeur manquante. Dans ce cas, si les données manquantes
pour différentes variables se retrouvent dans un groupe différent
d’observation, les corrélations ne seront pas nécessairement calculées
sur le même nombre de cas ni sur le même sous-ensemble de cas. En
général, vous devriez utiliser l’option use=“complete.obs” à moins
que vous ayez un très grand nombre de données manquantes et que
cette façon de procéder élimine la plus grande partie de vos
observations.
Pourquoi la corrélation entre les variables originales est-elle la plus
faible des trois ?
fklngth
lfklngth
lrdwght
rdwght
fklngth
1.0000000
0.9921435
0.9645108
0.9175435
lfklngth
0.9921435
1.0000000
0.9670139
0.8756203
lrdwght
0.9645108
0.9670139
1.0000000
0.9265513
rdwght
0.9175435
0.8756203
0.9265513
1.0000000
Il y a plusieurs choses à noter ici. Premièrement, la corrélation entre la
longueur à la fourche et le poids rond est élevée, peu importe la
transformation: les poissons lourds ont tendance à être longs.
Deuxièmement, la corrélation est plus forte pour les données
transformées que pour les données brutes. Pourquoi? Parce que le
coefficient de corrélation est inversement proportionnel au bruit
autour de la relation linéaire. Si la relation est curvilinéaire (comme
dans le cas des données non transformées), le bruit est plus grand que
si la relation est parfaitement linéaire. Par conséquent, la corrélation
est plus faible.
Matrices de corrélations et correction de
Bonferroni
Une pratique courante est d’examiner une matrice de corrélation à la
recherche des associations significatives. Comme exemple, essayons
de tester si la corrélation entre lfklngth et rdwght est significative (c’est
le plus faible coefficient de corrélation de cette matrice).
 De la fenêtre R console, inscrivez le code suivant pour tester la corréla-
tion entre lfklngth et rdwght:
&gt;cor.test(sturgeon<span class="math inline">\(lfklngth, sturgeon\)</span>rdwght, alterna-
tive=“two.sided”,
method=“pearson”)
Pearson’s product-moment correlation
data: sturgeon<span class="math inline">\(lfklngth and sturgeon\)</span>rdwght
t = 24.3223, df = 180, p-value &lt; 2.2e-16
alternative hypothesis: true correlation is not equal to 0
95 percent confidence interval:
0.8367345 0.9057199
sample estimates:
cor
0.8756203</p>
<p>On voit ici que la corrélation est hautement significative (p&lt; 2.2e-16),
ce qui n’est pas surprenant étant donné la valeur du coefficient de
corrélation (0.8756).
Il est important de réaliser que si une matrice contient un grand
nombre de corrélations, il n’est pas surprenant d’en trouver au moins
une qui soit “significative”. En effet, on s’attend à en trouver 5% en
moyenne lorsqu’il n’y a en fait aucune corrélation entre les paires de
moyennes. Une façon de corriger pour cette tendance est d’ajuster le
niveau  critique auquel on attribue une signification statistique en
divisant  par le nombre k de corrélations qui sont examinées : ’ =
/k (ajustement de Bonferroni). Si initialement = 0.05 et qu’il y a
10 corrélations qui sont examinées, alors ’= 0.005. Donc, afin de
rejeter l’hypothèse nulle, la valeur de p devra être plus petite que ’, en
l’occurrence 0.005.
Dans l’exemple qui précède, on devrait donc ajuster  critique en
divisant par le nombre total de corrélations dans la matrice (6 dans ce
cas, donc ’=0.00833). Cette correction modifie-t-elle votre
conclusion quant à la corrélation entre lkfl et rdwght?
Corrélations non paramétriques : r de
Spearman et tau de Kendall
L’analyse faite à la section précédente avec les esturgeons suggère que
l’une des conditions préalables à l’analyse de corrélation, soit la
distribution normale bidimensionnelle de données, pourrait ne pas
être remplie pour fklngth et rdwght , ni pour les paires de variables
transformées. La recherche d’une transformation appropriée peut
parfois être difficile. Pire encore, pour certaines distributions il
n’existe pas de transformation qui va normaliser les données. Dans
ces cas-là, la meilleure option est de faire une analyse non
paramétrique qui ne présume ni de la normalité ni de la linéarité. Ces
analyses sont basées sur les rangs. Les deux plus communes sont le
coefficient de rang de Spearman et le tau de Kendall.
 Allez à la fenêtre R console , et testez la corrélation entre fklngth et
rdwght en utilisant Spearman et Kendall’s . Les commandes qui suiv-
ent produiront les corrélations:
&gt;cor.test(sturgeon<span class="math inline">\(fklngth, sturgeon\)</span>rdwght, alterna-
tive=“two.sided”,
method=“spearman”)
Spearman’s rank correlation rho
data: sturgeon<span class="math inline">\(fklngth and sturgeon\)</span>rdwght
S = 47971.33, p-value &lt; 2.2e-16
alternative hypothesis: true rho is not equal to 0</p>
<p>sample estimates:
rho
0.9522546
&gt;cor.test(sturgeon<span class="math inline">\(fklngth, sturgeon\)</span>rdwght, alterna-
tive=“two.sided”, method=“kendall”)Kendall’s rank correla-
tion tau
Kendall’s rank correlation tau
data: sturgeon<span class="math inline">\(fklngth and sturgeon\)</span>rdwght
z = 16.3578, p-value &lt; 2.2e-16
alternative hypothesis: true tau is not equal to 0
sample estimates:
tau
0.8208065
Comparer les résultats de cette analyse à l’analyse paramétrique.
Pourquoi y-a-t’il une différence ?
Calculez les corrélations non paramétriques sur les paires de variables
transformées. Vous devriez voir tout de suite que les corrélations des
données transformées et non transformées sont identiques puisque
dans les deux cas la corrélation est calculée à partir des rangs qui ne
sont pas affectés par la transformation.
Notez que les corrélations obtenues avec le tau de Kendall (0.820)
sont plus faibles que celles du coefficient de Spearman (0.952). Le tau
pondère un peu plus les grandes différences entre les rangs alors que
le coefficient de Spearman donne le même poids à chaque paire
d’observations. En général, on préfère le tau de Kendall lorsqu’il y a
plus d’incertitude quant aux rangs qui sont près les uns des autres.
Les esturgeons de cet échantillon ont été capturés à l’aide de filets et
d’hameçons d’une taille fixe. Quel impact cette méthode de capture
peut-elle avoir eu sur la forme de la distribution de fklngth et rdwght
? Compte tenu de ces circonstances, l’analyse de corrélation est-elle
appropriée ?
Rappelez-vous que l’analyse de corrélation présume aussi que chaque
variable est échantillonnée aléatoirement. Dans le cas de nos esturgeons, ce
n’est pas le cas: les hameçons appâtés et les filets ne capturent pas de
petits esturgeons (et c’est pourquoi il n’y en a pas dans l’échantillon). Il
faut donc réaliser que les coefficients de corrélation obtenus dans
cette analyse ne reflètent pas nécessairement ceux de la population
totale des esturgeons.
Régression linéaire simple
L’analyse de corrélation vise à décrire comment deux variables
covarient. L’analyse de régression vise plutôt à produire un modèle
permettant de prédire une variable (la variable dépendante) par l’autre
(la variable indépendante).</p>
<p>Comme pour l’analyse de corrélation, on devrait commencer en
examinant des graphiques. Puisque l’on est intéressé à quantifier la
relation entre deux variables, un graphique de la variable dépendante
(Y) en fonction de la variable indépendante (X) est tout à fait
approprié.
 Le fichier sturgeon.Rdata contient des données d’un inventaire des
esturgeons récoltés en 1978-1980 à Cumberland House en Saskatche-
wan et à The Pas au Manitoba. Faites un diagramme de dispersion de
fklngth (la variable dépendante) en fonction de age (la variable
indépendante) pour les esturgeons mâles et ajoutez-y une régression
linéaire et une trace lowess. Que concluez-vous de ce diagramme de
dispersion ?
sturgeon.male &lt;- subset(sturgeon, subset=sex==“MALE”)
lmygraph&lt;-ggplot(
data=sturgeon.male, # source of data
aes(x=age, y=fklngth)) #aesthetics: y=fklngth, x=rdwght
# plot data points, regression, loess trace
mygraph&lt;-mygraph+
stat_smooth(method=lm, se=FALSE, color=“green”) + # add linear regression,
but no SE shading
stat_smooth(color=“red”)+ #add loess
geom_point() # add data points
mygraph # display graph
Figure 4.
Ce graphique suggère que la relation n’est pas linéaire.</p>
<p>Supposons que nous désirions estimer le taux de croissance des
esturgeons mâles. Un estimé (peut-être pas terrible…) du taux de
croissance peut être obtenu en calculant la pente de la régression de la
longueur à la fourche sur l’âge.
Ajustons d’abord une régression avec la commande lm() et sauvons
ces résultats dans un objet appelé RegModel.1
RegModel.1 &lt;- lm(fklngth~age, data=sturgeon.male)
Rien n’apparait à l’écran, mais ne vous inquiétez pas, tout a été
sauvegardé en mémoire.
Pour voir ces résultats, tapez:
summary(RegModel.1)
Call:
lm(formula = fklngth ~ age, data = sturgeon.male)


Residuals:
Min
1Q
-8.4936 -2.2263
Median
0.1849
3Q
Max
1.7526 10.8234

Coefficients:
Estimate Std. Error t value Pr(&gt;|t|)
(Intercept) 28.50359
1.16873
24.39
&lt;2e-16 <strong><em>
age
0.70724
0.05888
12.01
&lt;2e-16 </em></strong>
—
Signif. codes: 0 ‘<em><strong>’ 0.001 ‘</strong>’ 0.01 ‘</em>’ 0.05 ‘.’ 0.1 ‘ ’ 1


Residual standard error:
3.307 on 73 degrees of freedom
(5 observations deleted due to missingness)
Multiple R-squared: 0.664
,
Adjusted R-squared: 0.6594
F-statistic: 144.3 on 1 and 73 DF,
p-value: &lt; 2.2e-16


 Le modèle qui a été ajusté et les données utilisées.
 Un sommaire statistique des résidus autour du modèle estimé.
 Valeurs estimées des paramètres du modèle, erreurs-types,
statistiques t et probabilités associées.
 Racine carrée de la variance résiduelle.
 Coefficient de détermination. Il correspond à la proportion de la
variabilité de la variable dépendante qui peut être expliquée par la
régression.
 Le R-carré ajusté tient compte du nombre de paramètres du
modèle. Si vous voulez comparer différents modèles qui n’ont pas le
même nombre de paramètres, c’est ce qu’il faut utiliser.
 C’est le test de signification omnibus du modèle. Dans le cas de la
régression simple, il est équivalent au test sur la pente de la régression.</p>
<p>La régression estimée est donc:
Fklngth = 28.50359+ 0.70724*age
Étant donné la valeur très significative du test de F ainsi que pour le
test de t pour la pente de la droite, on rejette l’hypothèse nulle qu’il n’y
a pas de relation entre la taille et l’âge.
Vérifier les conditions d’application de la
régression
La régression simple de modèle I a quatre conditions préalables :
1. il n’y a pas d’erreur de mesure sur la variable indépendante (X),
2. la relation entre Y et X est linéaire,
3. les résidus sont normalement distribués et
4. la variance des résidus est constante pour toutes les valeurs de la
variable indépendante.
Procédons maintenant à l’examen post-mortem. La première
condition est rarement remplie avec des données biologiques ; il y
presque toujours de l’erreur sur X et sur Y. Cela veut dire qu’en
général les pentes estimées sont biaisées, mais que les valeurs prédites
ne le sont pas. Toutefois, si l’erreur de mesure sur X est petite par
rapport à l’étendue des valeurs de X, le résultat de l’analyse n’est pas
dramatiquement influencé. Par contre, si l’erreur de mesure est
relativement grande (toujours par rapport à l’étendue des valeurs de
X), la droite de régression obtenue par la régression de modèle I est
un piètre estimé de la relation fonctionnelle entre X et Y. Dans ce cas,
il est préférable de passer à la régression de modèle II,
malheureusement au-delà du contenu de ce cours.
Les autres conditions préalables à l’analyse de régression de modèle I
peuvent cependant être vérifiées, ou du moins évaluées visuellement.
La commande plot() permet de visualiser des graphiques
diagnostiques pour des modèles linéaires.
par(mfrow = c(2, 2), las=1)
plot(RegModel.1)
La commande par() est utilisée pour dire à R de tracer 2 rangées et 2
colonnes de graphiques par page (il y a quatre graphiques
diagnostiques qui sont générés automatiquement pour les modèles</p>
<p>linéaires), et la commande las indique à R d’effectuer une rotation des
légendes de l’axe des Y pour qu’elles soient perpendiculaires à l’axe
(oui. Je sais. Rien de tout ça n’est évident.)
Vous obtiendrez:
Figure 5.
Le premier graphique (en haut à gauche) permet d’évaluer la linéarité,
la normalité, et l’homoscédasticité des résidus. Il illustre les déviations
autour de la régression en fonction des valeurs prédites. Rappllez-vous
que le graphique de fklngth vs age suggère que la relation entre la
longueur à la fourche et l’âge n’est pas linéaire. Les très jeunes et très
vieux esturgeons sont sous la droite en général, alors que les
esturgeons d’âge moyen sont retrouvés généralement au-dessus de la
droite de régression. C’est exactement ce que le graphique des résidus
en fonction des valeurs prédites illustre. La ligne en rouge est une</p>
<p>trace lowess au travers de ce nuage de points. Si la relation était
linéaire, la trace lowess serait presque plate et près de 0. La dispersion
des résidus permet d’évaluer visuellement leur normalité et
hétéroscédasticité; mais ce graphique n’est pas optimal pour évaluer
ces propriétés. Les deux graphiques suivants sont supérieurs au
premier pour cela.
Le deuxième graphique permet d’évaluer la normalité des résidus.
C’est un graphique QQ des résidus (QQ plot). Des résidus distribués
normalement tomberaient exactement sur la diagonale. Ici, on voit
que c’est presque le cas, sauf dans les queues de la distribution.
Le troisième graphique, en bas à gauche, intitulé Scale-Location,
permet d’évaluer l’homoscedasticité. On y retrouve sur l’ordonnée
(l’axe des y) la racine carrée de la valeur absolue des résidus
standardisés (résidus divisés par l’écart-type des résidus) en fonction
des valeurs prédites. Le graphique aide à déterminer si la variation des
résidus est constante ou non. Si les résidus sont homoscédastiques, la
valeur moyenne sur l’axe des y ne va pas changer en fonction de la
valeur prédite. Ici, il y a une certaine tendance, mais pas une tendance
monotone puisqu’ il y a d’abord une baisse puis une hausse..; bref, rien
qui soit une forte évidence contre la supposition d’homoscédasticité.
Le quatrième graphique, en bas à droite, montre les résidus en
fonction du “leverage” et permet de détecter certaines valeurs
extrêmes qui ont une grande influence sur la régression. Le leverage
d’un point mesure sa distance des autres points, mais seulement en ce
qui concerne les variables indépendantes. Dans le cas d’une régression
simple, cela revient à la distance entre le point sur l’axe des x et la
moyenne de tous les points sur cet axe. Vous devriez porter une
attention particulière aux observations qui ont un leverage plus grand
que 2(k+1)/n, où k est le nombre de variables indépendantes (ici, 1)
et n est le nombre d’observations. Dans cet exemple, il y a 75
observations et une variable indépendante et donc les points ayant un
leverage plus grand que 4/75= 0.053 devrait être considérés avec
attention. Le graphique indique également comment la régression
changerait si on enlevait un point. Ce changement est mesuré par la
distance de Cook, illustrée par les bandes en rouge sur le graphique.
Un point ayant une distance de Cook supérieure à 1 a une grande
influence.
Attrappe: Notez que R identifie automatiquement les cas les plus
extrèmes sur chacun de ces 4 graphiques. Le fait qu’un point soit
identifié ne signifie pas nécessairement que c’est une valeur réellement</p>
<p>extrème, ou que vous devez vous en préoccuper. Dans tous les
ensembles de données il y aura toujours un résidu plus grand que les
autres…
Finalement, quel est le verdict concernant la régression linéaire entre
fklngth et age ? Elle viole la condition de linéarité, possiblement celle
de normalité, remplit la condition d’homoscédasticité, et ne semble
pas influencée outre mesure par des valeurs bizarres ou extrêmes.
Tests formels des conditions d’application
pour la régression
Personnellement, je n’utilise jamais les tests formels des conditions
d’application de la régression et me contente des graphiques des
résidus pour guider mes décisions. C’est ce que la plupart des
praticiens font. Cependant, lors de mes premières analyses, je n’étais
pas toujours certain de bien interpréter les graphiques et j’aurais aimé
un indice plus formel ou un test permettant de détecter les violations
des conditions d’application de la régression.
Le package lmtest , qui ne fait pas partie de l’installation de base, mais
qui est disponible sur CRAN, permet de faire plusieurs tests de
linéarité et d’homoscédasticité. Et on peut tester la normalité avec le
test Shapiro-Wilk test vu précédemment..
 Installez le package lmtest de CRAN.
 Exécutez les commandes suivantes:
library(lmtest)
bptest(RegModel.1)
dwtest(RegModel.1)
resettest(RegModel.1)
shapiro.test(residuals(RegModel.1))
pour obtenir
studentized Breusch-Pagan test

data: RegModel.1
BP = 1.1765, df = 1, p-value = 0.2781
Durbin-Watson test

data: RegModel.1
DW = 2.242, p-value = 0.849
alternative hypothesis: true autocorrelation is greater than 0</p>
<p>RESET test

data: RegModel.1
RESET = 14.544, df1 = 2, df2 = 71, p-value = 5.082e-06
&gt; shapiro.test(residuals(RegModel.1))

Shapiro-Wilk normality test
data: residuals(RegModel.1)
W = 0.9804, p-value = 0.2961
 Le test Breusch-Pagan test examine si la variabilité des résidus est
constantes lorsque les valeurs prédites changent. Une faible valeur de
p suggère de l’hétéroscédasticité. Ici, la valeur p est élevée et suggère
que la condition d’application d’homoscédasticité est remplie avec ces
données.
 Le test
Durbin-Watson permet de détecter l’autocorrélation
sérielle des résidus. En l’absence d’autocorrélation (i.e.
d’indépendance des résidus) la valeur attendue de la statistique D est
2. Ce test permet d’éprouver l’hypothèse d’indépendance des résidus,
mais ne permet de détecter qu’un type particulier de dépendance. Ici,
le test ne permet pas de rejeter l’hypothèse d’indépendance.
 Le test RESET permet d’éprouver la linéarité. Si la relation est
linéaire, alors la statistique RESET sera d’environ 1. Ici, la statistique
est beaucoup plus élevée (14.54) et hautement significative. Le test
confirme la tendance que nous avons détectée visuellement plus haut:
la relation n’est pas linéaire.
 Le test de normalité Shapiro-Wilk sur les résidus confirme que la
déviation par rapport à une distribution normale des résidus n’est pas
grande.
Transformation des données en régression
La relation entre fklngth et age n’étant pas linéaire, on devrait donc
essayer de transformer les données pour tenter de les linéariser. :
 Voyons ce qu’une transformation log donne:
ggplot(data=sturgeon.male,
aes(x=log10(age), y=log10(fklngth)))+
geom_smooth(color=“red”)+
geom_smooth(method=“lm”, se=FALSE, color=“green”)+
geom_point()
On obtient:</p>
<p>Figure 6.
Ajustons maintenant une régression simple sur ces données
transformées:
RegModel.2 &lt;- lm(log10(fklngth)~log10(age), data=stur-
geon.male)
summary(RegModel.2)
Call:
lm(formula = log10(fklngth) ~ log10(age), data = sturgeon.male)
Residuals:
Min
1Q
Median
-0.0827935 -0.0168373 -0.0007188
3Q
0.0211016
Max
0.0874465
Coefficients:
Estimate Std. Error t value Pr(&gt;|t|)
(Intercept) 1.19199
0.02723
43.77
&lt;2e-16 <strong><em>
log10(age)
0.34086
0.02168
15.72
&lt;2e-16 </em></strong>
—
Signif. codes: 0 ‘<em><strong>’ 0.001 ‘</strong>’ 0.01 ‘</em>’ 0.05 ‘.’ 0.1 ‘ ’ 1
Residual standard error: 0.03015 on 73 degrees of freedom
(5 observations deleted due to missingness)
Multiple R-squared: 0.772,
Adjusted R-squared: 0.7688
F-statistic: 247.1 on 1 and 73 DF, p-value: &lt; 2.2e-16
Examinons maintenant les graphiques diagnostiques:
plot(RegModel.2)</p>
<p>Figure 7.
Il y a une certaine amélioration, mais ce n’est pas encore parfait (la
perfection n’est pas de ce monde….). Le graphique des résidus en
fonction des valeurs prédites suggère encore une certaine non
linéarité. Sur le graphique Q-Q les points se retrouvent plus près de la
droite diagonale qu’avant, indiquant que les résidus sont encore plus
près de la normalité après la transformation log-log. Il n’y a pas
d’indice d’hétéroscédasticité. Finalement, même si il reste quelques
points avec plus d’influence (leverage) que les autres, aucun n’a une
distance de Cook au-delà de 0.5. En résumé, la transformation log a
amélioré les choses: relation est plus linéaire, les résidus sont plus
normaux, et il y a moins de points avec une influence relativement
élevée.Est-ce que les tests formels supportent cette évaluation?
bptest(RegModel.2)</p>
<p>dwtest(RegModel.2)
resettest(RegModel.2)
shapiro.test(residuals(RegModel.2))
&gt; bptest(RegModel.2)
studentized Breusch-Pagan test
data: RegModel.2
BP = 0.14282, df = 1, p-value = 0.7055
&gt; dwtest(RegModel.2)
Durbin-Watson test
data: RegModel.2
DW = 2.1777, p-value = 0.6134
alternative hypothesis: true autocorrelation is greater than 0
&gt; resettest(RegModel.2)
RESET test
data: RegModel.2
RESET = 4.4413, df1 = 2, df2 = 71, p-value = 0.01523
&gt; shapiro.test(residuals(RegModel.2))
Shapiro-Wilk normality test
data: residuals(RegModel.2)
W = 0.98998, p-value = 0.8246
Oui, les conclusions sont les mêmes: les résidus sont encore
homoscédastiques (test Breusch-Pagan), ne sont pas autocorrélés (test
Durbin-Watson), sont normaux (test Shapiro-Wilk ), et sont plus
linéaires (la valeur de P du test RESET est maintenant 0.015, au lieu
de 0.000005). Donc la linéarité a augmenté, mais cette condition
d’application semble encore légèrement violée.
Traitement des valeurs extrèmes
Dans cet exemple, il n’y a pas de valeur vraiment extrème. Oui, je sais,
R a quand même identifié les observations 8, 24, et 112 dans le dernier
graphique diagnostique. Mais ces valeurs sont encore dans la
fourchette de valeurs que je juge “acceptables”. Mais comment
déterminer objectivement ce qui est acceptable? À quel moment juge
t’on qu’une valeur extrême est vraiment trop invraisemblable pour ne
pas l’exclure? Il n’y a malheureusement pas de règle absolue là-dessus.
Les opinions varient, mais je penche vers le conservatisme sur cette
question.
Ma position est que, à moins que la valeur soit impossible ou
clairement une erreur d’entrée de données, je n’élimine pas les valeurs
extrêmes et j’utilise toutes mes données dans leur analyse. Pourquoi?</p>
<p>Parce que je veux que mes données reflètent bien la variabilité
naturelle ou réelle. C’est d’ailleurs parfois cette variabilité qui est
intéressante.
L’approche conservatrice qui consiste à conserver toutes les valeurs
extrêmes possibles est possiblement la plus honnête, mais elle peut
causer certains problèmes. Ces valeurs extrêmes sont souvent la cause
des violations des conditions d’application des tests statistiques. La
solution suggérée à ce dilemme est de faire l’analyse avec et sans les
valeurs extrêmes et de comparer les conclusions. Dans bien des cas,
les conclusions seront qualitativement les mêmes et les tailles d’effet
ne seront pas très différentes. Toutefois, dans certains cas, la présence
des valeurs extrêmes change complètement les conclusions. Dans ces
cas, il faut simplement accepter que les conclusions dépendent
entièrement de la présence des valeurs extrêmes et sont donc peu
concluantes.
Suivant cette approche comparative, refaisons donc l’analyse après
avoir enlevé les observations 8, 24, et 112:
RegModel.3 &lt;- lm(log10(fklngth)~log10(age), data=stur-
geon.male, subset=!(rownames(sturgeon.male) %in%
c(’8’,’24’,’112’)))
summary(RegModel.3)
pour obtenir:
Call:
lm(formula = log10(fklngth) ~ log10(age), data = sturgeon.male,
subset = !(rownames(sturgeon.male) %in% c(“8”, “24”, “112”)))
Residuals:
Min
1Q
-0.0691634 -0.0173903
Median
0.0009862
3Q
0.0185900
Max
0.0476466
Coefficients:
Estimate Std. Error t value Pr(&gt;|t|)
(Intercept) 1.22676
0.02431
50.46
&lt;2e-16 <strong><em>
log10(age)
0.31219
0.01932
16.16
&lt;2e-16 </em></strong>
—
Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ’ ’ 1
Residual standard error: 0.02554 on 70 degrees of freedom
(5 observations deleted due to missingness)
Multiple R-squared: 0.7885,
Adjusted R-squared: 0.7855
F-statistic:
261 on 1 and 70 DF, p-value: &lt; 2.2e-16
L’ordonnée à l’origine (Intercept), la pente, et le R carré sont presque
les mêmes, et la valeur de p est encore astronomiquement petite.
Enlever les valeurs extrêmes a peu d’effet dans ce cas.
Les graphiques diagnostiques des résidus et les tests formels des
conditions d’application sur ce sous-ensemble de données donnent:
plot(RegModel.3)
library(lmtest)</p>
<p>sturgeon.male.subset &lt;- subset(sturgeon, subset=!(rown-
ames(sturgeon.male) %in% c(’8’,’24’,’112’)))
bptest(RegModel.3)
dwtest(RegModel.3)
resettest(RegModel.3)
shapiro.test(residuals(RegModel.3))
Figure 8.
&gt; bptest(RegModel.3)
studentized Breusch-Pagan test
data: RegModel.3
BP = 0.3001, df = 1, p-value = 0.5838
&gt; dwtest(RegModel.3)
Durbin-Watson test
data: RegModel.3
DW = 2.0171, p-value = 0.5074
alternative hypothesis: true autocorrelation is greater than 0
&gt; resettest(RegModel.3)
RESET test</p>
<p>data: RegModel.3
RESET = 3.407, df1 = 2, df2 = 68, p-value = 0.0389
&gt; shapiro.test(residuals(RegModel.3))
Shapiro-Wilk normality test
data: residuals(RegModel.3)
W = 0.98318, p-value = 0.4502
Il n’y a pas vraiment de différence ici non plus avec l’analyse des
données en entier. Bref, tout pointe vers la conclusion que les valeurs
les plus extrêmes de cet ensemble de donnée n’influencent pas
indûment les résultats statistiques.
Quantifier la taille d’effet et analyse de
puissance en régression
L’interprétation biologique des résultats n’est pas la même chose que
l’interprétation statistique. Dans l’analyse qui précède, on conclue
statistiquement que la taille augmente avec l’âge (puisque la pente est
positive et et p&lt;0.05). Mais cette augmentation “statistique” de la taille
avec l’âge ne donne pas d’information sur la différence de taille entre
les jeunes et vieux individus. La pente et un graphique sont plus
informatifs à ce sujet que la valeur p. La pente (dans l’espace log-log)
est 0.34. Cela veut dire que pour chaque unité d’accroissement de X
(log10(age)), il y a une augmentation de 0.34 unités of log10(fklngth).
En d’autres mots, quand l’âge est multiplié par 10, la longueur à la
fourche est multipliée environ par 2. Donc la longueur des esturgeons
augmente plus lentement que leur âge (contrairement à mon tour de
taille, semble-t-il….). La valeur de la pente (0.34) est un estimé de la
taille de l’effet de l’âge sur la longueur.
Puissance de détecter une pente donnée
Pour les calculs de puissance avec G<em>Power vous devrez cependant
utiliser une autre métrique de la taille de l’effet., calculée à partir de la
pente, de son erreur-type, et de la taille de l’échantillon (ce qui facilite
les calculs pour G</em>Power, mais malheureusement pas pour vous ;-) La
métrique (d) est calculée comme:</p>
<p>où b est l’estimé de la pente, s b est l’erreur type de la pente, n est le
nombre d’observations, et k est le nombre de variables indépendantes
(1 pour la régression linéaire simple).
Vous pouvez calculer approximativement la puissance avec G<em>Power
pour une valeur de pente que vous jugez assez grande pour mériter
d’être détectée. Allez à Tests: Means: One group: difference from
constant , là, vous devrez remplacer la valeur de b dans l’équation
pour la taille d’effet (d) par la pente que vous voudriez détecter, mais
utiliser l’erreur type calculée à partir de vos données.
Par exemple, supposons que les ichthyologues considèrent qu’une
pente de 0.1 pour la relation entre log10(fklngth) et log10(age) est
signifiante biologiquement, et qu’ils désirent estimer la puissance de
détecter une telle pente à partir d’un échantillon de 20 esturgeons. Les
résultats de la régression log-log nous fournissent ce dont on a besoin:
summary(RegModel.2)
Call:
lm(formula = log10(fklngth) ~ log10(age), data = sturgeon.male)
Residuals:
Min
1Q
Median
-0.0827935 -0.0168373 -0.0007188
3Q
0.0211016
Max
0.0874465
Coefficients:
Estimate Std. Error t value Pr(&gt;|t|)
(Intercept) 1.19199
0.02723
43.77
&lt;2e-16 </em><strong>
log10(age)
0.34086
0.02168
15.72
&lt;2e-16 </strong><em>
—
Signif. codes: 0 ‘<em><strong>’ 0.001 ‘</strong>’ 0.01 ‘</em>’ 0.05 ‘.’ 0.1 ‘ ’ 1
Residual standard error: 0.03015 on 73 degrees of freedom
(5 observations deleted due to missingness)
Multiple R-squared: 0.772,
Adjusted R-squared: 0.7688
F-statistic: 247.1 on 1 and 73 DF, p-value: &lt; 2.2e-16
L’erreur-type de la pente est 0.02168. Il y avait 75 poissons (n=75)
dans l’échantillon de départ. On peut donc calculer la métrique de
taille d’effet pour G</em>Power</p>
<p>Armés de cette taille d’effet (une pente présumée de 0.1 et une
variabilité autour de la régression similaire à la régression de fklngth
vs age), aller à Tests: Means: One group: difference from constant ,
et entrez la valeur calculée de d, alpha, et l’effectif de l’échantillon
pour calculer la puissance
Figure 9.
La puissance de détecter une pente comme étant statistiquement
significative (au niveau alpha), si la pente est 0.1, que la variabilité
résiduelle autour de la régression est semblable à celle de notre
échantillon (ce qui revient à une taille d’effet de 0.54, pour un
échantillon de 20 esturgeons et alpha=0.05) est de 0.629. Seulement
environ 2/3 des échantillons de cette taille détecteraient un effet
significatif de l’âge sur fklngth.
Effectif requis pour atteindre une puissance désirée
Pour estimer la taille d’échantillon (effectif) requis pour avoir une
puissance de 99% de détecter un effet de l’âge si la pente est 0.1 (sur
une échelle log-log ), avec alpha=0.05, on utilise la même valeur de d
(0.54):</p>
<p>Figure 10.
En augmentant la taille de l’échantillon à 65, selon le même scénario
que précédemment, la puissance augmente à 99%.
Bootstrap en régression simple avec R
Un test non paramétrique pour l’ordonnée à l’origine et la pente d’une
régression simple peut être effectué par bootstrap:
# Bootstrap 95% CI for regression coefficients
library(boot)
# function to obtain regression weights
bs &lt;- function(formula, data, indices) {
d &lt;- data[indices,] # allows boot to select sample
fit &lt;- lm(formula, data=d)
return(coef(fit))
}
# bootstrapping with 1000 replications
results &lt;- boot(data=sturgeon.male, statistic=bs,
R=1000, formula=log10(fklngth)~log10(age))
# view results</p>
<p>results
&gt; results
ORDINARY NONPARAMETRIC BOOTSTRAP
Call:
boot(data = sturgeon.male, statistic = bs, R = 1000, formula = log10(fklngth)
~
log10(age))
Bootstrap Statistics :

original
bias

t1* 1.1919926 -8.936048e-05
t2* 0.3408557 1.116266e-04
std. error

0.03532614
0.02789170
 Pour chaque paramètre du modèle (ici l’ordonnée à l’origine est
appelée t1* et la pente de la régression t2*), R imprime d’abord la
valeur estimée sur tout l’échantillon
 “bias” est la différence entre la valeur moyenne des estimés
bootstrap et la valeur originale sur tout l’échantillon
 l’erreur-type de l’estimé bootstrap
plot(results, index=1) # intercept
Figure 11.
plot(results, index=2) # log10(age)</p>
<p>Figure 12.
La distribution des estimés obtenus par bootstrap est assez normale
dans cet exemple, avec de petites déviations dans les queuee de la
distribution (là où ça compte pour les intervalles de confiance…). On
pourrait utiliser l’erreur-type des estimés bootstrap pour calculer un
intervalle de confiance symétrique (moyenne +- t ET). Cependant,
comme R peut facilement calculer des intervalles de confiance qui
corrigent pour le biais (BCa) ou encore des intervalle empiriques à
partir des distributions simulées (méthode Percentile) il peut être aussi
simple de les calculer selon les 3 méthodes:
# get 95% confidence intervals
boot.ci(results, type = “all”, index = 1)
BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
Based on 1000 bootstrap replicates
CALL :
boot.ci(boot.out = results, type = “all”, index = 1)
Intervals :
Level
Normal
95%
( 1.124, 1.256 )
Basic
( 1.123, 1.255 )
Level
Percentile
BCa
95%
( 1.129, 1.261 )
( 1.104, 1.247 )
Calculations and Intervals on Original Scale
Some BCa intervals may be unstable
Warning message:
In boot.ci(results, type = “all”, index = 1) :
bootstrap variances needed for studentized intervals
boot.ci(results, type = “all”, index = 2)
BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS</p>
<p>Based on 1000 bootstrap replicates
CALL :
boot.ci(boot.out = results, type = “all”, index = 2)
Intervals :
Level
Normal
95%
( 0.2898, 0.3946 )
Basic
( 0.2902,
0.3931 )
Level
Percentile
BCa
95%
( 0.2886, 0.3915 )
( 0.2966, 0.4044 )
Calculations and Intervals on Original Scale
Some BCa intervals may be unstable
Warning message:
In boot.ci(results, type = “all”, index = 2) :
bootstrap variances needed for studentized intervals
Ici, les 4 types d’intervalles de confiance que R a calculé sont
essentiellement semblables. Si les données avaient violé plus
sévèrement les conditions d’application de la régression (normalité,
homoscedasticité), alors les différentes méthodes (Normal, Basic,
Percentile, et BCa) auraient divergé un peu plus. Lequel choisir alors?
BCa est celui qui est préféré de la majorité des praticiens,
présentement.</p>

</div>
            </section>

          </div>
        </div>
      </div>
<a href="analyse-de-puissance-avec-r-et-gpower-ahahahaha.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="comparaison-de-deux-echantillons.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["_main.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
