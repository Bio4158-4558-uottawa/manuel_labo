<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3 Corrélation et régression linéaire simple | BIO4558 Biostatistiques appliquées avec R</title>
  <meta name="description" content="Manuel de laboratoire pour le cours BIO4558" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="3 Corrélation et régression linéaire simple | BIO4558 Biostatistiques appliquées avec R" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="images/missing.png" />
  <meta property="og:description" content="Manuel de laboratoire pour le cours BIO4558" />
  <meta name="github-repo" content="JulienGAMartin/BIO4558_uOttawa_lab_manual" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3 Corrélation et régression linéaire simple | BIO4558 Biostatistiques appliquées avec R" />
  
  <meta name="twitter:description" content="Manuel de laboratoire pour le cours BIO4558" />
  <meta name="twitter:image" content="images/missing.png" />

<meta name="author" content="Julien Martin" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="analyse-de-puissance-avec-r-et-gpower.html"/>
<link rel="next" href="comparaison-de-deux-échantillons.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Note</a></li>
<li class="chapter" data-level="" data-path="préface.html"><a href="préface.html"><i class="fa fa-check"></i>Préface</a><ul>
<li class="chapter" data-level="" data-path="préface.html"><a href="préface.html#quelques-points-importants-à-retenir"><i class="fa fa-check"></i>Quelques points importants à retenir</a></li>
<li class="chapter" data-level="" data-path="préface.html"><a href="préface.html#quest-ce-que-r-et-pourquoi-lutiliser-dans-ce-cours"><i class="fa fa-check"></i>Qu’est-ce que R et pourquoi l’utiliser dans ce cours?</a></li>
<li class="chapter" data-level="" data-path="préface.html"><a href="préface.html#installation"><i class="fa fa-check"></i>Installation</a></li>
<li class="chapter" data-level="" data-path="préface.html"><a href="préface.html#instructions-générales-pour-les-laboratoires"><i class="fa fa-check"></i>Instructions générales pour les laboratoires</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introductionR.html"><a href="introductionR.html"><i class="fa fa-check"></i><b>1</b> Introduction à R</a><ul>
<li class="chapter" data-level="1.1" data-path="introductionR.html"><a href="introductionR.html#set-intro"><i class="fa fa-check"></i><b>1.1</b> Paquets et données requises pour le labo</a></li>
<li class="chapter" data-level="1.2" data-path="introductionR.html"><a href="introductionR.html#importer-et-exporter-des-données"><i class="fa fa-check"></i><b>1.2</b> Importer et exporter des données</a><ul>
<li class="chapter" data-level="1.2.1" data-path="introductionR.html"><a href="introductionR.html#ouvrir-un-fichier-de-données-en-format-.rdata"><i class="fa fa-check"></i><b>1.2.1</b> Ouvrir un fichier de données en format <code>.Rdata</code></a></li>
<li class="chapter" data-level="1.2.2" data-path="introductionR.html"><a href="introductionR.html#ouvrir-un-fichier-de-données-en-format-.csv"><i class="fa fa-check"></i><b>1.2.2</b> Ouvrir un fichier de données en format <code>.csv</code></a></li>
<li class="chapter" data-level="1.2.3" data-path="introductionR.html"><a href="introductionR.html#entrer-des-données"><i class="fa fa-check"></i><b>1.2.3</b> Entrer des données</a></li>
<li class="chapter" data-level="1.2.4" data-path="introductionR.html"><a href="introductionR.html#nettoyercorriger-des-données"><i class="fa fa-check"></i><b>1.2.4</b> Nettoyer/corriger des données</a></li>
<li class="chapter" data-level="1.2.5" data-path="introductionR.html"><a href="introductionR.html#exporter-des-données-à-partir-de-r."><i class="fa fa-check"></i><b>1.2.5</b> Exporter des données à partir de R.</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="introductionR.html"><a href="introductionR.html#examen-préliminaire-des-données"><i class="fa fa-check"></i><b>1.3</b> Examen préliminaire des données</a><ul>
<li class="chapter" data-level="1.3.1" data-path="introductionR.html"><a href="introductionR.html#sommaire-statistique"><i class="fa fa-check"></i><b>1.3.1</b> Sommaire statistique</a></li>
<li class="chapter" data-level="1.3.2" data-path="introductionR.html"><a href="introductionR.html#histogramme-densité-de-probabilité-empirique-boxplot-et-examen-visuel-de-la-normalité"><i class="fa fa-check"></i><b>1.3.2</b> Histogramme, densité de probabilité empirique, boxplot et examen visuel de la normalité</a></li>
<li class="chapter" data-level="1.3.3" data-path="introductionR.html"><a href="introductionR.html#diagrammes-de-dispersion-bivariés"><i class="fa fa-check"></i><b>1.3.3</b> Diagrammes de dispersion bivariés</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="introductionR.html"><a href="introductionR.html#créer-des-sous-ensembles-de-cas"><i class="fa fa-check"></i><b>1.4</b> Créer des sous-ensembles de cas</a></li>
<li class="chapter" data-level="1.5" data-path="introductionR.html"><a href="introductionR.html#transformations-de-données"><i class="fa fa-check"></i><b>1.5</b> Transformations de données</a></li>
<li class="chapter" data-level="1.6" data-path="introductionR.html"><a href="introductionR.html#exercice-sur-r"><i class="fa fa-check"></i><b>1.6</b> Exercice sur R</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="analyse-de-puissance-avec-r-et-gpower.html"><a href="analyse-de-puissance-avec-r-et-gpower.html"><i class="fa fa-check"></i><b>2</b> Analyse de puissance avec R et G*Power</a><ul>
<li class="chapter" data-level="2.1" data-path="analyse-de-puissance-avec-r-et-gpower.html"><a href="analyse-de-puissance-avec-r-et-gpower.html#la-théorie"><i class="fa fa-check"></i><b>2.1</b> La théorie</a><ul>
<li class="chapter" data-level="2.1.1" data-path="analyse-de-puissance-avec-r-et-gpower.html"><a href="analyse-de-puissance-avec-r-et-gpower.html#quest-ce-que-la-puissance"><i class="fa fa-check"></i><b>2.1.1</b> Qu’est-ce que la puissance?</a></li>
<li class="chapter" data-level="2.1.2" data-path="analyse-de-puissance-avec-r-et-gpower.html"><a href="analyse-de-puissance-avec-r-et-gpower.html#pourquoi-faire-une-analyse-de-puissance"><i class="fa fa-check"></i><b>2.1.2</b> Pourquoi faire une analyse de puissance?</a></li>
<li class="chapter" data-level="2.1.3" data-path="analyse-de-puissance-avec-r-et-gpower.html"><a href="analyse-de-puissance-avec-r-et-gpower.html#facteurs-qui-affectent-la-puissance"><i class="fa fa-check"></i><b>2.1.3</b> Facteurs qui affectent la puissance</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="analyse-de-puissance-avec-r-et-gpower.html"><a href="analyse-de-puissance-avec-r-et-gpower.html#quest-ce-que-gpower"><i class="fa fa-check"></i><b>2.2</b> Qu’est ce que G*Power?</a></li>
<li class="chapter" data-level="2.3" data-path="analyse-de-puissance-avec-r-et-gpower.html"><a href="analyse-de-puissance-avec-r-et-gpower.html#comment-utiliser-gpower"><i class="fa fa-check"></i><b>2.3</b> Comment utiliser G*Power</a><ul>
<li class="chapter" data-level="2.3.1" data-path="analyse-de-puissance-avec-r-et-gpower.html"><a href="analyse-de-puissance-avec-r-et-gpower.html#principe-général"><i class="fa fa-check"></i><b>2.3.1</b> Principe général</a></li>
<li class="chapter" data-level="2.3.2" data-path="analyse-de-puissance-avec-r-et-gpower.html"><a href="analyse-de-puissance-avec-r-et-gpower.html#types-danalyses-de-puissance-disponibles"><i class="fa fa-check"></i><b>2.3.2</b> Types d’analyses de puissance disponibles</a></li>
<li class="chapter" data-level="2.3.3" data-path="analyse-de-puissance-avec-r-et-gpower.html"><a href="analyse-de-puissance-avec-r-et-gpower.html#comment-calculer-la-taille-de-leffet-gpower-permet-de-faire-une-analyse-de-puissance-pour-de-nombreux-tests-statistiques"><i class="fa fa-check"></i><b>2.3.3</b> Comment calculer la taille de l’effet G*Power permet de faire une analyse de puissance pour de nombreux tests statistiques</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="analyse-de-puissance-avec-r-et-gpower.html"><a href="analyse-de-puissance-avec-r-et-gpower.html#puissance-pour-un-test-de-t-comparant-deux-moyennes"><i class="fa fa-check"></i><b>2.4</b> Puissance pour un test de t comparant deux moyennes</a><ul>
<li class="chapter" data-level="2.4.1" data-path="analyse-de-puissance-avec-r-et-gpower.html"><a href="analyse-de-puissance-avec-r-et-gpower.html#analyse-post-hoc"><i class="fa fa-check"></i><b>2.4.1</b> Analyse post-hoc</a></li>
<li class="chapter" data-level="2.4.2" data-path="analyse-de-puissance-avec-r-et-gpower.html"><a href="analyse-de-puissance-avec-r-et-gpower.html#analyse-à-priori"><i class="fa fa-check"></i><b>2.4.2</b> Analyse à priori</a></li>
<li class="chapter" data-level="2.4.3" data-path="analyse-de-puissance-avec-r-et-gpower.html"><a href="analyse-de-puissance-avec-r-et-gpower.html#analyse-de-sensitivité---calculer-la-taille-deffet-détectable"><i class="fa fa-check"></i><b>2.4.3</b> Analyse de sensitivité - Calculer la taille d’effet détectable</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="analyse-de-puissance-avec-r-et-gpower.html"><a href="analyse-de-puissance-avec-r-et-gpower.html#points-à-retenir"><i class="fa fa-check"></i><b>2.5</b> Points à retenir</a></li>
<li class="chapter" data-level="2.6" data-path="analyse-de-puissance-avec-r-et-gpower.html"><a href="analyse-de-puissance-avec-r-et-gpower.html#exercice-sur-la-puissance"><i class="fa fa-check"></i><b>2.6</b> Exercice sur la puissance</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="corrélation-et-régression-linéaire-simple.html"><a href="corrélation-et-régression-linéaire-simple.html"><i class="fa fa-check"></i><b>3</b> Corrélation et régression linéaire simple</a><ul>
<li class="chapter" data-level="3.1" data-path="corrélation-et-régression-linéaire-simple.html"><a href="corrélation-et-régression-linéaire-simple.html#set-lm"><i class="fa fa-check"></i><b>3.1</b> Paquets et données requises pour le labo</a></li>
<li class="chapter" data-level="3.2" data-path="corrélation-et-régression-linéaire-simple.html"><a href="corrélation-et-régression-linéaire-simple.html#diagrammes-de-dispersion"><i class="fa fa-check"></i><b>3.2</b> Diagrammes de dispersion</a></li>
<li class="chapter" data-level="3.3" data-path="corrélation-et-régression-linéaire-simple.html"><a href="corrélation-et-régression-linéaire-simple.html#transformations-et-le-coefficient-de-corrélation"><i class="fa fa-check"></i><b>3.3</b> Transformations et le coefficient de corrélation</a></li>
<li class="chapter" data-level="3.4" data-path="corrélation-et-régression-linéaire-simple.html"><a href="corrélation-et-régression-linéaire-simple.html#matrices-de-corrélations-et-correction-de-bonferroni"><i class="fa fa-check"></i><b>3.4</b> Matrices de corrélations et correction de Bonferroni</a></li>
<li class="chapter" data-level="3.5" data-path="corrélation-et-régression-linéaire-simple.html"><a href="corrélation-et-régression-linéaire-simple.html#corrélations-non-paramétriques-r-de-spearman-et-tau-de-kendall"><i class="fa fa-check"></i><b>3.5</b> Corrélations non paramétriques: r de Spearman et tau de Kendall</a></li>
<li class="chapter" data-level="3.6" data-path="corrélation-et-régression-linéaire-simple.html"><a href="corrélation-et-régression-linéaire-simple.html#régression-linéaire-simple"><i class="fa fa-check"></i><b>3.6</b> Régression linéaire simple</a><ul>
<li class="chapter" data-level="3.6.1" data-path="corrélation-et-régression-linéaire-simple.html"><a href="corrélation-et-régression-linéaire-simple.html#vérifier-les-conditions-dapplication-de-la-régression"><i class="fa fa-check"></i><b>3.6.1</b> Vérifier les conditions d’application de la régression</a></li>
<li class="chapter" data-level="3.6.2" data-path="corrélation-et-régression-linéaire-simple.html"><a href="corrélation-et-régression-linéaire-simple.html#tests-formels-des-conditions-dapplication-pour-la-régression"><i class="fa fa-check"></i><b>3.6.2</b> Tests formels des conditions d’application pour la régression</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="corrélation-et-régression-linéaire-simple.html"><a href="corrélation-et-régression-linéaire-simple.html#transformation-des-données-en-régression"><i class="fa fa-check"></i><b>3.7</b> Transformation des données en régression</a></li>
<li class="chapter" data-level="3.8" data-path="corrélation-et-régression-linéaire-simple.html"><a href="corrélation-et-régression-linéaire-simple.html#traitement-des-valeurs-extrèmes"><i class="fa fa-check"></i><b>3.8</b> Traitement des valeurs extrèmes</a></li>
<li class="chapter" data-level="3.9" data-path="corrélation-et-régression-linéaire-simple.html"><a href="corrélation-et-régression-linéaire-simple.html#quantifier-la-taille-deffet-et-analyse-de-puissance-en-régression"><i class="fa fa-check"></i><b>3.9</b> Quantifier la taille d’effet et analyse de puissance en régression</a><ul>
<li class="chapter" data-level="3.9.1" data-path="corrélation-et-régression-linéaire-simple.html"><a href="corrélation-et-régression-linéaire-simple.html#puissance-de-détecter-une-pente-donnée"><i class="fa fa-check"></i><b>3.9.1</b> Puissance de détecter une pente donnée</a></li>
<li class="chapter" data-level="3.9.2" data-path="corrélation-et-régression-linéaire-simple.html"><a href="corrélation-et-régression-linéaire-simple.html#effectif-requis-pour-atteindre-une-puissance-désirée-test-a-priori"><i class="fa fa-check"></i><b>3.9.2</b> Effectif requis pour atteindre une puissance désirée (test A-priori)</a></li>
</ul></li>
<li class="chapter" data-level="3.10" data-path="corrélation-et-régression-linéaire-simple.html"><a href="corrélation-et-régression-linéaire-simple.html#bootstrap-en-régression-simple-avec-r"><i class="fa fa-check"></i><b>3.10</b> Bootstrap en régression simple avec R</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="comparaison-de-deux-échantillons.html"><a href="comparaison-de-deux-échantillons.html"><i class="fa fa-check"></i><b>4</b> Comparaison de deux échantillons</a><ul>
<li class="chapter" data-level="4.1" data-path="comparaison-de-deux-échantillons.html"><a href="comparaison-de-deux-échantillons.html#set-t"><i class="fa fa-check"></i><b>4.1</b> Paquets et données requises pour le labo</a></li>
<li class="chapter" data-level="4.2" data-path="comparaison-de-deux-échantillons.html"><a href="comparaison-de-deux-échantillons.html#examen-visuel-des-données"><i class="fa fa-check"></i><b>4.2</b> Examen visuel des données</a></li>
<li class="chapter" data-level="4.3" data-path="comparaison-de-deux-échantillons.html"><a href="comparaison-de-deux-échantillons.html#comparer-les-moyennes-de-deux-échantillons-indépendants"><i class="fa fa-check"></i><b>4.3</b> Comparer les moyennes de deux échantillons indépendants</a></li>
<li class="chapter" data-level="4.4" data-path="comparaison-de-deux-échantillons.html"><a href="comparaison-de-deux-échantillons.html#bootstrap-et-tests-de-permutation-pour-comparer-deux-moyennes"><i class="fa fa-check"></i><b>4.4</b> Bootstrap et tests de permutation pour comparer deux moyennes</a><ul>
<li class="chapter" data-level="4.4.1" data-path="comparaison-de-deux-échantillons.html"><a href="comparaison-de-deux-échantillons.html#bootstrap"><i class="fa fa-check"></i><b>4.4.1</b> Bootstrap</a></li>
<li class="chapter" data-level="4.4.2" data-path="comparaison-de-deux-échantillons.html"><a href="comparaison-de-deux-échantillons.html#permutation"><i class="fa fa-check"></i><b>4.4.2</b> Permutation</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="comparaison-de-deux-échantillons.html"><a href="comparaison-de-deux-échantillons.html#comparer-les-moyennes-de-deux-échantillons-appariés"><i class="fa fa-check"></i><b>4.5</b> Comparer les moyennes de deux échantillons appariés</a></li>
<li class="chapter" data-level="4.6" data-path="comparaison-de-deux-échantillons.html"><a href="comparaison-de-deux-échantillons.html#références"><i class="fa fa-check"></i><b>4.6</b> Références</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="anova-à-un-critère-de-classification.html"><a href="anova-à-un-critère-de-classification.html"><i class="fa fa-check"></i><b>5</b> ANOVA à un critère de classification</a><ul>
<li class="chapter" data-level="5.1" data-path="anova-à-un-critère-de-classification.html"><a href="anova-à-un-critère-de-classification.html#set-ano"><i class="fa fa-check"></i><b>5.1</b> Paquets et données requises pour le labo</a></li>
<li class="chapter" data-level="5.2" data-path="anova-à-un-critère-de-classification.html"><a href="anova-à-un-critère-de-classification.html#anova-à-un-critère-de-classification-et-comparaisons-multiples"><i class="fa fa-check"></i><b>5.2</b> ANOVA à un critère de classification et comparaisons multiples</a><ul>
<li class="chapter" data-level="5.2.1" data-path="anova-à-un-critère-de-classification.html"><a href="anova-à-un-critère-de-classification.html#visualiser-les-données"><i class="fa fa-check"></i><b>5.2.1</b> Visualiser les données</a></li>
<li class="chapter" data-level="5.2.2" data-path="anova-à-un-critère-de-classification.html"><a href="anova-à-un-critère-de-classification.html#vérifier-les-conditions-dapplication-de-lanova-paramétrique"><i class="fa fa-check"></i><b>5.2.2</b> Vérifier les conditions d’application de l’ANOVA paramétrique</a></li>
<li class="chapter" data-level="5.2.3" data-path="anova-à-un-critère-de-classification.html"><a href="anova-à-un-critère-de-classification.html#faire-lanova"><i class="fa fa-check"></i><b>5.2.3</b> Faire l’ANOVA</a></li>
<li class="chapter" data-level="5.2.4" data-path="anova-à-un-critère-de-classification.html"><a href="anova-à-un-critère-de-classification.html#les-comparaisons-multiples"><i class="fa fa-check"></i><b>5.2.4</b> Les comparaisons multiples</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="anova-à-un-critère-de-classification.html"><a href="anova-à-un-critère-de-classification.html#transformations-de-données-et-anova-non-paramétrique"><i class="fa fa-check"></i><b>5.3</b> Transformations de données et ANOVA non-paramétrique</a></li>
<li class="chapter" data-level="5.4" data-path="anova-à-un-critère-de-classification.html"><a href="anova-à-un-critère-de-classification.html#examen-des-valeurs-extrêmes"><i class="fa fa-check"></i><b>5.4</b> Examen des valeurs extrêmes</a></li>
<li class="chapter" data-level="5.5" data-path="anova-à-un-critère-de-classification.html"><a href="anova-à-un-critère-de-classification.html#test-de-permutation"><i class="fa fa-check"></i><b>5.5</b> Test de permutation</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">BIO4558 Biostatistiques appliquées avec R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="corrélation-et-régression-linéaire-simple" class="section level1">
<h1><span class="header-section-number">3</span> Corrélation et régression linéaire simple</h1>
<p>Après avoir complété cet exercice de laboratoire, vous devriez être en mesure de :</p>
<ul>
<li>Utiliser R pour produire un diagramme de dispersion pour illus-
trer la relation entre deux variables avec trace lowess</li>
<li>Utiliser R pour faire des transformations simples</li>
<li>Utiliser R pour calculer le coefficient de corrélation de Pearson entre deux variables et en évaluer sa signification statistique</li>
<li>Utiliser R pour calculer la corrélation de rang entre des paires de variables avec le r de Spearman et le tau de Kendall</li>
<li>Utiliser R pour évaluer la signification de corrélations dans une matrice de corrélation en utilisant les probabilités ajustées par la méthode de Bonferroni.</li>
<li>Utiliser R pour faire une régression linéaire simple.</li>
<li>Utiliser R pour évaluer si un ensemble de données remplit les conditions d’application d’une analyse de régression simple.</li>
<li>Quantifier la taille de l’effet d’une régression simple et effectuer une analyse de puissance avec G*Power.</li>
</ul>
<div id="set-lm" class="section level2">
<h2><span class="header-section-number">3.1</span> Paquets et données requises pour le labo</h2>
<p>Ce laboratoire nécessite:</p>
<ul>
<li>les paquets R:
<ul>
<li>car</li>
<li>lmtest</li>
<li>boot</li>
</ul></li>
<li>les fichiers de données
<ul>
<li>sturgeon.csv</li>
</ul></li>
</ul>
</div>
<div id="diagrammes-de-dispersion" class="section level2">
<h2><span class="header-section-number">3.2</span> Diagrammes de dispersion</h2>
<p>Les analyses de corrélation et de régression devraient toujours commencer par un examen des données.C’est une étape critique qui sert à évaluer si ce type d’analyse est approprié pour un ensemble de données.
Supposons que nous sommes intéressés à évaluer si la longueur d’esturgeons mâles dans la région de <em>The Pas</em> covarie avec leur poids.
Pour répondre à cette question, regardons d’abord la corrélation entre
la longueur et le poids.
Souvenez-vous qu’une des conditions d’application de l’analyse de
corrélation est que la relation entre les deux variables est linéaire. Pour
évaluer cela, commençons par faire un diagramme de dispersion.</p>
<ul>
<li>Les données sur les esturgeons son disponibles dans le fichier <code>sturgeon.csv</code>.
Après avoir chargé les données dnas un objet <code>sturgeon</code>, faites un diagramme de dispersion avec une droite de régression et une courbe LOWESS de la longueur en fonction du poids.</li>
</ul>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb28-1" title="1">sturgeon &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;data/sturgeon.csv&quot;</span>)</a>
<a class="sourceLine" id="cb28-2" title="2"><span class="kw">str</span>(sturgeon)</a></code></pre></div>
<pre><code>## &#39;data.frame&#39;:	186 obs. of  9 variables:
##  $ fklngth : num  37 50.2 28.9 50.2 45.6 ...
##  $ totlngth: num  40.7 54.1 31.3 53.1 49.5 ...
##  $ drlngth : num  23.6 31.5 17.3 32.3 32.1 ...
##  $ rdwght  : num  15.95 NA 6.49 NA 29.92 ...
##  $ age     : int  11 24 7 23 20 23 20 7 23 19 ...
##  $ girth   : num  40.5 53.5 31 52.5 50 54.2 48 28.5 44 39 ...
##  $ sex     : chr  &quot;MALE&quot; &quot;FEMALE&quot; &quot;MALE&quot; &quot;FEMALE&quot; ...
##  $ location: chr  &quot;THE_PAS&quot; &quot;THE_PAS&quot; &quot;THE_PAS&quot; &quot;THE_PAS&quot; ...
##  $ year    : int  1978 1978 1978 1978 1978 1978 1978 1978 1978 1978 ...</code></pre>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb30-1" title="1">mygraph&lt;-<span class="kw">ggplot</span>(</a>
<a class="sourceLine" id="cb30-2" title="2">  <span class="dt">data =</span> sturgeon[<span class="op">!</span><span class="kw">is.na</span>(sturgeon<span class="op">$</span>rdwght),], <span class="co"># source of data</span></a>
<a class="sourceLine" id="cb30-3" title="3">  <span class="kw">aes</span>(<span class="dt">x =</span> fklngth, <span class="dt">y =</span> rdwght))</a>
<a class="sourceLine" id="cb30-4" title="4"><span class="co"># plot data points, regression, loess trace</span></a>
<a class="sourceLine" id="cb30-5" title="5">mygraph &lt;-<span class="st"> </span>mygraph <span class="op">+</span></a>
<a class="sourceLine" id="cb30-6" title="6"><span class="st">  </span><span class="kw">stat_smooth</span>(<span class="dt">method=</span>lm, <span class="dt">se=</span><span class="ot">FALSE</span>, <span class="dt">color=</span><span class="st">&quot;green&quot;</span>) <span class="op">+</span><span class="st"> </span><span class="co"># add linear regression, but no SE shading</span></a>
<a class="sourceLine" id="cb30-7" title="7"><span class="st">  </span><span class="kw">stat_smooth</span>(<span class="dt">color=</span><span class="st">&quot;red&quot;</span>, <span class="dt">se=</span><span class="ot">FALSE</span>) <span class="op">+</span><span class="st"> </span><span class="co">#add loess</span></a>
<a class="sourceLine" id="cb30-8" title="8"><span class="st">  </span><span class="kw">geom_point</span>() <span class="co"># add data points</span></a>
<a class="sourceLine" id="cb30-9" title="9"></a>
<a class="sourceLine" id="cb30-10" title="10">mygraph <span class="co"># display graph</span></a></code></pre></div>
<div class="figure"><span id="fig:stur-2"></span>
<img src="Labo_BIO4558_files/figure-html/stur-2-1.png" alt="Graphique du poids en fonction de la longueur des esturgeons" width="672" />
<p class="caption">
Figure 3.1: Graphique du poids en fonction de la longueur des esturgeons
</p>
</div>
<!-- (notez ici la gymnastique requise pour éliminer les données
manquantes qui posent problème pour obtenir la trace loess). -->
<ul>
<li>Est-ce que la dispersion des points suggère une bonne corrélation entre les deux variables?
Est-ce que la relation semble linéaire?</li>
</ul>
<p>Ce graphique suggère une tendance plus curvilinéaire que linéaire.
Malgré tout, il semble y avoir une forte corrélation entre les deux variables.</p>
<ul>
<li>Refaites le diagramme de dispersion avec des axes logarithmiques.</li>
</ul>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb31-1" title="1"><span class="co"># apply log transformation on defined graph</span></a>
<a class="sourceLine" id="cb31-2" title="2">mygraph <span class="op">+</span><span class="st"> </span><span class="kw">scale_x_log10</span>() <span class="op">+</span><span class="st"> </span><span class="kw">scale_y_log10</span>()</a></code></pre></div>
<div class="figure"><span id="fig:stur-log"></span>
<img src="Labo_BIO4558_files/figure-html/stur-log-1.png" alt="Graphique poids-longueur avec une échelle log" width="672" />
<p class="caption">
Figure 3.2: Graphique poids-longueur avec une échelle log
</p>
</div>
<p>Comparez les diagrammes de dispersion avant et après transformation (Figures <a href="corrélation-et-régression-linéaire-simple.html#fig:stur-2">3.1</a> et <a href="corrélation-et-régression-linéaire-simple.html#fig:stur-log">3.2</a>). Comme l’analyse de corrélation présuppose une relation linéaire entre les variables, on devrait donc privilégier l’analyse sur les données log-transformées.</p>
</div>
<div id="transformations-et-le-coefficient-de-corrélation" class="section level2">
<h2><span class="header-section-number">3.3</span> Transformations et le coefficient de corrélation</h2>
<p>Une autre condition préalable à l’analyse de corrélation est que les deux variables concernées suivent une distribution normale bidimensionnelle.
On peut aisément vérifier la normalité de chacune des 2 variables séparément tel que décrit dans le laboratoire précédent.
Si les deux variables sont normalement distribuées, on présume généralement qu’elles suivent une distribution normale bidimensionnelle lorsqu’analysées simultanément (notez que ce n’est pas toujours le cas cependant).</p>
<ul>
<li>Examinez la distribution des quatre variables (les deux variables originales et les variables transformées). Que concluez-vous de l’inspection visuelle de ces graphiques ?</li>
</ul>
<p>Les figures ci-dessous sont les diagrammes de probabilité (<code>qqplot()</code>).
Le code pour produire des graphiques multiples sur une page, comme
on voit ci-dessous, est:</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb32-1" title="1"><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>)) <span class="co"># divise le graphique en 4 sections</span></a>
<a class="sourceLine" id="cb32-2" title="2"><span class="kw">qqnorm</span>(sturgeon<span class="op">$</span>fklngth,<span class="dt">ylab=</span><span class="st">&quot;fklngth&quot;</span>)</a>
<a class="sourceLine" id="cb32-3" title="3"><span class="kw">qqline</span>(sturgeon<span class="op">$</span>fklngth)</a>
<a class="sourceLine" id="cb32-4" title="4"><span class="kw">qqnorm</span>(<span class="kw">log10</span>(sturgeon<span class="op">$</span>fklngth),<span class="dt">ylab=</span><span class="st">&quot;log10(fklngth)&quot;</span>)</a>
<a class="sourceLine" id="cb32-5" title="5"><span class="kw">qqline</span>(<span class="kw">log10</span>(sturgeon<span class="op">$</span>fklngth))</a>
<a class="sourceLine" id="cb32-6" title="6"><span class="kw">qqnorm</span>(sturgeon<span class="op">$</span>rdwght,<span class="dt">ylab=</span><span class="st">&quot;rdwght&quot;</span>)</a>
<a class="sourceLine" id="cb32-7" title="7"><span class="kw">qqline</span>(sturgeon<span class="op">$</span>rdwght)</a>
<a class="sourceLine" id="cb32-8" title="8"><span class="kw">qqnorm</span>(<span class="kw">log10</span>(sturgeon<span class="op">$</span>rdwght),<span class="dt">ylab=</span><span class="st">&quot;log10(rdwgth)&quot;</span>)</a>
<a class="sourceLine" id="cb32-9" title="9"><span class="kw">qqline</span>(<span class="kw">log10</span>(sturgeon<span class="op">$</span>rdwght))</a></code></pre></div>
<p><img src="Labo_BIO4558_files/figure-html/stur-4hist-1.png" width="672" /></p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb33-1" title="1"><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>)) <span class="co">#redéfinie la zone de graphique par défaut</span></a></code></pre></div>
<p>Il n’y a pas grand-chose à redire: aucune des distributions n’est
parfaitement normale, mais les déviations semblent mineures.</p>
<ul>
<li>Générez une matrice de graphiques de dispersion améliorés en utilisant la commande <code>scatterplotMatrix</code> de la librairie <code>car</code>.</li>
</ul>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb34-1" title="1"><span class="kw">scatterplotMatrix</span>(</a>
<a class="sourceLine" id="cb34-2" title="2">  <span class="op">~</span>fklngth<span class="op">+</span><span class="kw">log10</span>(fklngth)<span class="op">+</span>rdwght<span class="op">+</span><span class="kw">log10</span>(rdwght),</a>
<a class="sourceLine" id="cb34-3" title="3">  <span class="dt">data=</span> sturgeon,</a>
<a class="sourceLine" id="cb34-4" title="4">  <span class="dt">smooth=</span><span class="ot">TRUE</span>, <span class="dt">diagonal =</span> <span class="st">&#39;density&#39;</span>)</a></code></pre></div>
<pre><code>## Warning in applyDefaults(diagonal, defaults = list(method =
## &quot;adaptiveDensity&quot;), : unnamed diag arguments, will be ignored</code></pre>
<p><img src="Labo_BIO4558_files/figure-html/stur-scatmat-1.png" width="672" /></p>
<ul>
<li>Ensuite, calculez le coefficient de corrélation de Pearson entre chaque paire (variables originales et logtransformées ) en utilisant la commande <code>cor()</code>.
Avant de commencer, on va cependant ajouter les variables transformées au tableau de données sturgeon:</li>
</ul>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb36-1" title="1">sturgeon<span class="op">$</span>lfklngth &lt;-<span class="st"> </span><span class="kw">with</span>(sturgeon, <span class="kw">log10</span>(fklngth))</a>
<a class="sourceLine" id="cb36-2" title="2">sturgeon<span class="op">$</span>lrdwght &lt;-<span class="st"> </span><span class="kw">log10</span>(sturgeon<span class="op">$</span>rdwght)</a></code></pre></div>
<p>Vous pouvez ensuite obtenir la matrice de corrélation par:</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb37-1" title="1"><span class="kw">cor</span>(sturgeon[,<span class="kw">c</span>(<span class="st">&quot;fklngth&quot;</span>,<span class="st">&quot;lfklngth&quot;</span>,<span class="st">&quot;lrdwght&quot;</span>,<span class="st">&quot;rdwght&quot;</span>)], <span class="dt">use=</span><span class="st">&quot;complete.obs&quot;</span>)</a></code></pre></div>
<p>Fréquemment, il y a des données manquantes dans un échantillon.
En choisissant <code>use="complete.obs"</code>, toutes les lignes du fichier pour lesquelles les variables ne sont pas toutes mesurées sont éliminées.
Dans ce cas, toutes les corrélations seront calculées avec le même nombre de cas.
Par contre, en utilisant <code>use="pairwise.complete.obs"</code> ,
R élimine une observation que lorsqu’un des deux membres de la paire a une valeur manquante.
Dans ce cas, si les données manquantes pour différentes variables se retrouvent dans un groupe différent d’observation, les corrélations ne seront pas nécessairement calculées sur le même nombre de cas ni sur le même sous-ensemble de cas.
En général, vous devriez utiliser l’option <code>use="complete.obs"</code> à moins que vous ayez un très grand nombre de données manquantes et que cette façon de procéder élimine la plus grande partie de vos
observations.</p>
<p>Pourquoi la corrélation entre les variables originales est-elle la plus faible des trois ?</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb38-1" title="1"><span class="kw">cor</span>(sturgeon[,<span class="kw">c</span>(<span class="st">&quot;fklngth&quot;</span>,<span class="st">&quot;lfklngth&quot;</span>,<span class="st">&quot;lrdwght&quot;</span>,<span class="st">&quot;rdwght&quot;</span>)], <span class="dt">use=</span><span class="st">&quot;complete.obs&quot;</span>)</a></code></pre></div>
<pre><code>##            fklngth  lfklngth   lrdwght    rdwght
## fklngth  1.0000000 0.9921435 0.9645108 0.9175435
## lfklngth 0.9921435 1.0000000 0.9670139 0.8756203
## lrdwght  0.9645108 0.9670139 1.0000000 0.9265513
## rdwght   0.9175435 0.8756203 0.9265513 1.0000000</code></pre>
<p>Il y a plusieurs choses à noter ici.</p>
<ul>
<li>Premièrement, la corrélation entre la longueur à la fourche et le poids rond est élevée, peu importe la transformation: les poissons lourds ont tendance à être longs.</li>
<li>Deuxièmement, la corrélation est plus forte pour les données
transformées que pour les données brutes.</li>
</ul>
<p><strong>Pourquoi?</strong> Parce que le coefficient de corrélation est inversement proportionnel au bruit autour de la relation linéaire.
Si la relation est curvilinéaire (comme dans le cas des données non transformées), le bruit est plus grand que si la relation est parfaitement linéaire.
Par conséquent, la corrélation est plus faible.</p>
</div>
<div id="matrices-de-corrélations-et-correction-de-bonferroni" class="section level2">
<h2><span class="header-section-number">3.4</span> Matrices de corrélations et correction de Bonferroni</h2>
<p>Une pratique courante est d’examiner une matrice de corrélation à la recherche des associations significatives.
Comme exemple, essayons de tester si la corrélation entre lfklngth et rdwght est significative (c’est le plus faible coefficient de corrélation de cette matrice).</p>
<ul>
<li>Estimer la correlation entre la longueur (fklngth) et le poids (rdwght) des esturgeons:</li>
</ul>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb40-1" title="1"><span class="kw">cor.test</span>(</a>
<a class="sourceLine" id="cb40-2" title="2">  sturgeon<span class="op">$</span>lfklngth, sturgeon<span class="op">$</span>rdwght,</a>
<a class="sourceLine" id="cb40-3" title="3">  <span class="dt">alternative=</span><span class="st">&quot;two.sided&quot;</span>,</a>
<a class="sourceLine" id="cb40-4" title="4">  <span class="dt">method=</span><span class="st">&quot;pearson&quot;</span>)</a></code></pre></div>
<pre><code>## 
## 	Pearson&#39;s product-moment correlation
## 
## data:  sturgeon$lfklngth and sturgeon$rdwght
## t = 24.322, df = 180, p-value &lt; 2.2e-16
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  0.8367345 0.9057199
## sample estimates:
##       cor 
## 0.8756203</code></pre>
<p>On voit ici que la corrélation est hautement significative (p&lt; 2.2e-16),ce qui n’est pas surprenant étant donné la valeur du coefficient de corrélation (0.8756).
Il est important de réaliser que si une matrice contient un grand nombre de corrélations, il n’est pas surprenant d’en trouver au moins une qui soit “significative”.
En effet, on s’attend à en trouver 5% en moyenne lorsqu’il n’y a en fait aucune corrélation entre les paires de moyennes.
Une façon de corriger pour cette tendance est d’ajuster le niveau <span class="math inline">\(\alpha\)</span> critique auquel on attribue une signification statistique en divisant <span class="math inline">\(\alpha\)</span> par le nombre <span class="math inline">\(k\)</span> de corrélations qui sont examinées : <span class="math inline">\(\alpha&#39; = \alpha / k\)</span> (ajustement de Bonferroni). Si initialement <span class="math inline">\(\alpha = 0.05\)</span> et qu’il y a 10 corrélations qui sont examinées, alors <span class="math inline">\(\alpha&#39;= 0.005\)</span>.
Donc, afin de rejeter l’hypothèse nulle, la valeur de p devra être plus petite que <span class="math inline">\(\alpha&#39;\)</span>, en l’occurrence 0.005.
Dans l’exemple qui précède, on devrait donc ajuster <span class="math inline">\(\alpha\)</span> critique en divisant par le nombre total de corrélations dans la matrice (6 dans ce cas, donc <span class="math inline">\(\alpha&#39;=0.00833\)</span>).
Cette correction modifie-t-elle votre conclusion quant à la corrélation entre <code>lkfl</code> et <code>rdwght</code>?</p>
</div>
<div id="corrélations-non-paramétriques-r-de-spearman-et-tau-de-kendall" class="section level2">
<h2><span class="header-section-number">3.5</span> Corrélations non paramétriques: r de Spearman et tau de Kendall</h2>
<p>L’analyse faite à la section précédente avec les esturgeons suggère que l’une des conditions préalables à l’analyse de corrélation, soit la distribution normale bidimensionnelle de données, pourrait ne pas être remplie pour <code>fklngth</code> et <code>rdwght</code>, ni pour les paires de variables transformées.
La recherche d’une transformation appropriée peut parfois être difficile.
Pire encore, pour certaines distributions il n’existe pas de transformation qui va normaliser les données.
Dans ces cas-là, la meilleure option est de faire une analyse non
paramétrique qui ne présume ni de la normalité ni de la linéarité.
Ces analyses sont basées sur les rangs.
Les deux plus communes sont le coefficient de rang de Spearman et le tau de Kendall.</p>
<ul>
<li>Dans R, testez la corrélation entre <code>fklngth</code> et <code>rdwght</code> en utilisant Spearman et Kendall’s .</li>
</ul>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb42-1" title="1"><span class="kw">cor.test</span>(</a>
<a class="sourceLine" id="cb42-2" title="2">  sturgeon<span class="op">$</span>lfklngth, sturgeon<span class="op">$</span>rdwght,</a>
<a class="sourceLine" id="cb42-3" title="3">  <span class="dt">alternative=</span><span class="st">&quot;two.sided&quot;</span>,</a>
<a class="sourceLine" id="cb42-4" title="4">  <span class="dt">method=</span><span class="st">&quot;spearman&quot;</span>)</a></code></pre></div>
<pre><code>## Warning in cor.test.default(sturgeon$lfklngth, sturgeon$rdwght, alternative =
## &quot;two.sided&quot;, : Cannot compute exact p-value with ties</code></pre>
<pre><code>## 
## 	Spearman&#39;s rank correlation rho
## 
## data:  sturgeon$lfklngth and sturgeon$rdwght
## S = 47971, p-value &lt; 2.2e-16
## alternative hypothesis: true rho is not equal to 0
## sample estimates:
##       rho 
## 0.9522546</code></pre>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb45-1" title="1"><span class="kw">cor.test</span>(</a>
<a class="sourceLine" id="cb45-2" title="2">  sturgeon<span class="op">$</span>lfklngth, sturgeon<span class="op">$</span>rdwght,</a>
<a class="sourceLine" id="cb45-3" title="3">  <span class="dt">alternative=</span><span class="st">&quot;two.sided&quot;</span>,</a>
<a class="sourceLine" id="cb45-4" title="4">  <span class="dt">method=</span><span class="st">&quot;pearson&quot;</span>)</a></code></pre></div>
<pre><code>## 
## 	Pearson&#39;s product-moment correlation
## 
## data:  sturgeon$lfklngth and sturgeon$rdwght
## t = 24.322, df = 180, p-value &lt; 2.2e-16
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  0.8367345 0.9057199
## sample estimates:
##       cor 
## 0.8756203</code></pre>
<p>Comparer les résultats de cette analyse à l’analyse paramétrique.
Pourquoi y-a-t’il une différence ?</p>
<p>Calculez les corrélations non paramétriques sur les paires de variables transformées.
Vous devriez voir tout de suite que les corrélations des données transformées et non transformées sont identiques puisque dans les deux cas la corrélation est calculée à partir des rangs qui ne sont pas affectés par la transformation.</p>
<p>Notez que les corrélations obtenues avec le tau de Kendall (0.820) sont plus faibles que celles du coefficient de Spearman (0.952).
Le tau de Kendall pondère un peu plus les grandes différences entre les rangs alors que le coefficient de Spearman donne le même poids à chaque paire d’observations.
En général, on préfère le tau de Kendall lorsqu’il y a plus d’incertitude quant aux rangs qui sont près les uns des autres.</p>
<p>Les esturgeons de cet échantillon ont été capturés à l’aide de filets et d’hameçons d’une taille fixe.
Quel impact cette méthode de capture peut-elle avoir eu sur la forme de la distribution de <code>fklngth</code> et <code>rdwght</code>?
Compte tenu de ces circonstances, l’analyse de corrélation est-elle appropriée ?</p>
<p>Rappelez-vous que l’analyse de corrélation présume aussi que chaque variable est échantillonnée aléatoirement.
Dans le cas de nos esturgeons, ce n’est pas le cas: les hameçons appâtés et les filets ne capturent pas de petits esturgeons (et c’est pourquoi il n’y en a pas dans l’échantillon).
Il faut donc réaliser que les coefficients de corrélation obtenus dans cette analyse ne reflètent pas nécessairement ceux de la population totale des esturgeons.</p>
</div>
<div id="régression-linéaire-simple" class="section level2">
<h2><span class="header-section-number">3.6</span> Régression linéaire simple</h2>
<p>L’analyse de corrélation vise à décrire comment deux variables covarient.
L’analyse de régression vise plutôt à produire un modèle permettant de prédire une variable (la variable dépendante) par l’autre (la variable indépendante).</p>
<p>Comme pour l’analyse de corrélation, on devrait commencer en examinant des graphiques.
Puisque l’on est intéressé à quantifier la relation entre deux variables, un graphique de la variable dépendante (Y) en fonction de la variable indépendante (X) est tout à fait approprié.</p>
<ul>
<li>Le fichier <code>sturgeon.csv</code> contient des données d’un inventaire des esturgeons récoltés en 1978-1980 à Cumberland House en Saskatchewan et à The Pas au Manitoba.
Faites un diagramme de dispersion de <code>fklngth</code> (la variable dépendante) en fonction de <code>age</code> (la variable indépendante) pour les esturgeons mâles unqiuement et ajoutez-y une régression linéaire et une trace lowess.
Que concluez-vous de ce diagramme de dispersion ?</li>
</ul>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb47-1" title="1">sturgeon.male &lt;-<span class="st"> </span><span class="kw">subset</span>(sturgeon, <span class="dt">subset =</span> sex <span class="op">==</span><span class="st"> &quot;MALE&quot;</span>)</a>
<a class="sourceLine" id="cb47-2" title="2">mygraph &lt;-<span class="st"> </span><span class="kw">ggplot</span>(</a>
<a class="sourceLine" id="cb47-3" title="3">  <span class="dt">data=</span>sturgeon.male, <span class="co"># source of data</span></a>
<a class="sourceLine" id="cb47-4" title="4">  <span class="kw">aes</span>(<span class="dt">x=</span>age, <span class="dt">y=</span>fklngth)) <span class="co">#aesthetics: y=fklngth, x=rdwght</span></a>
<a class="sourceLine" id="cb47-5" title="5"><span class="co"># plot data points, regression, loess trace</span></a>
<a class="sourceLine" id="cb47-6" title="6">mygraph &lt;-<span class="st"> </span>mygraph <span class="op">+</span></a>
<a class="sourceLine" id="cb47-7" title="7"><span class="st">  </span><span class="kw">stat_smooth</span>(<span class="dt">method=</span>lm, <span class="dt">se=</span><span class="ot">FALSE</span>, <span class="dt">color=</span><span class="st">&quot;green&quot;</span>) <span class="op">+</span><span class="st"> </span><span class="co"># add linear regression, but no SE shading</span></a>
<a class="sourceLine" id="cb47-8" title="8"><span class="st">  </span><span class="kw">stat_smooth</span>(<span class="dt">color=</span><span class="st">&quot;red&quot;</span>) <span class="op">+</span><span class="st"> </span><span class="co">#add loess</span></a>
<a class="sourceLine" id="cb47-9" title="9"><span class="st">  </span><span class="kw">geom_point</span>() <span class="co"># add data points</span></a>
<a class="sourceLine" id="cb47-10" title="10">mygraph <span class="co"># display graph</span></a></code></pre></div>
<p><img src="Labo_BIO4558_files/figure-html/sturlm-1-1.png" width="672" /></p>
<p>Ce graphique suggère que la relation n’est pas linéaire.</p>
<p>Supposons que nous désirions estimer le taux de croissance des esturgeons mâles.
Un estimé (peut-être pas terrible…) du taux de croissance peut être obtenu en calculant la pente de la régression de la longueur à la fourche sur l’âge.</p>
<p>Ajustons d’abord une régression avec la commande lm() et sauvons ces résultats dans un objet appelé <code>RegModel.1</code>.</p>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb48-1" title="1">RegModel<span class="fl">.1</span> &lt;-<span class="st"> </span><span class="kw">lm</span>(fklngth <span class="op">~</span><span class="st"> </span>age, <span class="dt">data =</span> sturgeon.male)</a></code></pre></div>
<p>Rien n’apparait à l’écran, c’est normal ne vous inquiétez pas, tout a été sauvegardé en mémoire.
Pour voir les résultats, tapez:</p>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb49-1" title="1"><span class="kw">summary</span>(RegModel<span class="fl">.1</span>)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = fklngth ~ age, data = sturgeon.male)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -8.4936 -2.2263  0.1849  1.7526 10.8234 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 28.50359    1.16873   24.39   &lt;2e-16 ***
## age          0.70724    0.05888   12.01   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.307 on 73 degrees of freedom
##   (5 observations deleted due to missingness)
## Multiple R-squared:  0.664,	Adjusted R-squared:  0.6594 
## F-statistic: 144.3 on 1 and 73 DF,  p-value: &lt; 2.2e-16</code></pre>
<ol style="list-style-type: decimal">
<li>Le modèle qui a été ajusté et les données utilisées.</li>
<li>Un sommaire statistique des résidus autour du modèle estimé.</li>
<li>Valeurs estimées des paramètres du modèle, erreurs-types, statistiques t et probabilités associées.</li>
<li>Racine carrée de la variance résiduelle.</li>
<li>Coefficient de détermination. Il correspond à la proportion de la variabilité de la variable dépendante qui peut être expliquée par la régression.</li>
<li>Le R-carré ajusté tient compte du nombre de paramètres du modèle. Si vous voulez comparer différents modèles qui n’ont pas le même nombre de paramètres, c’est ce qu’il faut utiliser.</li>
<li>C’est le test de signification omnibus du modèle. Dans le cas de la régression simple, il est équivalent au test sur la pente de la régression.</li>
</ol>
<p>La régression estimée est donc:</p>
<p><span class="math display">\[ Fklngth = 28.50359 + 0.70724 * age\]</span></p>
<p>Étant donné la valeur significative du test de F ainsi que pour le test de t pour la pente de la droite, on rejette l’hypothèse nulle qu’il n’y a pas de relation entre la taille et l’âge.</p>
<div id="vérifier-les-conditions-dapplication-de-la-régression" class="section level3">
<h3><span class="header-section-number">3.6.1</span> Vérifier les conditions d’application de la régression</h3>
<p>La régression simple de type I a quatre conditions préalables :</p>
<ol style="list-style-type: decimal">
<li>il n’y a pas d’erreur de mesure sur la variable indépendante (X)</li>
<li>la relation entre Y et X est linéaire</li>
<li>les résidus sont normalement distribués</li>
<li>la variance des résidus est constante pour toutes les valeurs de la variable indépendante</li>
</ol>
<p>Procédons maintenant à l’examen post-mortem. La première
condition est rarement remplie avec des données biologiques ; il y
presque toujours de l’erreur sur X et sur Y. Cela veut dire qu’en
général les pentes estimées sont biaisées, mais que les valeurs prédites
ne le sont pas. Toutefois, si l’erreur de mesure sur X est petite par
rapport à l’étendue des valeurs de X, le résultat de l’analyse n’est pas
dramatiquement influencé. Par contre, si l’erreur de mesure est
relativement grande (toujours par rapport à l’étendue des valeurs de
X), la droite de régression obtenue par la régression de modèle I est
un piètre estimé de la relation fonctionnelle entre X et Y. Dans ce cas,
il est préférable de passer à la régression de modèle II,
malheureusement au-delà du contenu de ce cours.
Les autres conditions préalables à l’analyse de régression de modèle I
peuvent cependant être vérifiées, ou du moins évaluées visuellement.
La commande plot() permet de visualiser des graphiques
diagnostiques pour des modèles linéaires.</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb51-1" title="1"><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>), <span class="dt">las=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb51-2" title="2"><span class="kw">plot</span>(RegModel<span class="fl">.1</span>)</a></code></pre></div>
<p>La commande par() est utilisée pour dire à R de tracer 2 rangées et 2 colonnes de graphiques par page (il y a quatre graphiques diagnostiques qui sont générés automatiquement pour les modèles linéaires), et la commande las indique à R d’effectuer une rotation des légendes de l’axe des Y pour qu’elles soient perpendiculaires à l’axe (oui. Je sais. Rien de tout ça n’est évident.)</p>
<p>Vous obtiendrez:
<img src="Labo_BIO4558_files/figure-html/sturlmv-1eval-1.png" width="672" /></p>
<ol style="list-style-type: decimal">
<li>En haut à gauche, permet d’évaluer la linéarité, la normalité, et l’homoscédasticité des résidus. Il illustre les déviations autour de la régression en fonction des valeurs prédites. Rappllez-vous que le graphique de fklngth vs age suggère que la relation entre la longueur à la fourche et l’âge n’est pas linéaire. Les très jeunes et très vieux esturgeons sont sous la droite en général, alors que les esturgeons d’âge moyen sont retrouvés généralement au-dessus de la droite de régression. C’est exactement ce que le graphique des résidus en fonction des valeurs prédites illustre. La ligne en rouge est une trace lowess au travers de ce nuage de points. Si la relation était linéaire, la trace lowess serait presque plate et près de 0. La dispersion des résidus permet d’évaluer visuellement leur normalité et hétéroscédasticité; mais ce graphique n’est pas optimal pour évaluer ces propriétés. Les deux graphiques suivants sont supérieurs au premier pour cela.</li>
<li>En haut à droite permet d’évaluer la normalité des résidus. C’est un graphique QQ des résidus (QQ plot). Des résidus distribués normalement tomberaient exactement sur la diagonale. Ici, on voit que c’est presque le cas, sauf dans les queues de la distribution.</li>
<li>En bas à gauche, intitulé Scale-Location, permet d’évaluer l’homoscedasticité. On y retrouve sur l’ordonnée (l’axe des y) la racine carrée de la valeur absolue des résidus standardisés (résidus divisés par l’écart-type des résidus) en fonction des valeurs prédites. Le graphique aide à déterminer si la variation des résidus est constante ou non. Si les résidus sont homoscédastiques, la valeur moyenne sur l’axe des y ne va pas changer en fonction de la valeur prédite. Ici, il y a une certaine tendance, mais pas une tendance monotone puisqu’ il y a d’abord une baisse puis une hausse..; bref, rien qui soit une forte évidence contre la supposition d’homoscédasticité.</li>
<li>En bas à droite, montre les résidus en fonction du “leverage” et permet de détecter certaines valeurs extrêmes qui ont une grande influence sur la régression. Le leverage d’un point mesure sa distance des autres points, mais seulement en ce qui concerne les variables indépendantes. Dans le cas d’une régression simple, cela revient à la distance entre le point sur l’axe des x et la moyenne de tous les points sur cet axe. Vous devriez porter une attention particulière aux observations qui ont un leverage plus grand que <span class="math inline">\(2(k+1)/n\)</span>, où k est le nombre de variables indépendantes (ici, 1) et n est le nombre d’observations. Dans cet exemple, il y a 75 observations et une variable indépendante et donc les points ayant un leverage plus grand que <span class="math inline">\(4 / 75 = 0.053\)</span> devrait être considérés avec attention. Le graphique indique également comment la régression changerait si on enlevait un point. Ce changement est mesuré par la distance de Cook, illustrée par les bandes en rouge sur le graphique. Un point ayant une distance de Cook supérieure à 1 a une grande influence.</li>
</ol>
<p><strong>Attrappe</strong>: Notez que R identifie automatiquement les cas les plus extrèmes sur chacun de ces 4 graphiques. Le fait qu’un point soit identifié ne signifie pas nécessairement que c’est une valeur réellement extrème, ou que vous devez vous en préoccuper. Dans tous les ensembles de données il y aura toujours un résidu plus grand que les autres…</p>
<p>Finalement, quel est le verdict concernant la régression linéaire entre fklngth et age ? Elle viole la condition de linéarité, possiblement celle de normalité, remplit la condition d’homoscédasticité, et ne semble pas influencée outre mesure par des valeurs bizarres ou extrêmes.</p>
</div>
<div id="tests-formels-des-conditions-dapplication-pour-la-régression" class="section level3">
<h3><span class="header-section-number">3.6.2</span> Tests formels des conditions d’application pour la régression</h3>
<p>Personnellement, je n’utilise jamais les tests formels des conditions d’application de la régression et me contente des graphiques des résidus pour guider mes décisions. C’est ce que la plupart des praticiens font. Cependant, lors de mes premières analyses, je n’étais pas toujours certain de bien interpréter les graphiques et j’aurais aimé un indice plus formel ou un test permettant de détecter les violations des conditions d’application de la régression.</p>
<p>Le package <code>lmtest</code> , qui ne fait pas partie de l’installation de base, mais qui est disponible sur CRAN, permet de faire plusieurs tests de linéarité et d’homoscédasticité. Et on peut tester la normalité avec le test Shapiro-Wilk test vu précédemment.</p>
<ul>
<li>Charger le package lmtest de CRAN (et installer le si besoin).</li>
</ul>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb52-1" title="1"><span class="kw">library</span>(lmtest)</a></code></pre></div>
<ul>
<li>Exécutez les commandes suivantes:</li>
</ul>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb53-1" title="1"><span class="kw">bptest</span>(RegModel<span class="fl">.1</span>)</a></code></pre></div>
<pre><code>## 
## 	studentized Breusch-Pagan test
## 
## data:  RegModel.1
## BP = 1.1765, df = 1, p-value = 0.2781</code></pre>
<p>Le test Breusch-Pagan test examine si la variabilité des résidus est constantes lorsque les valeurs prédites changent. Une faible valeur de p suggère de l’hétéroscédasticité. Ici, la valeur p est élevée et suggère que la condition d’application d’homoscédasticité est remplie avec ces données.</p>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb55-1" title="1"><span class="kw">dwtest</span>(RegModel<span class="fl">.1</span>)</a></code></pre></div>
<pre><code>## 
## 	Durbin-Watson test
## 
## data:  RegModel.1
## DW = 2.242, p-value = 0.8489
## alternative hypothesis: true autocorrelation is greater than 0</code></pre>
<p>Le test Durbin-Watson permet de détecter l’autocorrélation sérielle des résidus. En l’absence d’autocorrélation (i.e. d’indépendance des résidus) la valeur attendue de la statistique D est 2. Ce test permet d’éprouver l’hypothèse d’indépendance des résidus, mais ne permet de détecter qu’un type particulier de dépendance. Ici, le test ne permet pas de rejeter l’hypothèse d’indépendance.</p>
<div class="sourceCode" id="cb57"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb57-1" title="1"><span class="kw">resettest</span>(RegModel<span class="fl">.1</span>)</a></code></pre></div>
<pre><code>## 
## 	RESET test
## 
## data:  RegModel.1
## RESET = 14.544, df1 = 2, df2 = 71, p-value = 5.082e-06</code></pre>
<p>Le test RESET permet d’éprouver la linéarité. Si la relation est linéaire, alors la statistique RESET sera d’environ 1. Ici, la statistique est beaucoup plus élevée (14.54) et hautement significative. Le test confirme la tendance que nous avons détectée visuellement plus haut: la relation n’est pas linéaire.</p>
<div class="sourceCode" id="cb59"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb59-1" title="1"><span class="kw">shapiro.test</span>(<span class="kw">residuals</span>(RegModel<span class="fl">.1</span>))</a></code></pre></div>
<pre><code>## 
## 	Shapiro-Wilk normality test
## 
## data:  residuals(RegModel.1)
## W = 0.98037, p-value = 0.2961</code></pre>
<p>Le test de normalité Shapiro-Wilk sur les résidus confirme que la déviation par rapport à une distribution normale des résidus n’est pas grande.</p>
</div>
</div>
<div id="transformation-des-données-en-régression" class="section level2">
<h2><span class="header-section-number">3.7</span> Transformation des données en régression</h2>
<p>La relation entre <code>fklngth</code> et <code>age</code> n’étant pas linéaire, on devrait donc essayer de transformer les données pour tenter de les linéariser :</p>
<ul>
<li>Voyons ce qu’une transformation log donne:</li>
</ul>
<div class="sourceCode" id="cb61"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb61-1" title="1"><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>), <span class="dt">las=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb61-2" title="2"><span class="kw">ggplot</span>(</a>
<a class="sourceLine" id="cb61-3" title="3">  <span class="dt">data =</span> sturgeon.male,</a>
<a class="sourceLine" id="cb61-4" title="4">  <span class="kw">aes</span>(<span class="dt">x=</span><span class="kw">log10</span>(age), <span class="dt">y=</span><span class="kw">log10</span>(fklngth))) <span class="op">+</span></a>
<a class="sourceLine" id="cb61-5" title="5"><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">color=</span><span class="st">&quot;red&quot;</span>)<span class="op">+</span></a>
<a class="sourceLine" id="cb61-6" title="6"><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method=</span><span class="st">&quot;lm&quot;</span>, <span class="dt">se=</span><span class="ot">FALSE</span>, <span class="dt">color=</span><span class="st">&quot;green&quot;</span>)<span class="op">+</span></a>
<a class="sourceLine" id="cb61-7" title="7"><span class="st">  </span><span class="kw">geom_point</span>()</a></code></pre></div>
<p><img src="Labo_BIO4558_files/figure-html/sturtr-1-1.png" width="672" /></p>
<p>Ajustons maintenant une régression simple sur ces données transformées.</p>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb62-1" title="1">RegModel<span class="fl">.2</span> &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">log10</span>(fklngth)<span class="op">~</span><span class="kw">log10</span>(age), <span class="dt">data=</span>sturgeon.male)</a>
<a class="sourceLine" id="cb62-2" title="2"><span class="kw">summary</span>(RegModel<span class="fl">.2</span>)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log10(fklngth) ~ log10(age), data = sturgeon.male)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.082794 -0.016837 -0.000719  0.021102  0.087446 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  1.19199    0.02723   43.77   &lt;2e-16 ***
## log10(age)   0.34086    0.02168   15.72   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.03015 on 73 degrees of freedom
##   (5 observations deleted due to missingness)
## Multiple R-squared:  0.772,	Adjusted R-squared:  0.7688 
## F-statistic: 247.1 on 1 and 73 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Examinons maintenant les graphiques diagnostiques:</p>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb64-1" title="1"><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>), <span class="dt">las=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb64-2" title="2"><span class="kw">plot</span>(RegModel<span class="fl">.2</span>)</a></code></pre></div>
<p><img src="Labo_BIO4558_files/figure-html/sturtr-3-1.png" width="672" /></p>
<p>Il y a une certaine amélioration, mais ce n’est pas encore parfait (la perfection n’est pas de ce monde….). Le graphique des résidus en fonction des valeurs prédites suggère encore une certaine non linéarité. Sur le graphique Q-Q les points se retrouvent plus près de la droite diagonale qu’avant, indiquant que les résidus sont encore plus près de la normalité après la transformation log-log. Il n’y a pas d’indice d’hétéroscédasticité. Finalement, même si il reste quelques points avec plus d’influence (leverage) que les autres, aucun n’a une distance de Cook au-delà de 0.5. En résumé, la transformation log a amélioré les choses: relation est plus linéaire, les résidus sont plus normaux, et il y a moins de points avec une influence relativement élevée.Est-ce que les tests formels supportent cette évaluation?</p>
<div class="sourceCode" id="cb65"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb65-1" title="1"><span class="kw">bptest</span>(RegModel<span class="fl">.2</span>)</a></code></pre></div>
<pre><code>## 
## 	studentized Breusch-Pagan test
## 
## data:  RegModel.2
## BP = 0.14282, df = 1, p-value = 0.7055</code></pre>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb67-1" title="1"><span class="kw">dwtest</span>(RegModel<span class="fl">.2</span>)</a></code></pre></div>
<pre><code>## 
## 	Durbin-Watson test
## 
## data:  RegModel.2
## DW = 2.1777, p-value = 0.6134
## alternative hypothesis: true autocorrelation is greater than 0</code></pre>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb69-1" title="1"><span class="kw">resettest</span>(RegModel<span class="fl">.2</span>)</a></code></pre></div>
<pre><code>## 
## 	RESET test
## 
## data:  RegModel.2
## RESET = 4.4413, df1 = 2, df2 = 71, p-value = 0.01523</code></pre>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb71-1" title="1"><span class="kw">shapiro.test</span>(<span class="kw">residuals</span>(RegModel<span class="fl">.2</span>))</a></code></pre></div>
<pre><code>## 
## 	Shapiro-Wilk normality test
## 
## data:  residuals(RegModel.2)
## W = 0.98998, p-value = 0.8246</code></pre>
<p>Oui, les conclusions sont les mêmes: les résidus sont encore homoscédastiques (test Breusch-Pagan), ne sont pas autocorrélés (test Durbin-Watson), sont normaux (test Shapiro-Wilk ), et sont plus linéaires (la valeur de P du test RESET est maintenant 0.015, au lieu de 0.000005). Donc la linéarité a augmenté, mais cette condition d’application semble encore légèrement violée.</p>
</div>
<div id="traitement-des-valeurs-extrèmes" class="section level2">
<h2><span class="header-section-number">3.8</span> Traitement des valeurs extrèmes</h2>
<p>Dans cet exemple, il n’y a pas de valeur vraiment extrème. Oui, je sais, R a quand même identifié les observations 8, 24, et 112 dans le dernier graphique diagnostique. Mais ces valeurs sont encore dans la fourchette de valeurs que je juge “acceptables”. Mais comment déterminer objectivement ce qui est acceptable? À quel moment juge t’on qu’une valeur extrême est vraiment trop invraisemblable pour ne pas l’exclure? Il n’y a malheureusement pas de règle absolue là-dessus. Les opinions varient, mais je penche vers le conservatisme sur cette question.</p>
<p>Ma position est que, à moins que la valeur soit biologiquement impossible ou clairement une erreur d’entrée de données, je n’élimine pas les valeurs extrêmes et j’utilise toutes mes données dans leur analyse. Pourquoi?</p>
<p>Parce que je veux que mes données reflètent bien la variabilité naturelle ou réelle. C’est d’ailleurs parfois cette variabilité qui est intéressante.</p>
<p>L’approche conservatrice qui consiste à conserver toutes les valeurs extrêmes possibles est possiblement la plus honnête, mais elle peut causer certains problèmes. Ces valeurs extrêmes sont souvent la cause des violations des conditions d’application des tests statistiques. La solution suggérée à ce dilemme est de faire l’analyse avec et sans les valeurs extrêmes et de comparer les conclusions. Dans bien des cas, les conclusions seront qualitativement les mêmes et les tailles d’effet ne seront pas très différentes. Toutefois, dans certains cas, la présence des valeurs extrêmes change complètement les conclusions. Dans ces cas, il faut simplement accepter que les conclusions dépendent entièrement de la présence des valeurs extrêmes et sont donc peu concluantes.</p>
<p>Suivant cette approche comparative, refaisons donc l’analyse après
avoir enlevé les observations 8, 24, et 112.</p>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb73-1" title="1">RegModel<span class="fl">.3</span> &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">log10</span>(fklngth)<span class="op">~</span><span class="kw">log10</span>(age), <span class="dt">data=</span>sturgeon.male, <span class="dt">subset =</span> <span class="op">!</span>(<span class="kw">rownames</span>(sturgeon.male) <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="st">&#39;8&#39;</span>,<span class="st">&#39;24&#39;</span>,<span class="st">&#39;112&#39;</span>)))</a>
<a class="sourceLine" id="cb73-2" title="2"><span class="kw">summary</span>(RegModel<span class="fl">.3</span>)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log10(fklngth) ~ log10(age), data = sturgeon.male, 
##     subset = !(rownames(sturgeon.male) %in% c(&quot;8&quot;, &quot;24&quot;, &quot;112&quot;)))
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.069163 -0.017390  0.000986  0.018590  0.047647 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  1.22676    0.02431   50.46   &lt;2e-16 ***
## log10(age)   0.31219    0.01932   16.16   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.02554 on 70 degrees of freedom
##   (5 observations deleted due to missingness)
## Multiple R-squared:  0.7885,	Adjusted R-squared:  0.7855 
## F-statistic:   261 on 1 and 70 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>L’ordonnée à l’origine (Intercept), la pente, et le R carré sont presque les mêmes, et la valeur de p est encore astronomiquement petite. Enlever les valeurs extrêmes a peu d’effet dans ce cas.</p>
<p>Les graphiques diagnostiques des résidus et les tests formels des conditions d’application sur ce sous-ensemble de données donnent:</p>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb75-1" title="1"><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</a>
<a class="sourceLine" id="cb75-2" title="2"><span class="kw">plot</span>(RegModel<span class="fl">.3</span>)</a></code></pre></div>
<p><img src="Labo_BIO4558_files/figure-html/sturtr-6-1.png" width="672" /></p>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb76-1" title="1">sturgeon.male.subset &lt;-<span class="st"> </span><span class="kw">subset</span>(sturgeon, <span class="dt">subset=</span><span class="op">!</span>(<span class="kw">rownames</span>(sturgeon.male) <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="st">&#39;8&#39;</span>,<span class="st">&#39;24&#39;</span>,<span class="st">&#39;112&#39;</span>)))</a>
<a class="sourceLine" id="cb76-2" title="2"><span class="kw">bptest</span>(RegModel<span class="fl">.3</span>)</a></code></pre></div>
<pre><code>## 
## 	studentized Breusch-Pagan test
## 
## data:  RegModel.3
## BP = 0.3001, df = 1, p-value = 0.5838</code></pre>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb78-1" title="1"><span class="kw">dwtest</span>(RegModel<span class="fl">.3</span>)</a></code></pre></div>
<pre><code>## 
## 	Durbin-Watson test
## 
## data:  RegModel.3
## DW = 2.0171, p-value = 0.5074
## alternative hypothesis: true autocorrelation is greater than 0</code></pre>
<div class="sourceCode" id="cb80"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb80-1" title="1"><span class="kw">resettest</span>(RegModel<span class="fl">.3</span>)</a></code></pre></div>
<pre><code>## 
## 	RESET test
## 
## data:  RegModel.3
## RESET = 3.407, df1 = 2, df2 = 68, p-value = 0.0389</code></pre>
<div class="sourceCode" id="cb82"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb82-1" title="1"><span class="kw">shapiro.test</span>(<span class="kw">residuals</span>(RegModel<span class="fl">.3</span>))</a></code></pre></div>
<pre><code>## 
## 	Shapiro-Wilk normality test
## 
## data:  residuals(RegModel.3)
## W = 0.98318, p-value = 0.4502</code></pre>
<p>Il n’y a pas vraiment de différence ici non plus avec l’analyse des données en entier. Bref, tout pointe vers la conclusion que les valeurs les plus extrêmes de cet ensemble de donnée n’influencent pas indûment les résultats statistiques.</p>
</div>
<div id="quantifier-la-taille-deffet-et-analyse-de-puissance-en-régression" class="section level2">
<h2><span class="header-section-number">3.9</span> Quantifier la taille d’effet et analyse de puissance en régression</h2>
<p>L’interprétation biologique des résultats n’est pas la même chose que l’interprétation statistique. Dans l’analyse qui précède, on conclue statistiquement que la taille augmente avec l’âge (puisque la pente est positive et et p&lt;0.05). Mais cette augmentation “statistique” de la taille avec l’âge ne donne pas d’information sur la différence de taille entre les jeunes et vieux individus. La pente et un graphique sont plus informatifs à ce sujet que la valeur p. La pente (dans l’espace log-log) est 0.34. Cela veut dire que pour chaque unité d’accroissement de X (log10(age)), il y a une augmentation de 0.34 unités de log10(fklngth). En d’autres mots, quand l’âge est multiplié par 10, la longueur à la fourche est multipliée environ par 2. Donc la longueur des esturgeons augmente plus lentement que leur âge (contrairement à mon tour de taille, semble-t-il….). La valeur de la pente (0.34) est un estimé de la taille de l’effet de l’âge sur la longueur.</p>
<div id="puissance-de-détecter-une-pente-donnée" class="section level3">
<h3><span class="header-section-number">3.9.1</span> Puissance de détecter une pente donnée</h3>
<p>Pour les calculs de puissance avec G*Power vous devrez cependant utiliser une autre métrique de la taille de l’effet, calculée à partir de la pente, de son erreur-type, et de la taille de l’échantillon (ce qui facilite les calculs pour G*Power, mais malheureusement pas pour vous ;-) La métrique (d) est calculée comme:
<span class="math display">\[ d = \frac{b}{s_b\sqrt{n-k-1}} \]</span>
où <span class="math inline">\(b\)</span> est l’estimé de la pente, <span class="math inline">\(s_b\)</span> est l’erreur type de la pente, <span class="math inline">\(n\)</span> est le nombre d’observations, et <span class="math inline">\(k\)</span> est le nombre de variables indépendantes (1 pour la régression linéaire simple).</p>
<p>Vous pouvez calculer approximativement la puissance avec G*Power pour une valeur de pente que vous jugez assez grande pour mériter d’être détectée. Allez à <strong>Tests: Means: One group: difference from constant</strong>, là, vous devrez remplacer la valeur de <span class="math inline">\(b\)</span> dans l’équation pour la taille d’effet (d) par la pente que vous voudriez détecter, mais utiliser l’erreur type calculée à partir de vos données.</p>
<p>Par exemple, supposons que les ichthyologues considèrent qu’une pente de 0.1 pour la relation entre log10(fklngth) et log10(age) est signifiante biologiquement, et qu’ils désirent estimer la puissance de détecter une telle pente à partir d’un échantillon de 20 esturgeons. Les résultats de la régression log-log nous fournissent ce dont on a besoin:</p>
<div class="sourceCode" id="cb84"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb84-1" title="1"><span class="kw">summary</span>(RegModel<span class="fl">.2</span>)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log10(fklngth) ~ log10(age), data = sturgeon.male)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.082794 -0.016837 -0.000719  0.021102  0.087446 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  1.19199    0.02723   43.77   &lt;2e-16 ***
## log10(age)   0.34086    0.02168   15.72   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.03015 on 73 degrees of freedom
##   (5 observations deleted due to missingness)
## Multiple R-squared:  0.772,	Adjusted R-squared:  0.7688 
## F-statistic: 247.1 on 1 and 73 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>L’erreur-type de la pente est 0.02168. Il y avait 75 poissons (n=75) dans l’échantillon de départ. On peut donc calculer la métrique de taille d’effet pour G*Power
<span class="math display">\[ d = \frac{b}{s_b\sqrt{n-k-1}} = \frac{0.1}{0.02168\sqrt{74-1-1}}=0.54\]</span></p>
<p>Armés de cette taille d’effet (une pente présumée de 0.1 et une variabilité autour de la régression similaire à la régression de fklngth vs age), aller à <strong>Tests: Means: One group: difference from constant</strong>, et entrez la valeur calculée de d, alpha, et l’effectif de l’échantillon pour calculer la puissance.</p>
<div class="figure"><span id="fig:lm-pow-fig-1"></span>
<img src="images/lm_pow_1.png" alt="Analyse de puissance pour N = 20 et pente = 0.1" width="100%" />
<p class="caption">
Figure 3.3: Analyse de puissance pour N = 20 et pente = 0.1
</p>
</div>
<p>La puissance de détecter une pente comme étant statistiquement significative (au niveau alpha), si la pente est 0.1, que la variabilité résiduelle autour de la régression est semblable à celle de notre échantillon (ce qui revient à une taille d’effet de 0.54, pour un échantillon de 20 esturgeons et alpha=0.05) est de 0.629. Seulement environ 2/3 des échantillons de cette taille détecteraient un effet significatif de l’âge sur <code>fklngth</code>.</p>
<!-- parler de l'autre manière de faire un test de puissance pour la pente -->
</div>
<div id="effectif-requis-pour-atteindre-une-puissance-désirée-test-a-priori" class="section level3">
<h3><span class="header-section-number">3.9.2</span> Effectif requis pour atteindre une puissance désirée (test A-priori)</h3>
<p>Pour estimer la taille d’échantillon (effectif) requis pour avoir une puissance de 99% de détecter un effet de l’âge si la pente est 0.1 (sur une échelle log-log ), avec alpha=0.05, on utilise la même valeur de d (0.54):</p>
<div class="figure"><span id="fig:lm-pow-fig-2"></span>
<img src="images/lm_pow_2.png" alt="Analyse à priori pour déterminer la taille d'échantillon pour une puissance de 0.99" width="100%" />
<p class="caption">
Figure 3.4: Analyse à priori pour déterminer la taille d’échantillon pour une puissance de 0.99
</p>
</div>
<p>En augmentant la taille de l’échantillon à 65, selon le même scénario que précédemment, la puissance augmente à 99%.</p>
</div>
</div>
<div id="bootstrap-en-régression-simple-avec-r" class="section level2">
<h2><span class="header-section-number">3.10</span> Bootstrap en régression simple avec R</h2>
<p>Un test non paramétrique pour l’ordonnée à l’origine et la pente d’une régression simple peut être effectué par bootstrap.</p>
<div class="sourceCode" id="cb86"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb86-1" title="1"><span class="co">#charger le paquet boot</span></a>
<a class="sourceLine" id="cb86-2" title="2"><span class="kw">library</span>(boot)</a>
<a class="sourceLine" id="cb86-3" title="3"><span class="co"># obtenir les poids de régression</span></a>
<a class="sourceLine" id="cb86-4" title="4">bs &lt;-<span class="st"> </span><span class="cf">function</span>(formula, data, indices) {</a>
<a class="sourceLine" id="cb86-5" title="5">  d &lt;-<span class="st"> </span>data[indices,] <span class="co"># allows boot to select sample</span></a>
<a class="sourceLine" id="cb86-6" title="6">  fit &lt;-<span class="st"> </span><span class="kw">lm</span>(formula, <span class="dt">data =</span> d)</a>
<a class="sourceLine" id="cb86-7" title="7">  <span class="kw">return</span>(<span class="kw">coef</span>(fit))</a>
<a class="sourceLine" id="cb86-8" title="8">}</a>
<a class="sourceLine" id="cb86-9" title="9"><span class="co"># bootstrapping with 1000 replications</span></a>
<a class="sourceLine" id="cb86-10" title="10">results &lt;-<span class="st"> </span><span class="kw">boot</span>(</a>
<a class="sourceLine" id="cb86-11" title="11">  <span class="dt">data =</span> sturgeon.male,</a>
<a class="sourceLine" id="cb86-12" title="12">  <span class="dt">statistic =</span> bs,</a>
<a class="sourceLine" id="cb86-13" title="13">  <span class="dt">R=</span><span class="dv">1000</span>, <span class="dt">formula=</span><span class="kw">log10</span>(fklngth)<span class="op">~</span><span class="kw">log10</span>(age))</a>
<a class="sourceLine" id="cb86-14" title="14"><span class="co"># view results</span></a>
<a class="sourceLine" id="cb86-15" title="15">results</a></code></pre></div>
<pre><code>## 
## ORDINARY NONPARAMETRIC BOOTSTRAP
## 
## 
## Call:
## boot(data = sturgeon.male, statistic = bs, R = 1000, formula = log10(fklngth) ~ 
##     log10(age))
## 
## 
## Bootstrap Statistics :
##      original       bias    std. error
## t1* 1.1919926  0.001770032  0.03341155
## t2* 0.3408557 -0.001291806  0.02643552</code></pre>
<p>Pour chaque paramètre du modèle (ici l’ordonnée à l’origine est
appelée t1* et la pente de la régression t2*), R imprime :</p>
<ol style="list-style-type: decimal">
<li><code>original</code> la valeur estimée sur tout l’échantillon</li>
<li><code>bias</code> la différence entre la valeur moyenne des estimés par bootstrap et la valeur originale sur tout l’échantillon</li>
<li><code>std. error</code> l’erreur-type de l’estimé bootstrap</li>
</ol>
<div class="sourceCode" id="cb88"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb88-1" title="1"><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</a>
<a class="sourceLine" id="cb88-2" title="2"><span class="kw">plot</span>(results, <span class="dt">index=</span><span class="dv">1</span>) <span class="co"># intercept</span></a></code></pre></div>
<p><img src="Labo_BIO4558_files/figure-html/lm-boot-2-1.png" width="672" /></p>
<div class="sourceCode" id="cb89"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb89-1" title="1"><span class="kw">plot</span>(results, <span class="dt">index=</span><span class="dv">2</span>) <span class="co"># log10(age)</span></a></code></pre></div>
<p><img src="Labo_BIO4558_files/figure-html/lm-boot-2-2.png" width="672" /></p>
<p>La distribution des estimés obtenus par bootstrap est assez normale dans cet exemple, avec de petites déviations dans les queuee de la distribution (là où ça compte pour les intervalles de confiance…). On pourrait utiliser l’erreur-type des estimés bootstrap pour calculer un intervalle de confiance symétrique (moyenne +- t ET). Cependant, comme R peut facilement calculer des intervalles de confiance qui corrigent pour le biais (BCa) ou encore des intervalle empiriques à partir des distributions simulées (méthode Percentile) il peut être aussi simple de les calculer selon les 3 méthodes:</p>
<div class="sourceCode" id="cb90"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb90-1" title="1"><span class="co"># interval de confiance pour l&#39;ordonnée à l&#39;origine</span></a>
<a class="sourceLine" id="cb90-2" title="2"><span class="kw">boot.ci</span>(results, <span class="dt">type =</span> <span class="st">&quot;all&quot;</span>, <span class="dt">index =</span> <span class="dv">1</span>)</a></code></pre></div>
<pre><code>## Warning in boot.ci(results, type = &quot;all&quot;, index = 1): bootstrap variances needed
## for studentized intervals</code></pre>
<pre><code>## BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
## Based on 1000 bootstrap replicates
## 
## CALL : 
## boot.ci(boot.out = results, type = &quot;all&quot;, index = 1)
## 
## Intervals : 
## Level      Normal              Basic         
## 95%   ( 1.125,  1.256 )   ( 1.125,  1.257 )  
## 
## Level     Percentile            BCa          
## 95%   ( 1.127,  1.259 )   ( 1.117,  1.252 )  
## Calculations and Intervals on Original Scale
## Some BCa intervals may be unstable</code></pre>
<div class="sourceCode" id="cb93"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb93-1" title="1"><span class="co">#intervalle de confiance pour la pente</span></a>
<a class="sourceLine" id="cb93-2" title="2"><span class="kw">boot.ci</span>(results, <span class="dt">type =</span> <span class="st">&quot;all&quot;</span>, <span class="dt">index =</span> <span class="dv">2</span>)</a></code></pre></div>
<pre><code>## Warning in boot.ci(results, type = &quot;all&quot;, index = 2): bootstrap variances needed
## for studentized intervals</code></pre>
<pre><code>## BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
## Based on 1000 bootstrap replicates
## 
## CALL : 
## boot.ci(boot.out = results, type = &quot;all&quot;, index = 2)
## 
## Intervals : 
## Level      Normal              Basic         
## 95%   ( 0.2903,  0.3940 )   ( 0.2893,  0.3947 )  
## 
## Level     Percentile            BCa          
## 95%   ( 0.2870,  0.3924 )   ( 0.2942,  0.4005 )  
## Calculations and Intervals on Original Scale</code></pre>
<p>Ici, les 4 types d’intervalles de confiance que R a calculé sont essentiellement semblables. Si les données avaient violé plus sévèrement les conditions d’application de la régression (normalité, homoscedasticité), alors les différentes méthodes (Normal, Basic, Percentile, et BCa) auraient divergé un peu plus. Lequel choisir alors? BCa est celui qui est préféré de la majorité des praticiens, présentement.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="analyse-de-puissance-avec-r-et-gpower.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="comparaison-de-deux-échantillons.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Labo_BIO4558.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
